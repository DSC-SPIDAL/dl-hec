# -*- coding: utf-8 -*-
"""FFFFWNPFEARTHQv3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q7HbRFEHOyHr_1HSB0jQPSPfoxx5Mu2o

##### Copyright 2019 The TensorFlow Authors and Geoffrey Fox 2020
"""

# @title #### Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""###Describe Dataset components"""

from util import printexit
from cloudmesh.common.Shell import Shell

import config

import copy
import json

NamesList = ["RunName",
             "RunComment",
             "LocalRunName",
             "LocalRunComment",
             "UseLSTMModel",
             "UseScienceTransformerModel",
             "UseTFTModel",
             "UseModel",
             "Directoryaddon",
             "SymbolicWindows",
             "Tseq",
             "LocationBasedValidation",
             "RestartLocationBasedValidation",
             "LocationValidationFraction",
             "RestartValidationSetRunName",
             "UseFutures",
             "CustomLoss",
             "Npropperseq",
             "NpropperseqTOT",
             "Npredperseq",
             "NpredperseqTOT",
             "PropertyNameIndex",
             "PredictionNameIndex",
             "PropertyAverageValuesPointer",

             "PredictionAverageValuesPointer",
             "Predictionwgt",

             "InputSource",
             "InputSourceNumber",
             "PredSource",
             "PredSourceNumber",
             "FuturedPred ",

             "SpaceTimeEncodingPropTypes",
             "SpaceTimeEncodingPropValues",
             "SpaceTimeEncodingPredTypes",
             "SpaceTimeEncodingPredValues ",

             "Nloc",
             "ListofTrainingLocs",
             "ListofValidationLocs",
             "MappingtoTraining",
             "MappingtoValidation",
             "TrainingNloc",
             "ValidationNloc",

             "RawInputSequences",
             "RawInputPredictions",
             "RawInputSequencesTOT",
             "RawInputPredictionsTOT",

             "LSTMepochs",
             "LSTMvalidationfrac",
             "LSTMbatch_size",
             "LSTMoptimizer",
             "LSTMactivationvalue",
             "LSTMdropout1",
             "LSTMrecurrent_dropout1",
             "LSTMdropout2",
             "LSTMrecurrent_dropout2",
             "LSTMSkipInitial",
             "number_LSTMnodes",
             "LSTMThirdLayer",
             "LSTMInitialMLP",
             "LSTMFinalMLP",
             "LSTMverbose",
             "LSTMlearning_rate ",
             "LSTMvalidationfrac",
             "UsedLSTMvalidationfrac",

             "SpacetimeforMask ",
             "GlobalSpacetime",

             "IncreaseNloc_sample",
             "DecreaseNloc_sample",
             "Transformerepochs",

             "SkipDL2",
             "SkipDL2B",
             "SkipDL2D",
             "SkipDL2E",

             "SampleSize",
             "PredictionTraining",
             "FullSetValidation",

             "MaskingOption",
             "ActivateAttention",
             "DoubleQKV",
             "TimeShufflingOnly",
             "Transformerbatch_size",

             "Transformervalidationfrac",
             "UsedTransformervalidationfrac",
             "Transformeroptimizer",
             "Transformerverbose",

             "TransformerOnlyFullAttention",
             "SpacewiseSecondAttention",
             "SeparateHeads",
             "d_model",
             "d_Attention",

             "d_qkl",
             "d_intermediateqk",
             "num_heads",
             "num_Encoderlayers",
             "EncoderDropout",
             "EncoderActivation",

             "d_EncoderLayer",
             "d_merge",
             "d_ffn",
             "oldencoderversion",
             "ReuseInputinEncoder",
             "UseMappedinput",

             "Takevasinput",

             
             "ChopupMatrix",
             "ChopupNumber",

             
             "Plotrealnumbers",
             "JournalSimplePrint",
             "UseRealDatesonplots",
             "PlotinDL2F",
             "SkipDL2F",
             "CalculateNNSE",

             "PlotPredictions",
             "SeparateValandTrainingPlots",
             "PlotsOnlyinTestFIPS",
             "ListofTestFIPS",

             
             "Dailyunit",
             "StartDate",

             
             "Num_Seq",
             "GlobalTimeMask ",

             
             "AnalysisOnly",
             "Dumpoutkeyplotsaspics",
             "Restorefromcheckpoint",
             "Checkpointfinalstate ",

             "inputRunName",
             "inputCheckpointpostfix",
             "standaloneLSTMrun",
             "ClassLSTMrun",
             "CustomTraining",

             "SuccessLimit",
             "FailureLimit"]


def SetDictvalues(Dict, UpdateList):
    for varname in UpdateList:
        if varname in Dict:
            exec('Dict["' + varname + '"] =' + varname)
            print(varname + " updated in Dict " + str(Dict[varname]))
        else:
            printexit("Error as " + varname + " not in dictionary")


def SetupModelOver():
    global UseModel, UseLSTMModel, UseScienceTransformerModel, UseTFTModel
    UseLSTMModel = False
    UseScienceTransformerModel = False
    UseTFTModel = False
    if UseModel == 0:
        UseLSTMModel = True
    elif UseModel == 1:
        UseScienceTransformerModel = True
    elif UseModel == 2:
        UseTFTModel = True


from IPython.display import Javascript
from psutil import virtual_memory


# Avoids scroll-in-the-scroll in the entire Notebook
def resize_colab_cell():
    display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 20000})'))


get_ipython().events.register('pre_run_cell', resize_colab_cell)

# Set Global Parameters for all components
# Can set defaults for components in Overalljstring
Overalljstring = '{ "RunName" : "EARTHQ-EMA1LR8" , "RunComment" : "EARTHQ LSTM and 1 EMA LR*0.1 Earlier Stop" }'

# from hec.config import read_config
# config = read_config("./config.yaml")
# FFFFOverallDict = config


FFFFOverallDict = dict.fromkeys(NamesList)

TempDict = json.loads(Overalljstring)
FFFFOverallDict.update(TempDict)

RunName = FFFFOverallDict["RunName"]

RunComment = FFFFOverallDict["RunComment"]
FFFFOverallDict["LocalRunName"] = ''
FFFFOverallDict["LocalRunComment"] = ''
CurrentDataset = FFFFOverallDict
NumberofDatasets = 1
PrintTitle('Start Job')


def PrintTitle(extrawords):
    current_time = timenow()

    LR = CurrentDataset["LocalRunName"]
    if LR != '':
        if NumberofDatasets > 1:
            LR = str(NumberofDatasets) + ': ' + LR
        LR = ' ' + LR
    LC = CurrentDataset["LocalRunComment"]
    if LC != '':
        if NumberofDatasets > 1:
            LC = str(NumberofDatasets) + ': ' + LC
        LC = ' ' + LC

    line = CurrentDataset["RunName"] + LR + ' ' + CurrentDataset["RunComment"] + LC
    beginwords = ''
    if extrawords != '':
        beginwords = extrawords + ' '
    print(wraptotext(startbold + startred + beginwords + current_time + ' ' + line + resetfonts))
    ram_gb = virtual_memory().total / 1e9
    print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))


"""#### Set Run Name etc

# Initial System Code
"""

startbold = "\033[1m"
resetfonts = "\033[0m"
startred = '\033[31m'

startpurple = '\033[35m'
startyellowbkg = '\033[43m'

content = Shell.run("lscpu")
print (content)

gpu_info = Shell.run("nvidia-smi")
# gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
    print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
else:
    print(gpu_info)

from google.colab import drive

drive.mount('/content/gdrive')

"""# Transformer model for science data based on original for language understanding

<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://www.tensorflow.org/tutorials/text/transformer">
    <img src="https://www.tensorflow.org/images/tf_logo_32px.png" />
    View on TensorFlow.org</a>
  </td>
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb">
    <img src="https://www.tensorflow.org/images/colab_logo_32px.png" />
    Run in Google Colab</a>
  </td>
  <td>
    <a target="_blank" href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub</a>
  </td>
  <td>
    <a href="https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/transformer.ipynb"><img src="https://www.tensorflow.org/images/download_logo_32px.png" />Download notebook</a>
  </td>
</table>

## Science Data Parameters and Sizes

-------
Here is structure of science time series module. We will need several arrays that will need to be flattened at times. Note Python defaults to row major i.e. final index describes contiguous positions in memory


At highest level data is labeled by Time and Location

*   Ttot is total number of time steps
*   Tseq is length of each sequence in time steps
*   Num_Seq is number of sequences in time: Num_Seq = Ttot-Tseq + 1
*   Nloc is Number of locations. The locations could be a 1D list or have array structure such as an image.
*   Nsample is number of data samples Nloc * Num_Seq




Input data is at each location
*   Nprop time independent properties describing the location
*   Nforcing is number of time dependent forcing features INPUT at each time value


Output (predicted) data at each location and for each time sequence is
*   Npred predicted time dependent values defined at every time step
*   Recorded at Nforecast time values measured wrt final time value of sequence
*   ForecastDay is an array of length Nforecast defining how many days into future prediction is. Typically ForecastDay[0] = 1 and Nforecast is often 1
*   There is also a class of science problems that are more similar to classic Seq2Seq. Here Nforecast = Tseq and ForecastDay = [-Tseq+1 ... 0]
*   We also support Nwishful predictions of events in future such probability of an earthquake of magnitude 6 in next 3 years. These are defined by araays EventType and Timestart, TimeInterval of length Nwishful. EventType is user defined and Timestart, TimeInterval is measured in time steps
*   Any missing output values should be set to NaN and Loss function must ensure that these points are ignored in derivative calculation and value calculation

We have an input module that supports either LSTM or Transformer (multi-head attention) models

Example Problem AICov

*   Ttot = 114
*   Tseq = 9
*   Num_Seq = 106
*   Nloc = 110


*   Nprop = 35
*   Nforcing = 5 including infections, fatalities, plus 3 temporal position variables (last 3 not in current version)
 
 
*   Npred = 2 (predicted infections and fatalities). Could be 5 if predicted temporal position of output)
*   Nforecast= 15
*   ForecastDay = [1, 2, .......14, 15]
*   Nwishful = 0

## Science Data Arrays

Typical Arrays


[ time, Location ] as Pandas array with label [name of time-dependent variable] as an array or just name of Pandas array

time labels rows indexed by datetime or the difference datetime - start

Non windowed data is stored with propert name as row index and location as column index
[ static property, Location]

Covid Input is
[Sequence number 0..Num_Seq-1 ] [ Location 0..Nloc-1 ] [position in time sequence Tseq]  [ Input Features]

Covid Output is 
[Sequence number Num_Seq ] [ Location Nloc ]  [ Output Features] 

Output Features are [ ipred = 0 ..Npred-1 ] [ iforecast = 0 ..Nforecast-1 ]

Input Features are static fields followed by if present by dynamic system fields (cos-theta sin-theta linear) chosen followed by cases, deaths. In fact this is user chosen as they set static and dynamic system properties to use

We will have various numpy and pandas arrays where we designate label

[Ttot] is all time values 

[Num_Seq]  is all sequences of window size ***Tseq***

We can select time values or sequences [Ttot-reason] [Num_Seq-reason] for a given "reason"

[Num_Seq][Tseq] is all time values in all sequences

[Nloc] is all locations while [Nloc-reason] is subset of locations for given "reason"

[Model1] is initial embedding of each data point

[Model1+TrPosEnc] is initial embedding of each data point with Transformer style positional encoding

[Nforcing] is time dependent input parameters and [Nprop] static properties while [ExPosEnc] are explicit positional (temporal) encoding.

[Nforcing+ExPosEnc+Nprop] are all possible inputs

[Npred] is predicted values with [Npred+ExPosEnc] as predictions plus encodings with actually used [Predvals] = [Npred+ExPosEnc-Selout] 

[Predtimes] = [Forecast time range] are times forecasted with "time range" separately defined
"""

import tensorflow as tf
from tqdm.keras import TqdmCallback
from tqdm import notebook

import os
import gc
from csv import reader
import sys
import random
import math
import numpy as np
import matplotlib.pyplot as plt
from textwrap import wrap
import io as io

import datetime
from datetime import timedelta, datetime

content = Shell.run("pip install cloudmesh.common -U")
print(content)

from cloudmesh.common.StopWatch import StopWatch

"""##Define Basic Control parameters

###General Functions for all Components
"""

from util import wraptotext
from util import  timenow
from util import float32fromstrwithNaN
from util import strrnd



import matplotlib.dates as mdates

NaN = np.float32("NaN")
PLOTNUMBER = 0  # Count Output Plots

"""###Set Global Variables to None"""

ReadMay2022Covid = None
Read7dayCovid = None
ScaleProperties = None
ConvertDynamicPredictedQuantity = None
ConvertDynamicProperties = None
GenerateFutures = None
GenerateSequences = None
PredictionsfromInputs = None
RereadMay2020 = None
UseOLDCovariates = None
Dropearlydata = None
NIHCovariates = None
UseFutures = None
Usedaystart = None
PopulationNorm = None
SymbolicWindows = None
Hydrology = None
Earthquake = None

CDSpecial = None
RootCasesDeaths = None
NumpredbasicperTime = None
NumpredFuturedperTime = None
NumTimeSeriesCalculated = None
Dailyunit = None
TimeIntervalUnitName = None
InitialDate = None
NumberofTimeunits = None
Num_Time = None
FinalDate = None
GlobalTrainingLoss = None
GlobalValidationLoss = None

# Type of Testing
LocationBasedValidation = None
LocationValidationFraction = None
LocationTrainingfraction = None
RestartLocationBasedValidation = None

# Plotting
SeparateValandTrainingPlots = None
Plotsplitsize = None
Plotrealnumbers = None
ListofTestFIPS = None
PlotsOnlyinTestFIPS = None
EarthquakeImagePlots = None
AddSpecialstoSummedplots = None
UseRealDatesonplots = None
Dumpoutkeyplotsaspics = None
OutputNetworkPictures = None
JournalSimplePrint = None
PlotinDL2F = None
FONTSIZE = None

GarbageCollect = None
GarbageCollectionLimit = None

"""###Start New Dataset"""

UpdateList = ["LocalRunName",
              "LocalRunComment",
              "UseLSTMModel",
              "UseScienceTransformerModel",
              "UseTFTModel",
              "UseModel",
              "Directoryaddon"]
CountDatasets = 0

ComponentRunsJSON = [""]
ComponentRuns = []
NumberofDatasets = len(ComponentRunsJSON)
while CountDatasets < NumberofDatasets:
    CountDatasets += 1
    UseLSTMModel = False
    UseScienceTransformerModel = False
    UseTFTModel = False
    UseModel = 0
    SetupModelOver()
    Directoryaddon = ""
    LocalRunName = ""
    LocalRunComment = ""
    CurrentDataset = copy.deepcopy(FFFFOverallDict)

    SetDictvalues(CurrentDataset, UpdateList)
    ComponentRuns.append(CurrentDataset)
    if Earthquake:
        ReadEarthquakeData()

sys.exit(22)


def SetupScience():
    global ReadJuly2020Covid, ReadAugust2020Covid, ReadJan2021Covid, ReadApril2021Covid, ReadNov2021Covid, ReadMay2022Covid, Read7dayCovid,
    ScaleProperties, ConvertDynamicPredictedQuantity, ConvertDynamicProperties, GenerateFutures, GenerateSequences, PredictionsfromInputs,
    RereadMay2020, UseOLDCovariates, Dropearlydata, NIHCovariates, UseFutures, Usedaystart, PopulationNorm, SymbolicWindows, Hydrology, Earthquake,
    CDSpecial, RootCasesDeaths, NumpredbasicperTime, NumpredFuturedperTime, NumTimeSeriesCalculated, Dailyunit, TimeIntervalUnitName, InitialDate,
    NumberofTimeunits, Num_Time, FinalDate, GlobalTrainingLoss, GlobalValidationLoss, LocationBasedValidation, LocationValidationFraction,
    LocationTrainingfraction, RestartLocationBasedValidation, SeparateValandTrainingPlots, Plotsplitsize, Plotrealnumbers, ListofTestFIPS,
    PlotsOnlyinTestFIPS, EarthquakeImagePlots, AddSpecialstoSummedplots, UseRealDatesonplots, Dumpoutkeyplotsaspics, OutputNetworkPictures,
    JournalSimplePrint, PlotinDL2F, FONTSIZE, GarbageCollect, GarbageCollectionLimit


ReadJuly2020Covid = False
ReadAugust2020Covid = False
ReadJan2021Covid = False
ReadApril2021Covid = False
ReadNov2021Covid = False
ReadMay2022Covid = False
Read7dayCovid = False
ScaleProperties = False
ConvertDynamicPredictedQuantity = False
ConvertDynamicProperties = True
GenerateFutures = False
GenerateSequences = False
PredictionsfromInputs = False
RereadMay2020 = False
UseOLDCovariates = False
Dropearlydata = 0
NIHCovariates = False
UseFutures = True
Usedaystart = False
PopulationNorm = False
SymbolicWindows = False
Hydrology = False
Earthquake = False

CDSpecial = False
RootCasesDeaths = True
NumpredbasicperTime = 2
NumpredFuturedperTime = 2
NumTimeSeriesCalculated = 0
Dailyunit = 1
TimeIntervalUnitName = 'Day'
InitialDate = datetime(2000, 1, 1)
NumberofTimeunits = 0
Num_Time = 0
FinalDate = datetime(2000, 1, 1)
GlobalTrainingLoss = 0.0
GlobalValidationLoss = 0.0

# Type of Testing
LocationBasedValidation = False
LocationValidationFraction = 0.0
LocationTrainingfraction = 1.0
RestartLocationBasedValidation = False

# Plotting
SeparateValandTrainingPlots = True
Plotsplitsize = -1  # if > 1 split time in plots
Plotrealnumbers = True
ListofTestFIPS = []
PlotsOnlyinTestFIPS = True
EarthquakeImagePlots = False
AddSpecialstoSummedplots = False
UseRealDatesonplots = False
Dumpoutkeyplotsaspics = False
OutputNetworkPictures = False
JournalSimplePrint = False
PlotinDL2F = False
FONTSIZE = 20

GarbageCollect = True
GarbageCollectionLimit = 5000000

PrintTitle('Start Dataset')

SubName = RunName[0:6]
if SubName == 'BEST14' or SubName == 'BEST15' or SubName == 'BEST16':
    UseOLDCovariates = False
    ReadAugust2020Covid = True
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    NIHCovariates = True
    ConvertDynamicProperties = True
    Dropearlydata = 37
    CDSpecial = True

if SubName == 'CovidA' or SubName == 'CovidN' or SubName == 'CovidM' or SubName == 'Covid7':
    UseOLDCovariates = False
    ReadApril2021Covid = True
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    UseFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    NIHCovariates = True
    ConvertDynamicProperties = True
    CDSpecial = True
    if SubName == 'CovidN':
        ReadNov2021Covid = True
    if SubName == 'CovidM':
        ReadMay2022Covid = True
    if SubName == 'Covid7':
        ReadMay2022Covid = True
        Read7dayCovid = True

if SubName == 'C2021A' or SubName == 'C2021B':
    UseOLDCovariates = False
    ReadJan2021Covid = True
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    NIHCovariates = True
    ConvertDynamicProperties = True
    Dropearlydata = 0
    CDSpecial = True

if SubName == 'Hydrol':
    Hydrology = True

if SubName == 'EARTHQ':
    Earthquake = True

if RunName == 'BEST10' or RunName == 'BEST13-10D' or RunName == 'BEST12-10' or RunName == 'BEST12-Test' or RunName == 'BEST13' or RunName == 'BEST13-10' or RunName == 'BEST13-10A' or RunName == 'BEST13-10C':
    UseOLDCovariates = False
    ReadAugust2020Covid = True
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    CDSpecial = True

if RunName == 'BEST11' or RunName == 'BEST11A':
    UseOLDCovariates = True
    ReadAugust2020Covid = True
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    CDSpecial = True

if RunName == 'BEST12':
    UseOLDCovariates = True
    RereadMay2020 = True
    ReadAugust2020Covid = False
    ScaleProperties = True
    ConvertDynamicPredictedQuantity = True
    GenerateFutures = True
    GenerateSequences = True
    PredictionsfromInputs = True
    CDSpecial = True

if RunName == 'BEST8' or RunName == 'BEST8A' or RunName == 'BEST12-LSTM-8':
    ReadJuly2020Covid = True

"""## Define input structure

Read in data and set it up for Tensorflow with training and validation

Set train_examples, val_examples as science training and validatioon set.

The shuffling of Science Data needs some care. We have ***Tseq*** * size of {[Num_Seq][Nloc]} locations in each sample. In simplease case the last is just a decomposition over location; not over time. Let's Nloc-sel be number of locations per sample. It will be helpful if Nloc-sel is divisable by 2. 

Perhaps Nloc-sel = 2 6 or 10 is reasonable.

Then you shuffle locations every epoch and divide them into groups of size Nloc-sel with 50% overlap so you get locations

0 1 2 3 4 5; 

3 4 5 6 7 8; 

6 7 8 9 10 11 etc.

Every locations appears twice in an epoch (for each time value). You need to randomly add locations at end of sequence so it is divisiuble by Nloc-sel e.g add 4 random positions to the end if Nloc=110 and Nloc-sel = 6. Note last group of 6 has members 112 113 114 0 1 2

After spatial structure set up, randomly shuffle in Num_Seq where there is an argument to do all locations for a partcular time value together.

For validation, it is probably best to select validation location before chopping them into groups of size Nloc-sel

How one groups locations for inference is not clear. One idea is to take trained network and use it to find for each location which other locations have the most attention with it. Use those locations in  prediction

More general input. 
NaN allowed value

* Number time values
* Number locations
* Number driving values
* Number predicted values

For COVID driving same as predicted

* a) Clean up >=0 daily
* b) Normalize
* c) Add Futures
* d) Add time/location encoding

### Setup File Systems
"""

# read in science data
COLABROOTDIR = "/content/gdrive/My Drive/Colab Datasets"
os.environ["COLABROOTDIR"] = COLABROOTDIR

if Hydrology:
    APPLDIR = os.path.join(COLABROOTDIR, "Hydrology")
elif Earthquake:
    APPLDIR = os.path.join(COLABROOTDIR, "EarthquakeDec2020")
else:
    APPLDIR = os.path.join(COLABROOTDIR, "COVIDJuly2020")

# Set up Checkpoints
CHECKPOINTDIR = APPLDIR + "/checkpoints/" + RunName + "dir/"

if Directoryaddon != "":
    APPLDIR += "/" + Directoryaddon

Shell.mkdir(CHECKPOINTDIR)
# try:
#     if not os.path.exists(CHECKPOINTDIR):
#         os.mkdir(CHECKPOINTDIR)
# except OSError as error:
#     print(error)
print('Checkpoint set up in directory ' + CHECKPOINTDIR)

"""##General Routines"""

def mysavefig(label):
    global PLOTNUMBER
    if label == "":
        label = RunName + str(PLOTNUMBER)
        PLOTNUMBER += 1
    print("SavedPlot " + label)
    plt.savefig(APPLDIR + '/Outputs/' + label + '.pdf', format='pdf', dpi=300)
    plt.savefig(APPLDIR + '/Outputs/' + label + '.png', format='png', dpi=300)
    return


def makeadateplot(plotfigure, plotpointer, Dateaxis=None, datemin=None, datemax=None, Yearly=True, majoraxis=5):
    if not Yearly:
        sys.exit('Only yearly supported')
    plt.rcParams.update({'font.size': 9})
    years5 = mdates.YearLocator(majoraxis)  # every 5 years
    years_fmt = mdates.DateFormatter('%Y')
    plotpointer.xaxis.set_major_locator(years5)
    plotpointer.xaxis.set_major_formatter(years_fmt)
    if datemin is None:
        datemin = np.datetime64(Dateaxis[0], 'Y')
    if datemax is None:
        datemax = np.datetime64(Dateaxis[-1], 'Y') + np.timedelta64(1, 'Y')
    plotpointer.set_xlim(datemin, datemax)
    plotfigure.autofmt_xdate()
    return datemin, datemax


def makeasmalldateplot(figure, ax, Dateaxis):
    plt.rcParams.update({'font.size': 9})
    months = mdates.MonthLocator(interval=2)  # every month
    datemin = np.datetime64(Dateaxis[0], 'M')
    datemax = np.datetime64(Dateaxis[-1], 'M') + np.timedelta64(1, 'M')
    ax.set_xlim(datemin, datemax)

    months_fmt = mdates.DateFormatter('%y-%b')
    locator = mdates.AutoDateLocator()
    locator.intervald['MONTHLY'] = [2]
    formatter = mdates.ConciseDateFormatter(locator)
    #  ax.xaxis.set_major_locator(locator)
    #  ax.xaxis.set_major_formatter(formatter)
    ax.xaxis.set_major_locator(months)
    ax.xaxis.set_major_formatter(months_fmt)

    figure.autofmt_xdate()
    return datemin, datemax


"""##Earthquake Routines"""

from earthquake import *


"""### Read Hydrology Data"""

from hydrology import *

"""### Read April Nov 2021, May 2022, 7day Covid Data"""

from covid import *

"""###Normalize All Static and Dynamic Properties

for Static Properties BasicInputStaticProps[Nloc,NpropperTimeStatic] converts to NormedInputStaticProps[Nloc,NpropperTimeStatic]
"""


def SetTakeroot(x, n):
    if np.isnan(x):
        return NaN
    if n == 3:
        return np.cbrt(x)
    elif n == 2:
        if x <= 0.0:
            return 0.0
        return np.sqrt(x)
    return x


def DynamicPropertyScaling(InputTimeSeries):
    Results = np.full(7, 0.0, dtype=np.float32)
    Results[1] = np.nanmax(InputTimeSeries, axis=(0, 1))
    Results[0] = np.nanmin(InputTimeSeries, axis=(0, 1))
    Results[3] = np.nanmean(InputTimeSeries, axis=(0, 1))
    Results[4] = np.nanstd(InputTimeSeries, axis=(0, 1))
    Results[2] = np.reciprocal(np.subtract(Results[1], Results[0]))
    Results[5] = np.multiply(Results[2], np.subtract(Results[3], Results[0]))
    Results[6] = np.multiply(Results[2], Results[4])
    return Results


NpropperTimeMAX = NpropperTime + NumTimeSeriesCalculated
print('Static Proprties ', NpropperTimeStatic, ' Total Number of Basic Properties Static+Dynamic ', NpropperTime,
      ' Number of additional Calculated Properties ', NumTimeSeriesCalculated, ' Absolute Total Properties ',
      NpropperTimeMAX)
if ScaleProperties:
    QuantityTakeroot = np.full(NpropperTimeMAX, 1, dtype=np.int)
    if Hydrology:
        QuantityTakeroot[27] = 3
        QuantityTakeroot[32] = 3
    if CDSpecial:
        if RootCasesDeaths:
            print(' Cases and Deaths Square-rooted')
            QuantityTakeroot[NpropperTimeStatic] = 2
            QuantityTakeroot[NpropperTimeStatic + 1] = 2
        else:
            print(' Cases and Deaths NOT Square-rooted')

    # Scale data by roots if requested
    for iprop in range(0, NpropperTimeMAX):
        if QuantityTakeroot[iprop] >= 2:
            if iprop < NpropperTimeStatic:
                for iloc in range(0, Nloc):
                    BasicInputStaticProps[iloc, iprop] = SetTakeroot(BasicInputStaticProps[iloc, iprop],
                                                                     QuantityTakeroot[iprop])
            elif iprop < NpropperTime:
                for itime in range(0, NumberofTimeunits):
                    for iloc in range(0, Nloc):
                        DynamicPropertyTimeSeries[itime, iloc, iprop - NpropperTimeStatic] = SetTakeroot(
                            DynamicPropertyTimeSeries[itime, iloc, iprop - NpropperTimeStatic], QuantityTakeroot[iprop])
            else:
                for itime in range(0, NumberofTimeunits):
                    for iloc in range(0, Nloc):
                        CalculatedTimeSeries[itime, iloc, iprop - NpropperTime] = SetTakeroot(
                            CalculatedTimeSeries[itime, iloc, iprop - NpropperTime], QuantityTakeroot[iprop])

    QuantityStatisticsNames = ['Min', 'Max', 'Norm', 'Mean', 'Std', 'Normed Mean', 'Normed Std']
    QuantityStatistics = np.zeros([NpropperTimeMAX, 7], dtype=np.float32)
    if NpropperTimeStatic > 0:
        print(BasicInputStaticProps.shape)
        max_value = np.amax(BasicInputStaticProps, axis=0)
        min_value = np.amin(BasicInputStaticProps, axis=0)
        mean_value = np.mean(BasicInputStaticProps, axis=0)
        std_value = np.std(BasicInputStaticProps, axis=0)
        normval = np.reciprocal(np.subtract(max_value, min_value))
        normed_mean = np.multiply(normval, np.subtract(mean_value, min_value))
        normed_std = np.multiply(normval, std_value)
        QuantityStatistics[0:NpropperTimeStatic, 0] = min_value
        QuantityStatistics[0:NpropperTimeStatic, 1] = max_value
        QuantityStatistics[0:NpropperTimeStatic, 2] = normval
        QuantityStatistics[0:NpropperTimeStatic, 3] = mean_value
        QuantityStatistics[0:NpropperTimeStatic, 4] = std_value
        QuantityStatistics[0:NpropperTimeStatic, 5] = normed_mean
        QuantityStatistics[0:NpropperTimeStatic, 6] = normed_std

        NormedInputStaticProps = np.empty_like(BasicInputStaticProps)
        for iloc in range(0, Nloc):
            NormedInputStaticProps[iloc, :] = np.multiply((BasicInputStaticProps[iloc, :] - min_value[:]), normval[:])

    if (NpropperTimeDynamic > 0) or (NumTimeSeriesCalculated > 0):
        for iprop in range(NpropperTimeStatic, NpropperTimeStatic + NpropperTimeDynamic):
            QuantityStatistics[iprop, :] = DynamicPropertyScaling(
                DynamicPropertyTimeSeries[:, :, iprop - NpropperTimeStatic])
        for iprop in range(0, NumTimeSeriesCalculated):
            QuantityStatistics[iprop + NpropperTime, :] = DynamicPropertyScaling(CalculatedTimeSeries[:, :, iprop])

        NormedDynamicPropertyTimeSeries = np.empty_like(DynamicPropertyTimeSeries)
        for iprop in range(NpropperTimeStatic, NpropperTimeStatic + NpropperTimeDynamic):
            NormedDynamicPropertyTimeSeries[:, :, iprop - NpropperTimeStatic] = np.multiply(
                (DynamicPropertyTimeSeries[:, :, iprop - NpropperTimeStatic]
                 - QuantityStatistics[iprop, 0]), QuantityStatistics[iprop, 2])

        if NumTimeSeriesCalculated > 0:
            NormedCalculatedTimeSeries = np.empty_like(CalculatedTimeSeries)
            for iprop in range(NpropperTime, NpropperTimeMAX):
                NormedCalculatedTimeSeries[:, :, iprop - NpropperTime] = np.multiply(
                    (CalculatedTimeSeries[:, :, iprop - NpropperTime]
                     - QuantityStatistics[iprop, 0]), QuantityStatistics[iprop, 2])
            CalculatedTimeSeries = None

        BasicInputStaticProps = None
        DynamicPropertyTimeSeries = None
        print(startbold + "Properties scaled" + resetfonts)

    line = 'Name   '
    for propval in range(0, 7):
        line += QuantityStatisticsNames[propval] + '    '
    print('\n' + startbold + startpurple + line + resetfonts)
    for iprop in range(0, NpropperTimeMAX):
        if iprop == NpropperTimeStatic:
            print('\n')
        line = startbold + startpurple + str(iprop) + ' ' + InputPropertyNames[iprop] + resetfonts + ' Root ' + str(
            QuantityTakeroot[iprop])
        for propval in range(0, 7):
            line += ' ' + str(round(QuantityStatistics[iprop, propval], 3))
        print(line)

"""###Set up Futures 

-- currently at unit time level 
"""


class Future:
    def __init__(self, name, daystart=0, days=[], wgt=1.0, classweight=1.0):
        self.name = name
        self.days = np.array(days)
        self.daystart = daystart
        self.wgts = np.full_like(self.days, wgt, dtype=float)
        self.size = len(self.days)
        self.classweight = classweight


LengthFutures = 0
Unit = "Day"
if Earthquake:
    Unit = "2wk"
if GenerateFutures:

    Futures = []
    daylimit = 14
    if Earthquake:
        daylimit = 25
    for ifuture in range(0, daylimit):
        xx = Future(Unit + 'x' + str(ifuture + 2), days=[ifuture + 2])
        Futures.append(xx)
    LengthFutures = len(Futures)
    Futuresmaxday = 0
    Futuresmaxweek = 0
    for i in range(0, LengthFutures):
        j = len(Futures[i].days)
        if j == 1:
            Futuresmaxday = max(Futuresmaxday, Futures[i].days[0])
        else:
            Futuresmaxweek = max(Futuresmaxweek, Futures[i].days[j - 1])
        Futures[i].daystart -= Dropearlydata
        if Futures[i].daystart < 0: Futures[i].daystart = 0
        if Earthquake:
            Futures[i].daystart = 0

"""###Set up mappings of locations

In next cell, we map locations for BEFORE location etc added

In cell after that we do same for sequences
"""

OriginalNloc = Nloc
if Earthquake:
    MapLocation = True

    MappedDynamicPropertyTimeSeries = np.empty([Num_Time, MappedNloc, NpropperTimeDynamic], dtype=np.float32)
    MappedNormedInputStaticProps = np.empty([MappedNloc, NpropperTimeStatic], dtype=np.float32)
    MappedCalculatedTimeSeries = np.empty([Num_Time, MappedNloc, NumTimeSeriesCalculated], dtype=np.float32)

    print(LookupLocations)
    MappedDynamicPropertyTimeSeries[:, :, :] = NormedDynamicPropertyTimeSeries[:, LookupLocations, :]
    NormedDynamicPropertyTimeSeries = None
    NormedDynamicPropertyTimeSeries = MappedDynamicPropertyTimeSeries

    MappedCalculatedTimeSeries[:, :, :] = NormedCalculatedTimeSeries[:, LookupLocations, :]
    NormedCalculatedTimeSeries = None
    NormedCalculatedTimeSeries = MappedCalculatedTimeSeries

    MappedNormedInputStaticProps[:, :] = NormedInputStaticProps[LookupLocations, :]
    NormedInputStaticProps = None
    NormedInputStaticProps = MappedNormedInputStaticProps

    Nloc = MappedNloc
    if GarbageCollect:
        gc.collect()
    print('Number of locations reduced to ' + str(Nloc))

else:
    MappedLocations = np.arange(0, Nloc, dtype=np.int)
    LookupLocations = np.arange(0, Nloc, dtype=np.int)
    MappedNloc = Nloc

"""###Property and Prediction  Data Structures

Two important Lists Properties and Predictions that are related

 * Data stored in series is for properties, the calculated value occuring at or ending that day
 * For predictions, the data is the calculated value from that date or later. 

 * We store data labelled by time so that
  * for inputs we use time 0 upto last value - 1 i.e. position [length of array - 1]
  * for outputs (predictions) with sequence Tseq, we use array locations [Tseq] to [length of array -1]
  * This implies Num_Seq = Num_Time - Tseq


**Properties**

Everything appears in Property list -- both input and output (predicted)
DynamicPropertyTimeSeries holds input property time series where value is value at that time using data before this time for aggregations
  * NpropperTimeStatic is the number of static properties -- typically read in or calculated from input information
  * NpropperTimeDynamicInput is total number of input time series
  * NpropperTimeDynamicCalculated is total number of calculated dynamic quantities  used in Time series analysis as input properties and/or output predictions
  * NpropperTimeDynamic = NpropperTimeDynamicInput + NpropperTimeDynamicCalculated ONLY includes input properties
  * NpropperTime = NpropperTimeStatic + NpropperTimeDynamic will not include futures and NOT include calculated predictions
  * InputPropertyNames is a list of size NpropperTime holding names
  * NpropperTimeMAX = NpropperTime + NumTimeSeriesCalculated has calculated predictions following input properties ignoring futures 
  * QuantityStatistics has 7 statistics used in normalizing for NpropperTimeMAX properties
  * Normalization takes NpropperTimeStatic static features in BasicInputStaticProps and stores in NormedInputStaticProps
  * Normalization takes NpropperTimeDynamicInput dynamic features in BasicInputTimeSeries and stores in NormedInputTimeSeries
  * Normalization takes NpropperTimeDynamicCalculated dynamic features in DynamicPropertyTimeSeries and stores in NormedDynamicPropertyTimeSeries

**Predictions**

 * NumpredbasicperTime can be 1 upto NpropperTimeDynamic and are part of dynamic input series. It includes input values that are to be predicted (these MUST be at start) plus NumTimeSeriesCalculated calculated series
 * NumpredFuturedperTime is <= NumpredbasicperTime and is the number of input dynamic series that are futured
 * NumTimeSeriesCalculated is number of calculated (not as futures) time series stored in CalculatedTimeSeries and names in NamespredCalculated
 * Typically NumpredbasicperTime = NumTimeSeriesCalculated + NumpredFuturedperTime (**Currently this is assumed**)
 * Normalization takes NumTimeSeriesCalculated calculated series in CalculatedTimeSeries and stores in NormedCalculatedTimeSeries
 * Predictions per Time are  NpredperTime = NumpredbasicperTime + NumpredFuturedperTime*LengthFutures
 * Predictions per sequence Npredperseq = NpredperTime

### Set Requested Properties Predictions Encodings
"""

# FuturePred = -1 Means NO FUTURE >= 0 FUTURED
# BASIC EARTHQUAKE SET JUST LOG ENERGY AND MULTIPLICITY
if Earthquake:
    InputSource = ['Static', 'Static', 'Static', 'Static', 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic'
        , 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic']
    InputSourceNumber = [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8]
    if addRundleEMA > 0:
        InputSource += ['Dynamic'] * addRundleEMA
        for i in range(0, addRundleEMA):
            InputSourceNumber += [15 + i]

    PredSource = ['Dynamic', 'Calc', 'Calc', 'Calc', 'Calc', 'Calc', 'Calc', 'Calc', 'Calc', 'Calc']
    PredSourceNumber = [0, 0, 1, 2, 3, 4, 5, 6, 7, 8]
    if addRundleEMA > 0:
        PredSource += ['Calc'] * addRundleEMA
        for i in range(0, addRundleEMA):
            PredSourceNumber += [19 + i]

    FuturedPred = [-1] * len(PredSource)

    # Earthquake Space-Time
    SpaceTimeEncodingPropTypes = ['Spatial', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'BottomUp', 'BottomUp',
                                  'BottomUp', 'BottomUp']
    SpaceTimeEncodingPropValues = [0, 0, 1, 2, 3, 4, 8, 16, 32, 64]

    SpaceTimeEncodingPredTypes = ['Spatial', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'BottomUp', 'BottomUp',
                                  'BottomUp', 'BottomUp']
    SpaceTimeEncodingPredValues = [0, 0, 1, 2, 3, 4, 8, 16, 32, 64]

    if UseTFTModel:
        InputSource = ['Static', 'Static', 'Static', 'Static', 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic'
            , 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic', 'Dynamic']
        InputSourceNumber = [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8]

        PredSource = ['Dynamic', 'Dynamic']
        PredSourceNumber = [0, 7]
        FuturedPred = [1, 1]

        SpaceTimeEncodingPredTypes = []
        SpaceTimeEncodingPredValues = []

        # TFT2 1 year
        PredSource = ['Dynamic', 'Dynamic', 'Dynamic', 'Dynamic']
        PredSourceNumber = [0, 6, 7, 8]
        FuturedPred = [1, 1, 1, 1]

# Hydrology
# Last Dynamic Variable predicted but not input as has undefined variables
if Hydrology:
    InputSource = ['Static'] * 27 + ['Dynamic'] * 5
    InputSourceNumber = list(range(0, 27)) + list(range(0, 5))

    PredSource = ['Dynamic'] * 6
    PredSourceNumber = list(range(0, 6))
    FuturedPred = [-1] * len(PredSource)

    # Hydrology Space-Time
    SpaceTimeEncodingPropTypes = ['Annual', 'TopDown', 'Spatial']
    SpaceTimeEncodingPropValues = [0, 1, 0]

    SpaceTimeEncodingPredTypes = ['Annual', 'TopDown', 'Spatial']
    SpaceTimeEncodingPredValues = [0, 1, 0]

# Recent Covid Default
if ReadApril2021Covid:
    if ReadNov2021Covid:
        InputSource = ['Dynamic'] * 16
        InputSourceNumber = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
    elif ReadMay2022Covid:
        if Read7dayCovid:
            InputSource = ['Dynamic'] * 8  # NOT voting read in
            InputSourceNumber = [0, 1, 2, 3, 4, 5, 6, 7]
        else:
            InputSource = ['Dynamic'] * 17
            InputSourceNumber = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
    else:
        InputSource = ['Dynamic'] * 15
        InputSourceNumber = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]

    if RunName == 'Covid7day22-LSTM8':  # DONT PREDICT DEATHS
        PredSource = ['Dynamic']
        PredSourceNumber = [0]
        FuturedPred = [1]
    else:
        PredSource = ['Dynamic', 'Dynamic']
        PredSourceNumber = [0, 1]
        FuturedPred = [1, 1]

    # Encodings
    SpaceTimeEncodingPropTypes = ['Spatial', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'Weekly']
    SpaceTimeEncodingPropValues = [0, 0, 1, 2, 3, 4, 0]

    SpaceTimeEncodingPredTypes = Types = ['Spatial', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'TopDown', 'Weekly']
    SpaceTimeEncodingPredValues = [0, 0, 1, 2, 3, 4, 0]

    if RunName == 'Covid7day22-LSTM4R':
        SpaceTimeEncodingPropTypes = ['Spatial', 'Weekly']
        SpaceTimeEncodingPropValues = [0, 0]

        SpaceTimeEncodingPredTypes = Types = ['Spatial', 'Weekly']
        SpaceTimeEncodingPredValues = [0, 0]

    if UseTFTModel:
        SpaceTimeEncodingPredTypes = []
        SpaceTimeEncodingPredValues = []

"""### Choose Input and Predicted Quantities"""

if len(InputSource) != len(InputSourceNumber):
    printexit(' Inconsistent Source Lengths ' + str(len(InputSource)) + ' ' + str(len(InputSourceNumber)))
if len(PredSource) != len(PredSourceNumber):
    printexit(' Inconsistent Prediction Lengths ' + str(len(PredSource)) + ' ' + str(len(PredSourceNumber)))

# Executed by all even if GenerateFutures false except for direct Romeo data
if (not ReadJuly2020Covid) and not (ReadJan2021Covid) and not (ReadApril2021Covid):
    if not UseFutures:
        LengthFutures = 0
    print(startbold + "Number of Futures -- separate for each regular prediction " + str(LengthFutures) + resetfonts)
    Usedaystart = False

if len(PredSource) > 0:  # set up Predictions
    NumpredbasicperTime = len(PredSource)
    FuturedPointer = np.full(NumpredbasicperTime, -1, dtype=np.int)
    NumpredFuturedperTime = 0
    NumpredfromInputsperTime = 0
    for ipred in range(0, len(PredSource)):
        if PredSource[ipred] == 'Dynamic':
            NumpredfromInputsperTime += 1
    countinputs = 0
    countcalcs = 0
    for ipred in range(0, len(PredSource)):
        if not (PredSource[ipred] == 'Dynamic' or PredSource[ipred] == 'Calc'):
            printexit('Illegal Prediction ' + str(ipred) + ' ' + PredSource[ipred])
        if PredSource[ipred] == 'Dynamic':
            countinputs += 1
        else:
            countcalcs += 1
        if FuturedPred[ipred] >= 0:
            if LengthFutures > 0:
                FuturedPred[ipred] = NumpredFuturedperTime
                FuturedPointer[ipred] = NumpredFuturedperTime
                NumpredFuturedperTime += 1
            else:
                FuturedPred[ipred] = -1

else:  # Set defaults
    NumpredfromInputsperTime = NumpredFuturedperTime
    FuturedPointer = np.full(NumpredbasicperTime, -1, dtype=np.int)
    PredSource = []
    PredSourceNumber = []
    FuturedPred = []
    futurepos = 0
    for ipred in range(0, NumpredFuturedperTime):
        PredSource.append('Dynamic')
        PredSourceNumber.append(ipred)
        futured = -1
        if LengthFutures > 0:
            futured = futurepos
            FuturedPointer[ipred] = futurepos
            futurepos += 1
        FuturedPred.append(futured)
    for ipred in range(0, NumTimeSeriesCalculated):
        PredSource.append('Calc')
        PredSourceNumber.append(ipred)
        FuturedPred.append(-1)
    print('Number of Predictions ' + str(len(PredSource)))

PropertyNameIndex = np.empty(NpropperTime, dtype=np.int32)
PropertyAverageValuesPointer = np.empty(NpropperTime, dtype=np.int32)
for iprop in range(0, NpropperTime):
    PropertyNameIndex[iprop] = iprop  # names
    PropertyAverageValuesPointer[iprop] = iprop  # normalizations

# Reset Source -- if OK as read don't set InputSource InputSourceNumber
# Reset NormedDynamicPropertyTimeSeries and NormedInputStaticProps
# Reset NpropperTime = NpropperTimeStatic + NpropperTimeDynamic
if len(InputSource) > 0:  # Reset Input Source
    NewNpropperTimeStatic = 0
    NewNpropperTimeDynamic = 0
    for isource in range(0, len(InputSource)):
        if InputSource[isource] == 'Static':
            NewNpropperTimeStatic += 1
        if InputSource[isource] == 'Dynamic':
            NewNpropperTimeDynamic += 1
    NewNormedDynamicPropertyTimeSeries = np.empty([Num_Time, Nloc, NewNpropperTimeDynamic], dtype=np.float32)
    NewNormedInputStaticProps = np.empty([Nloc, NewNpropperTimeStatic], dtype=np.float32)
    NewNpropperTime = NewNpropperTimeStatic + NewNpropperTimeDynamic
    NewPropertyNameIndex = np.empty(NewNpropperTime, dtype=np.int32)
    NewPropertyAverageValuesPointer = np.empty(NewNpropperTime, dtype=np.int32)
    countstatic = 0
    countdynamic = 0
    for isource in range(0, len(InputSource)):
        if InputSource[isource] == 'Static':
            OldstaticNumber = InputSourceNumber[isource]
            NewNormedInputStaticProps[:, countstatic] = NormedInputStaticProps[:, OldstaticNumber]
            NewPropertyNameIndex[countstatic] = PropertyNameIndex[OldstaticNumber]
            NewPropertyAverageValuesPointer[countstatic] = PropertyAverageValuesPointer[OldstaticNumber]
            countstatic += 1

        elif InputSource[isource] == 'Dynamic':
            OlddynamicNumber = InputSourceNumber[isource]
            NewNormedDynamicPropertyTimeSeries[:, :, countdynamic] = NormedDynamicPropertyTimeSeries[:, :, OlddynamicNumber]
            NewPropertyNameIndex[countdynamic + NewNpropperTimeStatic] = PropertyNameIndex[
                OlddynamicNumber + NpropperTimeStatic]
            NewPropertyAverageValuesPointer[countdynamic + NewNpropperTimeStatic] = PropertyAverageValuesPointer[
                OlddynamicNumber + NpropperTimeStatic]
            countdynamic += 1

        else:
            printexit('Illegal Property ' + str(isource) + ' ' + InputSource[isource])

else:  # pretend data altered
    NewPropertyNameIndex = PropertyNameIndex
    NewPropertyAverageValuesPointer = PropertyAverageValuesPointer
    NewNpropperTime = NpropperTime
    NewNpropperTimeStatic = NpropperTimeStatic
    NewNpropperTimeDynamic = NpropperTimeDynamic

    NewNormedInputStaticProps = NormedInputStaticProps
    NewNormedDynamicPropertyTimeSeries = NormedDynamicPropertyTimeSeries

"""###Calculate Futures

Start Predictions
"""

# Order of Predictions *****************************
# Basic "futured" Predictions from property dynamic arrays
# Additional predictions without futures and NOT in property arrays including Calculated time series
# LengthFutures predictions for first NumpredFuturedperTime predictions
# Special predictions (temporal, positional) added later
NpredperTime = NumpredbasicperTime + NumpredFuturedperTime * LengthFutures
Npredperseq = NpredperTime
Predictionbasicname = [' '] * NumpredbasicperTime
for ipred in range(0, NumpredbasicperTime):
    if PredSource[ipred] == 'Dynamic':
        Predictionbasicname[ipred] = InputPropertyNames[PredSourceNumber[ipred] + NpropperTimeStatic]
    else:
        Predictionbasicname[ipred] = NamespredCalculated[PredSourceNumber[ipred]]

TotalFutures = 0
if NumpredFuturedperTime <= 0:
    GenerateFutures = False
if GenerateFutures:
    TotalFutures = NumpredFuturedperTime * LengthFutures
print(startbold + 'Predictions Total ' + str(Npredperseq) + ' Basic ' + str(NumpredbasicperTime) + ' Of which futured are '
      + str(NumpredFuturedperTime) + ' Giving number explicit futures ' + str(TotalFutures) + resetfonts)
Predictionname = [' '] * Npredperseq
Predictionnametype = [' '] * Npredperseq
Predictionoldvalue = np.empty(Npredperseq, dtype=int)
Predictionnewvalue = np.empty(Npredperseq, dtype=int)
Predictionday = np.empty(Npredperseq, dtype=int)
PredictionAverageValuesPointer = np.empty(Npredperseq, dtype=int)
Predictionwgt = [1.0] * Npredperseq
for ipred in range(0, NumpredbasicperTime):
    Predictionnametype[ipred] = PredSource[ipred]
    Predictionoldvalue[ipred] = PredSourceNumber[ipred]
    Predictionnewvalue[ipred] = ipred
    if PredSource[ipred] == 'Dynamic':
        PredictionAverageValuesPointer[ipred] = NpropperTimeStatic + Predictionoldvalue[ipred]
    else:
        PredictionAverageValuesPointer[ipred] = NpropperTime + PredSourceNumber[ipred]
    Predictionwgt[ipred] = 1.0
    Predictionday[ipred] = 1
    extrastring = ''
    Predictionname[ipred] = 'Next ' + Predictionbasicname[ipred]
    if FuturedPred[ipred] >= 0:
        extrastring = ' Explicit Futures Added '
    print(str(ipred) + ' Internal Property # ' + str(PredictionAverageValuesPointer[ipred]) + ' ' + Predictionname[ipred]
          + ' Weight ' + str(round(Predictionwgt[ipred], 3)) + ' Day ' + str(Predictionday[ipred]) + extrastring)

for ifuture in range(0, LengthFutures):
    for ipred in range(0, NumpredbasicperTime):
        if FuturedPred[ipred] >= 0:
            FuturedPosition = NumpredbasicperTime + NumpredFuturedperTime * ifuture + FuturedPred[ipred]
            Predictionname[FuturedPosition] = Predictionbasicname[ipred] + ' ' + Futures[ifuture].name
            Predictionday[FuturedPosition] = Futures[ifuture].days[0]
            Predictionwgt[FuturedPosition] = Futures[ifuture].classweight
            Predictionnametype[FuturedPosition] = Predictionnametype[ipred]
            Predictionoldvalue[FuturedPosition] = Predictionoldvalue[ipred]
            Predictionnewvalue[FuturedPosition] = Predictionnewvalue[ipred]
            PredictionAverageValuesPointer[FuturedPosition] = PredictionAverageValuesPointer[ipred]
            print(str(iprop) + ' Internal Property # ' + str(PredictionAverageValuesPointer[FuturedPosition]) + ' ' +
                  Predictionname[FuturedPosition] + ' Weight ' + str(round(Predictionwgt[FuturedPosition], 3))
                  + ' Day ' + str(Predictionday[FuturedPosition]) + ' This is Explicit Future ')

Predictionnamelookup = {}
print(startbold + '\nBasic Predicted Quantities' + resetfonts)
for ipred in range(0, Npredperseq):
    Predictionnamelookup[Predictionname[ipred]] = ipred

    iprop = Predictionnewvalue[ipred]
    line = startbold + startred + Predictionbasicname[iprop]
    line += ' Weight ' + str(round(Predictionwgt[ipred], 4))
    if (iprop < NumpredFuturedperTime) or (iprop >= NumpredbasicperTime):
        line += ' Day= ' + str(Predictionday[ipred])
        line += ' Name ' + Predictionname[ipred]
    line += resetfonts
    jpred = PredictionAverageValuesPointer[ipred]
    line += ' Processing Root ' + str(QuantityTakeroot[jpred])
    for proppredval in range(0, 7):
        line += ' ' + QuantityStatisticsNames[proppredval] + ' ' + str(round(QuantityStatistics[jpred, proppredval], 3))
    print(wraptotext(line, size=150))

    print(line)

    # Note that only Predictionwgt and Predictionname defined for later addons

"""### Set up Predictions 

first for time arrays; we will extend to sequences next. Sequences include the predictions for final time in sequence.

This is prediction for sequence ending one day before the labelling time index. So sequence must end one unit before last time value

Note this is  "pure forecast" which are of quantities used in driving data allowing us to iitialize prediction to input

NaN represents non existent data
"""

if PredictionsfromInputs:
    InputPredictionsbyTime = np.zeros([Num_Time, Nloc, Npredperseq], dtype=np.float32)
    for ipred in range(0, NumpredbasicperTime):
        if Predictionnametype[ipred] == 'Dynamic':
            InputPredictionsbyTime[:, :, ipred] = NormedDynamicPropertyTimeSeries[:, :, Predictionoldvalue[ipred]]
        else:
            InputPredictionsbyTime[:, :, ipred] = NormedCalculatedTimeSeries[:, :, Predictionoldvalue[ipred]]

    # Add Futures based on Futured properties
    if LengthFutures > 0:
        NaNall = np.full([Nloc], NaN, dtype=np.float32)
        daystartveto = 0
        atendveto = 0
        allok = NumpredbasicperTime
        for ifuture in range(0, LengthFutures):
            for itime in range(0, Num_Time):
                ActualTime = itime + Futures[ifuture].days[0] - 1
                if ActualTime >= Num_Time:
                    for ipred in range(0, NumpredbasicperTime):
                        Putithere = FuturedPred[ipred]
                        if Putithere >= 0:
                            InputPredictionsbyTime[itime, :,
                            NumpredbasicperTime + NumpredFuturedperTime * ifuture + Putithere] = NaNall
                    atendveto += 1
                elif Usedaystart and (itime < Futures[ifuture].daystart):
                    for ipred in range(0, NumpredbasicperTime):
                        Putithere = FuturedPred[ipred]
                        if Putithere >= 0:
                            InputPredictionsbyTime[itime, :,
                            NumpredbasicperTime + NumpredFuturedperTime * ifuture + Putithere] = NaNall
                    daystartveto += 1
                else:
                    for ipred in range(0, NumpredbasicperTime):
                        Putithere = FuturedPred[ipred]
                        if Putithere >= 0:
                            if Predictionnametype[ipred] == 'Dynamic':
                                InputPredictionsbyTime[itime, :,
                                NumpredbasicperTime + NumpredFuturedperTime * ifuture + Putithere] \
                                    = NormedDynamicPropertyTimeSeries[ActualTime, :, Predictionoldvalue[ipred]]
                            else:
                                InputPredictionsbyTime[itime, :,
                                NumpredbasicperTime + NumpredFuturedperTime * ifuture + Putithere] \
                                    = NormedCalculatedTimeSeries[ActualTime, :, Predictionoldvalue[ipred]]
                    allok += NumpredFuturedperTime
        print(startbold + 'Futures Added: Predictions set from inputs OK ' + str(allok) +
              ' Veto at end ' + str(atendveto) + ' Veto at start ' + str(
            daystartveto) + ' Times number of locations' + resetfonts)

"""### Clean-up Input quantities#################"""


def checkNaN(y):
    countNaN = 0
    countnotNaN = 0
    ctprt = 0
    if y is None:
        return
    if len(y.shape) == 2:
        for i in range(0, y.shape[0]):
            for j in range(0, y.shape[1]):
                if (np.math.isnan(y[i, j])):
                    countNaN += 1
                else:
                    countnotNaN += 1
    else:
        for i in range(0, y.shape[0]):
            for j in range(0, y.shape[1]):
                for k in range(0, y.shape[2]):
                    if (np.math.isnan(y[i, j, k])):
                        countNaN += 1
                        ctprt += 1
                        if ctprt <= 10:
                            print('NaN Data ' + str(i) + ' ' + str(j) + ' ' + str(k))
                    else:
                        countnotNaN += 1

    percent = (100.0 * countNaN) / (countNaN + countnotNaN)
    print(' is NaN ', str(countNaN), ' percent ', str(round(percent, 2)), ' not NaN ', str(countnotNaN))


# Clean-up Input Source
if len(InputSource) > 0:
    PropertyNameIndex = NewPropertyNameIndex
    NewPropertyNameIndex = None
    PropertyAverageValuesPointer = NewPropertyAverageValuesPointer
    NewPropertyAverageValuesPointer = None

    NormedInputStaticProps = NewNormedInputStaticProps
    NewNormedInputStaticProps = None
    NormedDynamicPropertyTimeSeries = NewNormedDynamicPropertyTimeSeries
    NewNormedDynamicPropertyTimeSeries = None

    NpropperTime = NewNpropperTime
    NpropperTimeStatic = NewNpropperTimeStatic
    NpropperTimeDynamic = NewNpropperTimeDynamic

print('Static Properties')
if NpropperTimeStatic > 0:
    checkNaN(NormedInputStaticProps)
else:
    print(' None Defined')
print('Dynamic Properties')

checkNaN(NormedDynamicPropertyTimeSeries)

"""###Covid Data: Agree on Tseq Sequence Length"""

if ReadAugust2020Covid or RereadMay2020:
    Tseq = 9
if ReadJan2021Covid or ReadAugust2020Covid or ReadApril2021Covid:
    Tseq = 13
print(Tseq)
print(SymbolicWindows)

"""###Setup Sequences and Choose model"""

Num_SeqExtraUsed = Tseq - 1
Num_Seq = Num_Time - Tseq
Num_SeqPred = Num_Seq
TseqPred = Tseq
TFTExtraTimes = 0
Num_TimeTFT = Num_Time
if UseTFTModel:
    TFTExtraTimes = 1 + LengthFutures
    SymbolicWindows = True
    Num_SeqExtraUsed = Tseq  # as last position needed in input
    Num_TimeTFT = Num_Time + TFTExtraTimes
    Num_SeqPred = Num_Seq
    TseqPred = Tseq

# If SymbolicWindows, sequences are not made but we use same array with that dimension (RawInputSeqDimension) set to 1
# reshape can get rid of this irrelevant dimension
# Predictions and Input Properties are associated with sequence number which is first time value used in sequence
# if SymbolicWindows false then sequences are labelled by sequence # and contain time values from sequence # to sequence# + Tseq-1
# if SymbolicWindows True then sequences are labelled by time # and contain one value. They are displaced by Tseq
# If TFT Inputs and Predictions do NOT differ by Tseq
# Num_SeqExtra extra positions in RawInputSequencesTOT for Symbolic windows True as need to store full window
# TFTExtraTimes are extra times
RawInputSeqDimension = Tseq
Num_SeqExtra = 0
if SymbolicWindows:
    RawInputSeqDimension = 1
    Num_SeqExtra = Num_SeqExtraUsed
print('Tseq ' + str(Tseq) + ' TseqPred ' + str(TseqPred))

"""###Generate Sequences from Time labelled data 
given Tseq set above
"""

if GenerateSequences:
    UseProperties = np.full(NpropperTime, True, dtype=np.bool)
    #  if Hydrology:
    #    UseProperties[NpropperTime-1] = False
    Npropperseq = 0
    IndexintoPropertyArrays = np.empty(NpropperTime, dtype=np.int)
    for iprop in range(0, NpropperTime):
        if UseProperties[iprop]:
            IndexintoPropertyArrays[Npropperseq] = iprop
            Npropperseq += 1
    RawInputSequences = np.zeros([Num_Seq + Num_SeqExtra, Nloc, RawInputSeqDimension, Npropperseq], dtype=np.float32)
    RawInputPredictions = np.zeros([Num_SeqPred, Nloc, Npredperseq], dtype=np.float32)

    locationarray = np.empty(Nloc, dtype=np.float32)
    for iseq in range(0, Num_Seq + Num_SeqExtra):
        for windowposition in range(0, RawInputSeqDimension):
            itime = iseq + windowposition
            for usedproperty in range(0, Npropperseq):
                iprop = IndexintoPropertyArrays[usedproperty]
                if iprop >= NpropperTimeStatic:
                    jprop = iprop - NpropperTimeStatic
                    locationarray = NormedDynamicPropertyTimeSeries[itime, :, jprop]
                else:
                    locationarray = NormedInputStaticProps[:, iprop]
                RawInputSequences[iseq, :, windowposition, usedproperty] = locationarray
        if iseq < Num_SeqPred:
            RawInputPredictions[iseq, :, :] = InputPredictionsbyTime[iseq + TseqPred, :, :]
    print(startbold + 'Sequences set from Time values Num Seq ' + str(Num_SeqPred) + ' Time ' + str(
        Num_Time) + ' Tseq ' + str(Tseq) + resetfonts)

NormedInputTimeSeries = None
NormedDynamicPropertyTimeSeries = None
if GarbageCollect:
    gc.collect()

GlobalTimeMask = np.empty([1, 1, 1, Tseq, Tseq], dtype=np.float32)

"""### Define Possible Temporal and Spatial Positional Encodings"""


def LinearLocationEncoding(TotalLoc):
    linear = np.empty(TotalLoc, dtype=float)
    for i in range(0, TotalLoc):
        linear[i] = float(i) / float(TotalLoc)
    return linear


def LinearTimeEncoding(Dateslisted):
    Firstdate = Dateslisted[0]
    numtofind = len(Dateslisted)
    dayrange = (Dateslisted[numtofind - 1] - Firstdate).days + 1
    linear = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        linear[i] = float((Dateslisted[i] - Firstdate).days) / float(dayrange)
    return linear


def P2TimeEncoding(numtofind):
    P2 = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        x = -1 + 2.0 * i / (numtofind - 1)
        P2[i] = 0.5 * (3 * x * x - 1)
    return P2


def P3TimeEncoding(numtofind):
    P3 = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        x = -1 + 2.0 * i / (numtofind - 1)
        P3[i] = 0.5 * (5 * x * x - 3) * x
    return P3


def P4TimeEncoding(numtofind):
    P4 = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        x = -1 + 2.0 * i / (numtofind - 1)
        P4[i] = 0.125 * (35 * x * x * x * x - 30 * x * x + 3)
    return P4


def WeeklyTimeEncoding(Dateslisted):
    numtofind = len(Dateslisted)
    costheta = np.empty(numtofind, dtype=float)
    sintheta = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        j = Dateslisted[i].date().weekday()
        theta = float(j) * 2.0 * math.pi / 7.0
        costheta[i] = math.cos(theta)
        sintheta[i] = math.sin(theta)
    return costheta, sintheta


def AnnualTimeEncoding(Dateslisted):
    numtofind = len(Dateslisted)
    costheta = np.empty(numtofind, dtype=float)
    sintheta = np.empty(numtofind, dtype=float)
    for i in range(0, numtofind):
        runningdate = Dateslisted[i]
        year = runningdate.year
        datebeginyear = datetime(year, 1, 1)
        displacement = (runningdate - datebeginyear).days
        daysinyear = (datetime(year, 12, 31) - datebeginyear).days + 1
        if displacement >= daysinyear:
            printexit("EXIT Bad Date ", runningdate)
        theta = float(displacement) * 2.0 * math.pi / float(daysinyear)
        costheta[i] = math.cos(theta)
        sintheta[i] = math.sin(theta)
    return costheta, sintheta


def ReturnEncoding(numtofind, Typeindex, Typevalue):
    Dummy = costheta = np.empty(0, dtype=float)
    if Typeindex == 1:
        return LinearoverLocationEncoding, Dummy, ('LinearSpace', 0., 1.0, 0.5, 0.2887), ('Dummy', 0., 0., 0., 0.)
    if Typeindex == 2:
        if Dailyunit == 1:
            return CosWeeklytimeEncoding, SinWeeklytimeEncoding, ('CosWeekly', -1.0, 1.0, 0., 0.7071), (
            'SinWeekly', -1.0, 1.0, 0., 0.7071)
        else:
            return Dummy, Dummy, ('Dummy', 0., 0., 0., 0.), ('Dummy', 0., 0., 0., 0.)
    if Typeindex == 3:
        return CosAnnualtimeEncoding, SinAnnualtimeEncoding, ('CosAnnual', -1.0, 1.0, 0., 0.7071), (
        'SinAnnual', -1.0, 1.0, 0., 0.7071)
    if Typeindex == 4:
        if Typevalue == 0:
            ConstArray = np.full(numtofind, 0.5, dtype=float)
            return ConstArray, Dummy, ('Constant', 0.5, 0.5, 0.5, 0.0), ('Dummy', 0., 0., 0., 0.)
        if Typevalue == 1:
            return LinearovertimeEncoding, Dummy, ('LinearTime', 0., 1.0, 0.5, 0.2887), ('Dummy', 0., 0., 0., 0.)
        if Typevalue == 2:
            return P2TimeEncoding(numtofind), Dummy, ('P2-Time', -1.0, 1.0, 0., 0.4472), ('Dummy', 0., 0., 0., 0.)
        if Typevalue == 3:
            return P3TimeEncoding(numtofind), Dummy, ('P3-Time', -1.0, 1.0, 0., 0.3780), ('Dummy', 0., 0., 0., 0.)
        if Typevalue == 4:
            return P4TimeEncoding(numtofind), Dummy, ('P4-Time', -1.0, 1.0, 0., 0.3333), ('Dummy', 0., 0., 0., 0.)
    if Typeindex == 5:
        costheta = np.empty(numtofind, dtype=float)
        sintheta = np.empty(numtofind, dtype=float)
        j = 0
        for i in range(0, numtofind):
            theta = float(j) * 2.0 * math.pi / Typevalue
            costheta[i] = math.cos(theta)
            sintheta[i] = math.sin(theta)
            j += 1
            if j >= Typevalue:
                j = 0
        return costheta, sintheta, ('Cos ' + str(Typevalue) + ' Len', -1.0, 1.0, 0., 0.7071), (
        'Sin ' + str(Typevalue) + ' Len', -1.0, 1.0, 0., 0.7071)


# Dates set up in Python datetime format as Python LISTS
# All encodings are Numpy arrays
print("Total number of Time Units " + str(NumberofTimeunits) + ' ' + TimeIntervalUnitName)
if NumberofTimeunits != (Num_Seq + Tseq):
    printexit("EXIT Wrong Number of Time Units " + str(Num_Seq + Tseq))

Dateslist = []
for i in range(0, NumberofTimeunits + TFTExtraTimes):
    Dateslist.append(InitialDate + timedelta(days=i * Dailyunit))

LinearoverLocationEncoding = LinearLocationEncoding(Nloc)
LinearovertimeEncoding = LinearTimeEncoding(Dateslist)

if Dailyunit == 1:
    CosWeeklytimeEncoding, SinWeeklytimeEncoding = WeeklyTimeEncoding(Dateslist)
CosAnnualtimeEncoding, SinAnnualtimeEncoding = AnnualTimeEncoding(Dateslist)

# Encodings

# linearlocationposition
# Supported Time Dependent Probes that can be in properties and/or predictions
# Spatial
# Annual
# Weekly
#
# Top Down
# TD0 Constant at 0.5
# TD1 Linear from 0 to 1
# TD2 P2(x) where x goes from -1 to 1 as time goes from start to end
#
# Bottom Up
# n-way Cos and sin theta where n = 4 7 8 16 24 32

EncodingTypes = {'Spatial': 1, 'Weekly': 2, 'Annual': 3, 'TopDown': 4, 'BottomUp': 5}

PropIndex = []
PropNameMeanStd = []
PropMeanStd = []
PropArray = []
PropPosition = []

PredIndex = []
PredNameMeanStd = []
PredArray = []
PredPosition = []

Numberpropaddons = 0
propposition = Npropperseq
Numberpredaddons = 0
predposition = Npredperseq

numprop = len(SpaceTimeEncodingPropTypes)
if numprop != len(SpaceTimeEncodingPropValues):
    printexit('Error in property addons ' + str(numprop) + ' ' + str(len(SpaceTimeEncodingPropValues)))
for newpropinlist in range(0, numprop):
    Typeindex = EncodingTypes[SpaceTimeEncodingPropTypes[newpropinlist]]
    a, b, c, d = ReturnEncoding(Num_Time + TFTExtraTimes, Typeindex, SpaceTimeEncodingPropValues[newpropinlist])
    if c[0] != 'Dummy':
        PropIndex.append(Typeindex)
        PropNameMeanStd.append(c)
        InputPropertyNames.append(c[0])
        PropArray.append(a)
        PropPosition.append(propposition)
        propposition += 1
        Numberpropaddons += 1
        line = ' '
        for ipr in range(0, 20):
            line += str(round(a[ipr], 4)) + ' '
    #    print('c'+line)
    if d[0] != 'Dummy':
        PropIndex.append(Typeindex)
        PropNameMeanStd.append(d)
        InputPropertyNames.append(d[0])
        PropArray.append(b)
        PropPosition.append(propposition)
        propposition += 1
        Numberpropaddons += 1
        line = ' '
        for ipr in range(0, 20):
            line += str(round(b[ipr], 4)) + ' '
#    print('d'+line)

numpred = len(SpaceTimeEncodingPredTypes)
if numpred != len(SpaceTimeEncodingPredValues):
    printexit('Error in prediction addons ' + str(numpred) + ' ' + str(len(SpaceTimeEncodingPredValues)))
for newpredinlist in range(0, numpred):
    Typeindex = EncodingTypes[SpaceTimeEncodingPredTypes[newpredinlist]]
    a, b, c, d = ReturnEncoding(Num_Time + TFTExtraTimes, Typeindex, SpaceTimeEncodingPredValues[newpredinlist])
    if c[0] != 'Dummy':
        PredIndex.append(Typeindex)
        PredNameMeanStd.append(c)
        PredArray.append(a)
        Predictionname.append(c[0])
        Predictionnamelookup[c] = predposition
        PredPosition.append(predposition)
        predposition += 1
        Numberpredaddons += 1
        Predictionwgt.append(0.25)
    if d[0] != 'Dummy':
        PredIndex.append(Typeindex)
        PredNameMeanStd.append(d)
        PredArray.append(b)
        Predictionname.append(d[0])
        Predictionnamelookup[d[0]] = predposition
        PredPosition.append(predposition)
        predposition += 1
        Numberpredaddons += 1
        Predictionwgt.append(0.25)

"""### Add in Temporal and Spatial Encoding

###Set up NNSE and Plots including Futures
"""


def SetNewAverages(InputList):  # name min max mean std
    results = np.empty(7, dtype=np.float32)
    results[0] = InputList[1]
    results[1] = InputList[2]
    results[2] = 1.0
    results[3] = InputList[3]
    results[4] = InputList[4]
    results[5] = InputList[3]
    results[6] = InputList[4]
    return results


NpropperseqTOT = Npropperseq + Numberpropaddons

# These include both Property and Prediction Variables
NpropperTimeMAX = len(QuantityTakeroot)
NewNpropperTimeMAX = NpropperTimeMAX + Numberpropaddons + Numberpredaddons
NewQuantityStatistics = np.zeros([NewNpropperTimeMAX, 7], dtype=np.float32)
NewQuantityTakeroot = np.full(NewNpropperTimeMAX, 1, dtype=np.int)  # All new ones aare 1 and are set here
NewQuantityStatistics[0:NpropperTimeMAX, :] = QuantityStatistics[0:NpropperTimeMAX, :]
NewQuantityTakeroot[0:NpropperTimeMAX] = QuantityTakeroot[0:NpropperTimeMAX]

# Lookup for property names
NewPropertyNameIndex = np.empty(NpropperseqTOT, dtype=np.int32)
NumberofNames = len(InputPropertyNames) - Numberpropaddons
NewPropertyNameIndex[0:Npropperseq] = PropertyNameIndex[0:Npropperseq]

NewPropertyAverageValuesPointer = np.empty(NpropperseqTOT, dtype=np.int32)
NewPropertyAverageValuesPointer[0:Npropperseq] = PropertyAverageValuesPointer[0:Npropperseq]

for propaddons in range(0, Numberpropaddons):
    NewPropertyNameIndex[Npropperseq + propaddons] = NumberofNames + propaddons
    NewPropertyAverageValuesPointer[Npropperseq + propaddons] = NpropperTimeMAX + propaddons
    NewQuantityStatistics[NpropperTimeMAX + propaddons, :] = SetNewAverages(PropNameMeanStd[propaddons])

# Set extra Predictions metadata for Sequences
NpredperseqTOT = Npredperseq + Numberpredaddons

NewPredictionAverageValuesPointer = np.empty(NpredperseqTOT, dtype=np.int32)
NewPredictionAverageValuesPointer[0:Npredperseq] = PredictionAverageValuesPointer[0:Npredperseq]

for predaddons in range(0, Numberpredaddons):
    NewPredictionAverageValuesPointer[Npredperseq + predaddons] = NpropperTimeMAX + +Numberpropaddons + predaddons
    NewQuantityStatistics[NpropperTimeMAX + Numberpropaddons + predaddons, :] = SetNewAverages(PredNameMeanStd[predaddons])

RawInputSequencesTOT = np.empty([Num_Seq + Num_SeqExtra + TFTExtraTimes, Nloc, RawInputSeqDimension, NpropperseqTOT],
                                dtype=np.float32)
flsize = np.float(Num_Seq + Num_SeqExtra) * np.float(Nloc) * np.float(RawInputSeqDimension) * np.float(NpropperseqTOT) * 4.0
print('Total storage ' + str(round(flsize, 0)) + ' Bytes')

for i in range(0, Num_Seq + Num_SeqExtra):
    for iprop in range(0, Npropperseq):
        RawInputSequencesTOT[i, :, :, iprop] = RawInputSequences[i, :, :, iprop]
for i in range(Num_Seq + Num_SeqExtra, Num_Seq + Num_SeqExtra + TFTExtraTimes):
    for iprop in range(0, Npropperseq):
        RawInputSequencesTOT[i, :, :, iprop] = NaN

for i in range(0, Num_Seq + Num_SeqExtra + TFTExtraTimes):
    for k in range(0, RawInputSeqDimension):
        for iprop in range(0, Numberpropaddons):
            if PropIndex[iprop] == 1:
                continue
            RawInputSequencesTOT[i, :, k, PropPosition[iprop]] = PropArray[iprop][i + k]

for iprop in range(0, Numberpropaddons):
    if PropIndex[iprop] == 1:
        for j in range(0, Nloc):
            RawInputSequencesTOT[:, j, :, PropPosition[iprop]] = PropArray[iprop][j]

# Set extra Predictions for Sequences
RawInputPredictionsTOT = np.empty([Num_SeqPred + TFTExtraTimes, Nloc, NpredperseqTOT], dtype=np.float32)

for i in range(0, Num_SeqPred):
    for ipred in range(0, Npredperseq):
        RawInputPredictionsTOT[i, :, ipred] = RawInputPredictions[i, :, ipred]
for i in range(Num_SeqPred, Num_SeqPred + TFTExtraTimes):
    for ipred in range(0, Npredperseq):
        RawInputPredictionsTOT[i, :, ipred] = NaN

for i in range(0, Num_SeqPred + TFTExtraTimes):
    for ipred in range(0, Numberpredaddons):
        if PredIndex[ipred] == 1:
            continue
        actualarray = PredArray[ipred]
        RawInputPredictionsTOT[i, :, PredPosition[ipred]] = actualarray[i + TseqPred]

for ipred in range(0, Numberpredaddons):
    if PredIndex[ipred] == 1:
        for j in range(0, Nloc):
            RawInputPredictionsTOT[:, j, PredPosition[ipred]] = PredArray[ipred][j]

PropertyNameIndex = None
PropertyNameIndex = NewPropertyNameIndex
QuantityStatistics = None
QuantityStatistics = NewQuantityStatistics
QuantityTakeroot = None
QuantityTakeroot = NewQuantityTakeroot
PropertyAverageValuesPointer = None
PropertyAverageValuesPointer = NewPropertyAverageValuesPointer
PredictionAverageValuesPointer = None
PredictionAverageValuesPointer = NewPredictionAverageValuesPointer

print('Time and Space encoding added to input and predictions')

if SymbolicWindows:
    SymbolicInputSequencesTOT = np.empty([Num_Seq, Nloc], dtype=np.int32)  # This is sequences
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            SymbolicInputSequencesTOT[iseq, iloc] = np.left_shift(iseq, 16) + iloc
    ReshapedSequencesTOT = np.transpose(RawInputSequencesTOT, (1, 0, 3, 2))
    ReshapedSequencesTOT = np.reshape(ReshapedSequencesTOT, (Nloc, Num_Seq + Num_SeqExtra + TFTExtraTimes, NpropperseqTOT))

# To calculate masks (identical to Symbolic windows)
SpacetimeforMask = np.empty([Num_Seq, Nloc], dtype=np.int32)
for iseq in range(0, Num_Seq):
    for iloc in range(0, Nloc):
        SpacetimeforMask[iseq, iloc] = np.left_shift(iseq, 16) + iloc

print(PropertyNameIndex)
print(InputPropertyNames)
for iprop in range(0, NpropperseqTOT):
    line = 'Property ' + str(iprop) + ' ' + InputPropertyNames[PropertyNameIndex[iprop]]
    jprop = PropertyAverageValuesPointer[iprop]
    line += ' Processing Root ' + str(QuantityTakeroot[jprop])
    for proppredval in range(0, 7):
        line += ' ' + QuantityStatisticsNames[proppredval] + ' ' + str(round(QuantityStatistics[jprop, proppredval], 3))
    print(wraptotext(line, size=150))

PredictionNameIndex = np.empty(NpredperseqTOT, dtype=np.int32))
for ipred in range(0, NpredperseqTOT):
    PredictionNameIndex[ipred] = ipred
line = 'Prediction ' + str(ipred) + ' ' + Predictionname[PredictionNameIndex[ipred]] + ' ' + str(
    round(Predictionwgt[ipred], 3))
jpred = PredictionAverageValuesPointer[ipred]
line += ' Processing Root ' + str(QuantityTakeroot[jpred])
for proppredval in range(0, 7):
    line += ' ' + QuantityStatisticsNames[proppredval] + ' ' + str(round(QuantityStatistics[jpred, proppredval], 3))
print(wraptotext(line, size=150))

RawInputPredictions = None
RawInputSequences = None
if SymbolicWindows:
    RawInputSequencesTOT = None
if GarbageCollect:
    gc.collect()

# Set up NNSE Normalized Nash Sutcliffe Efficiency
CalculateNNSE = np.full(NpredperseqTOT, False, dtype=np.bool)
PlotPredictions = np.full(NpredperseqTOT, False, dtype=np.bool)
for ipred in range(0, NpredperseqTOT):
    CalculateNNSE[ipred] = True
if (Predictionname[PredictionNameIndex[ipred]] == 'Constant') or (
        Predictionname[PredictionNameIndex[ipred]] == 'LinearSpace'):
    CalculateNNSE[ipred] = False  # as standard deviation over time zero
PlotPredictions[ipred] = True

"""## Location Based Validation"""

LocationBasedValidation = False
LocationValidationFraction = 0.0
RestartLocationBasedValidation = False
RestartValidationSetRunName = RunName
if Earthquake:
    LocationBasedValidation = True
LocationValidationFraction = 0.2
RestartLocationBasedValidation = True
RestartValidationSetRunName = 'EARTHQN-Transformer3'
FullSetValidation = False

global SeparateValandTrainingPlots
SeparateValandTrainingPlots = True
if not LocationBasedValidation:
    SeparateValandTrainingPlots = False
LocationValidationFraction = 0.0
ListofTrainingLocs = np.arange(Nloc, dtype=np.int32)
ListofValidationLocs = np.full(Nloc, -1, dtype=np.int32)
MappingtoTraining = np.arange(Nloc, dtype=np.int32)
MappingtoValidation = np.full(Nloc, -1, dtype=np.int32)
TrainingNloc = Nloc
ValidationNloc = 0
if LocationBasedValidation:
    if
RestartLocationBasedValidation:
InputFileName = APPLDIR + '/Validation' + RestartValidationSetRunName
with open(InputFileName, 'r', newline='') as inputfile:
    Myreader = reader(inputfile, delimiter=',')
header = next(Myreader)
LocationValidationFraction = np.float32(header[0])
TrainingNloc = np.int32(header[1])
ValidationNloc = np.int32(header[2])

ListofTrainingLocs = np.empty(TrainingNloc, dtype=np.int32)
ListofValidationLocs = np.empty(ValidationNloc, dtype=np.int32)
nextrow = next(Myreader)
for iloc in range(0, TrainingNloc):
    ListofTrainingLocs[iloc] = np.int32(nextrow[iloc])
nextrow = next(Myreader)
for iloc in range(0, ValidationNloc):
    ListofValidationLocs[iloc] = np.int32(nextrow[iloc])

LocationTrainingfraction = 1.0 - LocationValidationFraction
if TrainingNloc + ValidationNloc != Nloc:
    printexit('EXIT: Inconsistent location counts for Location Validation ' + str(Nloc)
+ ' ' + str(TrainingNloc) + ' ' + str(ValidationNloc))
print(' Validation restarted Fraction ' + str(round(LocationValidationFraction, 4)) + ' ' + RestartValidationSetRunName)

else:
LocationTrainingfraction = 1.0 - LocationValidationFraction
TrainingNloc = math.ceil(LocationTrainingfraction * Nloc)
ValidationNloc = Nloc - TrainingNloc
np.random.shuffle(ListofTrainingLocs)
ListofValidationLocs = ListofTrainingLocs[TrainingNloc:Nloc]
ListofTrainingLocs = ListofTrainingLocs[0:TrainingNloc]

for iloc in range(0, TrainingNloc):
    jloc = ListofTrainingLocs[iloc]
MappingtoTraining[jloc] = iloc
MappingtoValidation[jloc] = -1
for iloc in range(0, ValidationNloc):
    jloc = ListofValidationLocs[iloc]
MappingtoValidation[jloc] = iloc
MappingtoTraining[jloc] = -1
if ValidationNloc <= 0:
    SeparateValandTrainingPlots = False

if not RestartLocationBasedValidation:
    OutputFileName = APPLDIR + '/Validation' + RunName
with open(OutputFileName, 'w', newline='') as outputfile:
    Mywriter = writer(outputfile, delimiter=',')
Mywriter.writerow([LocationValidationFraction, TrainingNloc, ValidationNloc])
Mywriter.writerow(ListofTrainingLocs)
Mywriter.writerow(ListofValidationLocs)

print('Training Locations ' + str(TrainingNloc) + ' Validation Locations ' + str(ValidationNloc))
if ValidationNloc <= 0:
    LocationBasedValidation = False

if Earthquake:
    StartDate = np.datetime64(InitialDate).astype('datetime64[D]') + np.timedelta64(Tseq * Dailyunit + int(Dailyunit / 2),
                                                                                    'D')
dayrange = np.timedelta64(Dailyunit, 'D')
Numericaldate = np.empty(numberspecialeqs, dtype=np.float32)
PrimaryTrainingList = []
SecondaryTrainingList = []
PrimaryValidationList = []
SecondaryValidationList = []
for iquake in range(0, numberspecialeqs):
    Numericaldate[iquake] = max(0, math.floor((Specialdate[iquake] - StartDate) / dayrange))
Trainingsecondary = False
Validationsecondary = False
for jloc in range(0, Nloc):
    iloc = LookupLocations[jloc]  # original location
result = quakesearch(iquake, iloc)
if result == 0:
continue
kloc = MappingtoTraining[jloc]
if result == 1:  # Primary
    if kloc >= 0:
        PrimaryTrainingList.append(iquake)
        Trainingsecondary = True
    else:
        PrimaryValidationList.append(iquake)
        Validationsecondary = True
else:  # Secondary
    if kloc >= 0:
        if Trainingsecondary:
            continue
        Trainingsecondary = True
        SecondaryTrainingList.append(iquake)
    else:
        if Validationsecondary:
            continue
        Validationsecondary = True
        SecondaryValidationList.append(iquake)
iloc = Specialxpos[iquake] + 60 * Specialypos[iquake]
jloc = MappedLocations[iloc]
kloc = -2
if jloc >= 0:
    kloc = LookupLocations[jloc]
line = str(iquake) + " " + str(Trainingsecondary) + " " + str(Validationsecondary) + " "
line += str(iloc) + " " + str(jloc) + " " + str(kloc) + " " + str(round(Specialmags[iquake], 1)) + ' ' + Specialeqname[
    iquake]
print(line)

PrimaryTrainingvetoquake = np.full(numberspecialeqs, True, dtype=np.bool)
SecondaryTrainingvetoquake = np.full(numberspecialeqs, True, dtype=np.bool)
PrimaryValidationvetoquake = np.full(numberspecialeqs, True, dtype=np.bool)
SecondaryValidationvetoquake = np.full(numberspecialeqs, True, dtype=np.bool)
for jquake in PrimaryTrainingList:
    PrimaryTrainingvetoquake[jquake] = False
for jquake in PrimaryValidationList:
    PrimaryValidationvetoquake[jquake] = False
for jquake in SecondaryTrainingList:
    if not PrimaryTrainingvetoquake[jquake]:
        continue
    SecondaryTrainingvetoquake[jquake] = False
for jquake in SecondaryValidationList:
    if not PrimaryValidationvetoquake[jquake]:
        continue
    SecondaryValidationvetoquake[jquake] = False

for iquake in range(0, numberspecialeqs):
    iloc = Specialxpos[iquake] + 60 * Specialypos[iquake]
    line = str(iquake) + " Loc " + str(iloc) + " " + str(MappedLocations[iloc]) + " Date " + str(
        Specialdate[iquake]) + " " + str(Numericaldate[iquake])
    line += " " + str(PrimaryTrainingvetoquake[iquake]) + " " + str(SecondaryTrainingvetoquake[iquake])
    line += " Val " + str(PrimaryValidationvetoquake[iquake]) + " " + str(SecondaryValidationvetoquake[iquake])
    print(line)

"""## LSTM Control Parameters EDIT TFTT..epochs"""

CustomLoss = 1
UseClassweights = True

PredictionTraining = False

if (not Hydrology) and (not Earthquake) and (NpredperseqTOT <= 2):
    useFutures = False
    CustomLoss = 0
    UseClassweights = False

number_of_LSTMworkers = 1
TFTTransformerepochs = 10
LSTMbatch_size = TrainingNloc
LSTMbatch_size = min(LSTMbatch_size, TrainingNloc)

LSTMactivationvalue = "selu"
LSTMrecurrent_activation = "sigmoid"
LSTMoptimizer = 'adam'
LSTMdropout1 = 0.2
LSTMrecurrent_dropout1 = 0.2
LSTMdropout2 = 0.2
LSTMrecurrent_dropout2 = 0.2
number_LSTMnodes = 16
LSTMFinalMLP = 64
LSTMInitialMLP = 32
LSTMThirdLayer = False

LSTMSkipInitial = False

LSTMverbose = 0
LSTMvalidationfrac = 0.0
UsedLSTMvalidationfrac = LSTMvalidationfrac
if LocationBasedValidation:
    UsedLSTMvalidationfrac = LocationBasedValidation
    LSTMvalidationfrac = UsedLSTMvalidationfrac

"""## General Control Parameters"""

OuterBatchDimension = Num_Seq * TrainingNloc
IndividualPlots = False
Plotrealnumbers = False
PlotsOnlyinTestFIPS = True
ListofTestFIPS = ['36061', '53033', '17031', '6037']
if Hydrology:
    ListofTestFIPS = ['6224000', '6622700']
    ListofTestFIPS = ['', '']
if Earthquake:
    ListofTestFIPS = ['', '']
    Plotrealnumbers = True

StartDate = np.datetime64(InitialDate).astype('datetime64[D]') + np.timedelta64(Tseq * Dailyunit + int(Dailyunit / 2), 'D')
if Earthquake:
    dayrange = np.timedelta64(Dailyunit, 'D')
    CutoffDate = np.datetime64('1989-01-01')
    NumericalCutoff = math.floor((CutoffDate - StartDate) / dayrange)
else:
    NumericalCutoff = int(Num_Seq / 2)
    CutoffDate = StartDate + np.timedelta64(NumericalCutoff * Dailyunit, 'D')
print('Start ' + str(StartDate) + ' Cutoff ' + str(CutoffDate) + " sequence index " + str(NumericalCutoff))

TimeCutLabel = [' All Time ', ' Start ', ' End ']

print("Size of sequence window Tseq ", str(Tseq))
print("Number of Sequences in time Num_Seq ", str(Num_Seq))
print("Number of locations Nloc ", str(Nloc))
print("Number of Training Sequences in Location and Time ", str(OuterBatchDimension))
print("Number of internal properties per sequence including static or dynamic Npropperseq ", str(Npropperseq))
print("Number of internal properties per sequence adding in explicit space-time encoding ", str(NpropperseqTOT))
print("Total number of predictions per sequence NpredperseqTOT ", str(NpredperseqTOT))

"""## Useful Time series utilities

### DLprediction

Prediction and Visualization LSTM+Transformer
"""


def DLprediction(Xin, yin, DLmodel, modelflag, LabelFit=''):
    # modelflag = 0 LSTM = 1 Transformer
    # Input is the windows [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT] (SymbolicWindows False)
    # Input is  the sequences [Nloc] [Num_Time-1] [NpropperseqTOT] (SymbolicWindows True)
    # Input Predictions are always [Num_Seq] [NLoc] [NpredperseqTOT]
    current_time = timenow()
    print(startbold + startred + current_time + ' ' + RunName + " DLPrediction " + RunComment + resetfonts)

    FitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    # Compare to RawInputPredictionsTOT

    RMSEbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSETRAINbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSEVALbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    AbsEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    AbsVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    ObsVbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT, 3], dtype=np.float64)
    Predbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT, 3], dtype=np.float64)
    countbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    countVALbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    countTRAINbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    totalcount = 0
    overcount = 0
    weightedcount = 0.0
    weightedovercount = 0.0
    weightedrmse1 = 0.0
    weightedrmse1TRAIN = 0.0
    weightedrmse1VAL = 0.0

    closs = 0.0
    dloss = 0.0
    eloss = 0.0
    floss = 0.0
    sw = np.empty([Nloc, NpredperseqTOT], dtype=np.float32)
    for iloc in range(0, Nloc):
        for k in range(0, NpredperseqTOT):
            sw[iloc, k] = Predictionwgt[k]

    global tensorsw
    tensorsw = tf.convert_to_tensor(sw, np.float32)
    Ctime1 = 0.0
    Ctime2 = 0.0
    Ctime3 = 0.0
    samplebar = notebook.trange(Num_Seq, desc='Predict loop', unit='sequences')
    countingcalls = 0

    for iseq in range(0, Num_Seq):
        StopWatch.start('label1')
        if SymbolicWindows:
            if modelflag == 2:
                InputVector = np.empty((Nloc, 2), dtype=int)
                for iloc in range(0, Nloc):
                    InputVector[iloc, 0] = iloc
                    InputVector[iloc, 1] = iseq
            else:
                InputVector = Xin[:, iseq:iseq + Tseq, :]
        else:
            InputVector = Xin[iseq]
        Time = None
        if modelflag == 0:
            InputVector = np.reshape(InputVector, (-1, Tseq, NpropperseqTOT))
        elif modelflag == 1:
            InputVector = np.reshape(InputVector, (1, Tseq * Nloc, NpropperseqTOT))
            BasicTimes = np.full(Nloc, iseq, dtype=np.int32)
            Time = SetSpacetime(np.reshape(BasicTimes, (1, -1)))
        StopWatch.stop('label1')
        Ctime1 += StopWatch.get('label1', digits=4)

        StopWatch.start('label2')
        PredictedVector = DLmodel(InputVector, training=PredictionTraining, Time=Time)
        StopWatch.stop('label2')
        Ctime2 += StopWatch.get('label2', digits=4)
        StopWatch.start('label3')
        PredictedVector = np.reshape(PredictedVector, (Nloc, NpredperseqTOT))
        TrueVector = yin[iseq]
        functionval = numpycustom_lossGCF1(TrueVector, PredictedVector, sw)
        closs += functionval
        PredictedVector_t = tf.convert_to_tensor(PredictedVector)
        yin_t = tf.convert_to_tensor(TrueVector)
        dloss += weightedcustom_lossGCF1(yin_t, PredictedVector_t, tensorsw)
        eloss += custom_lossGCF1spec(yin_t, PredictedVector_t)
        OutputLoss = 0.0
        FitPredictions[iseq] = PredictedVector
        for iloc in range(0, Nloc):
            yy = yin[iseq, iloc]
            yyhat = PredictedVector[iloc]

            sum1 = 0.0
            for i in range(0, NpredperseqTOT):
                overcount += 1
                weightedovercount += Predictionwgt[i]

                if (math.isnan(yy[i])):
                    continue
                weightedcount += Predictionwgt[i]
                totalcount += 1
                mse1 = ((yy[i] - yyhat[i]) ** 2)
                mse = mse1 * sw[iloc, i]
                if i < Npredperseq:
                    floss += mse
                sum1 += mse
                AbsEbyclass[i] += abs(yy[i] - yyhat[i])
                RMSVbyclass[i] += yy[i] ** 2
                AbsVbyclass[i] += abs(yy[i])
                RMSEbyclass[i, 0] += mse
                countbyclass[i, 0] += 1.0
                if iseq < NumericalCutoff:
                    countbyclass[i, 1] += 1.0
                    RMSEbyclass[i, 1] += mse
                else:
                    countbyclass[i, 2] += 1.0
                    RMSEbyclass[i, 2] += mse
                if LocationBasedValidation:
                    if MappingtoTraining[iloc] >= 0:
                        ObsVbytimeandclass[iseq, i, 1] += abs(yy[i])
                        Predbytimeandclass[iseq, i, 1] += abs(yyhat[i])
                        RMSETRAINbyclass[i, 0] += mse
                        countTRAINbyclass[i, 0] += 1.0
                        if iseq < NumericalCutoff:
                            RMSETRAINbyclass[i, 1] += mse
                            countTRAINbyclass[i, 1] += 1.0
                        else:
                            RMSETRAINbyclass[i, 2] += mse
                            countTRAINbyclass[i, 2] += 1.0
                    if MappingtoValidation[iloc] >= 0:
                        ObsVbytimeandclass[iseq, i, 2] += abs(yy[i])
                        Predbytimeandclass[iseq, i, 2] += abs(yyhat[i])
                        RMSEVALbyclass[i, 0] += mse
                        countVALbyclass[i, 0] += 1.0
                        if iseq < NumericalCutoff:
                            RMSEVALbyclass[i, 1] += mse
                            countVALbyclass[i, 1] += 1.0
                        else:
                            RMSEVALbyclass[i, 2] += mse
                            countVALbyclass[i, 2] += 1.0
                else:
                    ObsVbytimeandclass[iseq, i, 1] += abs(yy[i])
                    Predbytimeandclass[iseq, i, 1] += abs(yyhat[i])
                ObsVbytimeandclass[iseq, i, 0] += abs(yy[i])
                Predbytimeandclass[iseq, i, 0] += abs(yyhat[i])
            weightedrmse1 += sum1
            if LocationBasedValidation:
                if MappingtoTraining[iloc] >= 0:
                    weightedrmse1TRAIN += sum1
                if MappingtoValidation[iloc] >= 0:
                    weightedrmse1VAL += sum1
            OutputLoss += sum1
        StopWatch.stop('label3')
        Ctime3 += StopWatch.get('label3', digits=4)
        OutputLoss /= Nloc
        countingcalls += 1
        samplebar.update(1)
        samplebar.set_postfix(Call=countingcalls, TotalLoss=OutputLoss)

    print('Times ' + str(round(Ctime1, 5)) + ' ' + str(round(Ctime3, 5)) + ' TF ' + str(round(Ctime2, 5)))
    weightedrmse1 /= (Num_Seq * Nloc)
    floss /= (Num_Seq * Nloc)
    if LocationBasedValidation:
        weightedrmse1TRAIN /= (Num_Seq * TrainingNloc)
        if ValidationNloc > 0:
            weightedrmse1VAL /= (Num_Seq * ValidationNloc)
    dloss = dloss.numpy()
    eloss = eloss.numpy()
    closs /= Num_Seq
    dloss /= Num_Seq
    eloss /= Num_Seq

    current_time = timenow()
    line1 = ''
    global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
    GlobalLoss = weightedrmse1
    if LocationBasedValidation:
        line1 = ' Training ' + str(round(weightedrmse1TRAIN, 6)) + ' Validation ' + str(round(weightedrmse1VAL, 6))
        GlobalTrainingLoss = weightedrmse1TRAIN
        GlobalValidationLoss = weightedrmse1VAL
    print(startbold + startred + current_time + ' DLPrediction Averages' + ' ' + RunName + ' ' + RunComment + resetfonts)
    line = LabelFit + ' ' + RunName + ' Weighted sum over predicted values ' + str(round(weightedrmse1, 6))
    line += ' No Encoding Preds ' + str(round(floss, 6)) + line1
    line += ' from loss function ' + str(round(closs, 6)) + ' TF version ' + str(
        round(dloss, 6)) + ' TFspec version ' + str(round(eloss, 6))
    print(wraptotext(line))
    print('Count ignoring NaN ' + str(round(weightedcount, 4)) + ' Counting NaN ' + str(round(weightedovercount, 4)), 70)
    print(' Unwgt Count no NaN ', totalcount, ' Unwgt Count with NaN ', overcount, ' Number Sequences ', Nloc * Num_Seq)

    ObsvPred = np.sum(np.abs(ObsVbytimeandclass - Predbytimeandclass), axis=0)
    TotalObs = np.sum(ObsVbytimeandclass, axis=0)
    SummedEbyclass = np.divide(ObsvPred, TotalObs)
    RMSEbyclass1 = np.divide(RMSEbyclass, countbyclass)  # NO SQRT
    RMSEbyclass2 = np.sqrt(np.divide(RMSEbyclass[:, 0], RMSVbyclass))
    RelEbyclass = np.divide(AbsEbyclass, AbsVbyclass)
    extracomments = []

    line1 = '\nErrors by Prediction Components -- class weights not included except in final Loss components\n Name Count without NaN, '
    line2 = 'sqrt(sum errors**2/sum target**2), sum(abs(error)/sum(abs(value), abs(sum(abs(value)-abs(pred)))/sum(abs(pred)'
    print(wraptotext(startbold + startred + line1 + line2 + resetfonts))
    countbasic = 0

    for i in range(0, NpredperseqTOT):
        line = startbold + startred + ' AVG MSE '
        for timecut in range(0, 3):
            line += TimeCutLabel[timecut] + 'Full ' + str(round(RMSEbyclass1[i, timecut], 6)) + resetfonts
        if LocationBasedValidation:
            RTRAIN = np.divide(RMSETRAINbyclass[i], countTRAINbyclass[i])
            RVAL = np.full(3, 0.0, dtype=np.float32)
            if countVALbyclass[i, 0] > 0:
                RVAL = np.divide(RMSEVALbyclass[i], countVALbyclass[i])
            for timecut in range(0, 3):
                line += startbold + startpurple + TimeCutLabel[timecut] + 'TRAIN ' + resetfonts + str(
                    round(RTRAIN[timecut], 6))
                line += startbold + ' VAL ' + resetfonts + str(round(RVAL[timecut], 6))
        else:
            RTRAIN = RMSEbyclass1[i]
            RVAL = np.full(3, 0.0, dtype=np.float32)

        print(wraptotext(
            str(i) + ' ' + startbold + Predictionname[PredictionNameIndex[i]] + resetfonts + ' All Counts ' + str(
                round(countbyclass[i, 0], 0)) + ' IndE^2/IndObs^2 '
            + str(round(100.0 * RMSEbyclass2[i], 2)) + '% IndE/IndObs ' + str(
                round(100.0 * RelEbyclass[i], 2)) + '% summedErr/SummedObs ' + str(
                round(100.0 * SummedEbyclass[i, 0], 2)) + '%' + line))
        Trainline = 'AVG MSE F=' + str(round(RTRAIN[0], 8)) + ' S=' + str(round(RTRAIN[1], 8))
        Trainline += ' E=' + str(round(RTRAIN[2], 8)) + ' TOTAL summedErr/SummedObs ' + str(
            round(100.0 * SummedEbyclass[i, 1], 2)) + '%'
        Valline = 'AVG MSE F=' + str(round(RVAL[0], 6)) + ' S=' + str(round(RVAL[1], 6)) + ' E=' + str(
            round(RVAL[2], 6)) + ' TOTAL summedErr/SummedObs ' + str(round(100.0 * SummedEbyclass[i, 2], 2)) + '%'
        extracomments.append([Trainline, Valline])
        countbasic += 1
        if countbasic == NumpredbasicperTime:
            countbasic = 0
            print(' ')

    # Don't use DLPrediction for Transformer Plots. Wait for DL2B,D,E
    if modelflag == 1:
        return FitPredictions

    FindNNSE(yin, FitPredictions)
    print('\n Next plots come from DLPrediction')
    PredictedQuantity = -NumpredbasicperTime
    for ifuture in range(0, 1 + LengthFutures):
        increment = NumpredbasicperTime
        if ifuture > 1:
            increment = NumpredFuturedperTime
        PredictedQuantity += increment
        if not PlotPredictions[PredictedQuantity]:
            continue
        Dumpplot = False
        if PredictedQuantity == 0:
            Dumpplot = True
        Location_summed_plot(ifuture, yin, FitPredictions, extracomments=extracomments, Dumpplot=Dumpplot)

    if IndividualPlots:
        ProduceIndividualPlots(yin, FitPredictions)

    if Earthquake and EarthquakeImagePlots:
        ProduceSpatialQuakePlot(yin, FitPredictions)

    # Call DLprediction2F here if modelflag=0
    DLprediction2F(Xin, yin, DLmodel, modelflag)

    return FitPredictions


"""### Spatial Earthquake Plots"""


def ProduceSpatialQuakePlot(Observations, FitPredictions):
    current_time = timenow()
    print(
        startbold + startred + current_time + ' Produce Spatial Earthquake Plots ' + RunName + ' ' + RunComment + resetfonts)
    dayindexmax = Num_Seq - Plottingdelay
    Numdates = 4
    denom = 1.0 / np.float64(Numdates - 1)
    for plotdays in range(0, Numdates):
        dayindexvalue = math.floor(0.1 + (plotdays * dayindexmax) * denom)
        if dayindexvalue < 0:
            dayindexvalue = 0
        if dayindexvalue > dayindexmax:
            dayindexvalue = dayindexmax
        FixedTimeSpatialQuakePlot(dayindexvalue, Observations, FitPredictions)


def EQrenorm(casesdeath, value):
    if Plotrealnumbers:
        predaveragevaluespointer = PredictionAverageValuesPointer[casesdeath]
        newvalue = value / QuantityStatistics[predaveragevaluespointer, 2] + QuantityStatistics[predaveragevaluespointer, 0]
        rootflag = QuantityTakeroot[predaveragevaluespointer]
        if rootflag == 2:
            newvalue = newvalue ** 2
        if rootflag == 3:
            newvalue = newvalue ** 3
    else:
        newvalue = value
    return newvalue


def FixedTimeSpatialQuakePlot(PlotTime, Observations, FitPredictions):
    Actualday = InitialDate + timedelta(days=(PlotTime + Tseq))
    print(startbold + startred + ' Spatial Earthquake Plots ' + Actualday.strftime(
        "%d/%m/%Y") + ' ' + RunName + ' ' + RunComment + resetfonts)
    NlocationsPlotted = Nloc
    real = np.zeros([NumpredbasicperTime, NlocationsPlotted])
    predict = np.zeros([NumpredbasicperTime, NlocationsPlotted])
    print('Ranges for Prediction numbers/names/property pointer')
    for PredictedQuantity in range(0, NumpredbasicperTime):
        for iloc in range(0, NlocationsPlotted):
            real[PredictedQuantity, iloc] = EQrenorm(PredictedQuantity, Observations[PlotTime, iloc, PredictedQuantity])
            predict[PredictedQuantity, iloc] = EQrenorm(PredictedQuantity,
                                                        FitPredictions[PlotTime, iloc, PredictedQuantity])
        localmax1 = real[PredictedQuantity].max()
        localmin1 = real[PredictedQuantity].min()
        localmax2 = predict[PredictedQuantity].max()
        localmin2 = predict[PredictedQuantity].min()
        predaveragevaluespointer = PredictionAverageValuesPointer[PredictedQuantity]
        expectedmax = QuantityStatistics[predaveragevaluespointer, 1]
        expectedmin = QuantityStatistics[predaveragevaluespointer, 0]
        print(' Real max/min ' + str(round(localmax1, 3)) + ' ' + str(round(localmin1, 3))
              + ' Predicted max/min ' + str(round(localmax2, 3)) + ' ' + str(round(localmin2, 3))
              + ' Overall max/min ' + str(round(expectedmax, 3)) + ' ' + str(round(expectedmin, 3))
              + str(PredictedQuantity) + ' ' + Predictionbasicname[PredictedQuantity] + str(predaveragevaluespointer))

    InputImages = []
    InputTitles = []
    for PredictedQuantity in range(0, NumpredbasicperTime):
        InputImages.append(real[PredictedQuantity])
        InputTitles.append(Actualday.strftime("%d/%m/%Y") + ' Observed ' + Predictionbasicname[PredictedQuantity])
        InputImages.append(predict[PredictedQuantity])
        InputTitles.append(Actualday.strftime("%d/%m/%Y") + ' Predicted ' + Predictionbasicname[PredictedQuantity])
    plotimages(InputImages, InputTitles, NumpredbasicperTime, 2)


"""###Organize Location v Time Plots"""


def ProduceIndividualPlots(Observations, FitPredictions):
    current_time = timenow()
    print(startbold + startred + current_time + ' Produce Individual Plots ' + RunName + ' ' + RunComment + resetfonts)
    # Find Best and Worst Locations
    fips_b, fips_w = bestandworst(Observations, FitPredictions)
    if Hydrology or Earthquake:
        plot_by_fips(fips_b, Observations, FitPredictions)
        plot_by_fips(fips_w, Observations, FitPredictions)
    else:
        plot_by_fips(6037, Observations, FitPredictions)
        plot_by_fips(36061, Observations, FitPredictions)
        plot_by_fips(17031, Observations, FitPredictions)
        plot_by_fips(53033, Observations, FitPredictions)
        if (fips_b != 6037) and (fips_b != 36061) and (fips_b != 17031) and (fips_b != 53033):
            plot_by_fips(fips_b, Observations, FitPredictions)
        if (fips_w != 6037) and (fips_w != 36061) and (fips_w != 17031) and (fips_w != 53033):
            plot_by_fips(fips_w, Observations, FitPredictions)

        # Plot top 10 largest cities
        sortedcities = np.flip(np.argsort(Locationpopulation))
        for pickout in range(0, 10):
            Locationindex = sortedcities[pickout]
            fips = Locationfips[Locationindex]
            if not (Hydrology or Earthquake):
                if (fips == 6037 or fips == 36061 or fips == 17031 or fips == 53033):
                    continue
            if (fips == fips_b or fips == fips_w):
                continue
            plot_by_fips(fips, Observations, FitPredictions)

    if LengthFutures > 1:
        plot_by_futureindex(2, Observations, FitPredictions)
    if LengthFutures > 6:
        plot_by_futureindex(7, Observations, FitPredictions)
    if LengthFutures > 11:
        plot_by_futureindex(12, Observations, FitPredictions)
    return


def bestandworst(Observations, FitPredictions):
    current_time = timenow()
    print(startbold + startred + current_time + ' ' + RunName + " Best and Worst " + RunComment + resetfonts)

    keepabserrorvalues = np.zeros([Nloc, NumpredbasicperTime], dtype=np.float64)
    keepRMSEvalues = np.zeros([Nloc, NumpredbasicperTime], dtype=np.float64)
    testabserrorvalues = np.zeros(Nloc, dtype=np.float64)
    testRMSEvalues = np.zeros(Nloc, dtype=np.float64)

    real = np.zeros([NumpredbasicperTime, Num_Seq], dtype=np.float64)
    predictsmall = np.zeros([NumpredbasicperTime, Num_Seq], dtype=np.float64)
    c_error_props = np.zeros([NumpredbasicperTime], dtype=np.float64)
    c_error_props = np.zeros([NumpredbasicperTime], dtype=np.float64)

    for icity in range(0, Nloc):
        validcounts = np.zeros([NumpredbasicperTime], dtype=np.float64)
        RMSE = np.zeros([NumpredbasicperTime], dtype=np.float64)
        for PredictedQuantity in range(0, NumpredbasicperTime):
            for itime in range(0, Num_Seq):
                if not math.isnan(Observations[itime, icity, PredictedQuantity]):
                    real[PredictedQuantity, itime] = Observations[itime, icity, PredictedQuantity]
                    predictsmall[PredictedQuantity, itime] = FitPredictions[itime, icity, PredictedQuantity]
                    validcounts[PredictedQuantity] += 1.0
                    RMSE[PredictedQuantity] += (Observations[itime, icity, PredictedQuantity] - FitPredictions[
                        itime, icity, PredictedQuantity]) ** 2
            c_error_props[PredictedQuantity] = cumulative_error(predictsmall[PredictedQuantity],
                                                                real[PredictedQuantity])  # abs(error) as percentage
            keepabserrorvalues[icity, PredictedQuantity] = c_error_props[PredictedQuantity]
            keepRMSEvalues[icity, PredictedQuantity] = RMSE[PredictedQuantity] * 100. / validcounts[PredictedQuantity]

        testabserror = 0.0
        testRMSE = 0.0
        for PredictedQuantity in range(0, NumpredbasicperTime):
            testabserror += c_error_props[PredictedQuantity]
            testRMSE += keepRMSEvalues[icity, PredictedQuantity]
        testabserrorvalues[icity] = testabserror
        testRMSEvalues[icity] = testRMSE

    sortingindex = np.argsort(testabserrorvalues)
    bestindex = sortingindex[0]
    worstindex = sortingindex[Nloc - 1]
    fips_b = Locationfips[bestindex]
    fips_w = Locationfips[worstindex]

    current_time = timenow()
    print(startbold + "\n" + current_time + " Best " + str(fips_b) + " " + Locationname[bestindex] + " " + Locationstate[
        bestindex] + ' ABS(error) ' +
          str(round(testabserrorvalues[bestindex], 2)) + ' RMSE ' + str(round(testRMSEvalues[bestindex], 2)) + resetfonts)

    for topcities in range(0, 10):
        localindex = sortingindex[topcities]
        printstring = str(topcities) + ") " + str(Locationfips[localindex]) + " " + Locationname[
            localindex] + " ABS(error) Total " + str(round(testabserrorvalues[localindex], 4)) + " Components "
        for PredictedQuantity in range(0, NumpredbasicperTime):
            printstring += ' ' + str(round(keepabserrorvalues[localindex, PredictedQuantity], 2))
        print(printstring)
    print("\nlist RMSE")
    for topcities in range(0, 9):
        localindex = sortingindex[topcities]
        printstring = str(topcities) + ") " + str(Locationfips[localindex]) + " " + Locationname[
            localindex] + " RMSE Total " + str(round(testRMSEvalues[localindex], 4)) + " Components "
        for PredictedQuantity in range(0, NumpredbasicperTime):
            printstring += ' ' + str(round(keepRMSEvalues[localindex, PredictedQuantity], 2))
        print(printstring)

    print(startbold + "\n" + current_time + " Worst " + str(fips_w) + " " + Locationname[worstindex] + " " + Locationstate[
        worstindex] + ' ABS(error) ' +
          str(round(testabserrorvalues[worstindex], 2)) + ' RMSE ' + str(round(testRMSEvalues[worstindex], 2)) + resetfonts)

    for badcities in range(Nloc - 1, Nloc - 11, -1):
        localindex = sortingindex[badcities]
        printstring = str(badcities) + ") " + str(Locationfips[localindex]) + " " + Locationname[
            localindex] + " ABS(error) Total " + str(round(testabserrorvalues[localindex], 4)) + " Components "
        for PredictedQuantity in range(0, NumpredbasicperTime):
            printstring += ' ' + str(round(keepabserrorvalues[localindex, PredictedQuantity], 2))
        print(printstring)
    print("\nlist RMSE")
    for badcities in range(0, 9):
        localindex = sortingindex[badcities]
        printstring = str(badcities) + ") " + str(Locationfips[localindex]) + " " + Locationname[
            localindex] + " RMSE Total " + str(round(testRMSEvalues[localindex], 4)) + " Components "
        for PredictedQuantity in range(0, NumpredbasicperTime):
            printstring += ' ' + str(round(keepRMSEvalues[localindex, PredictedQuantity], 2))
        print(printstring)

    return fips_b, fips_w


"""### Summed & By Location Plots"""


def setValTrainlabel(iValTrain):
    if SeparateValandTrainingPlots:
        if iValTrain == 0:
            Overalllabel = 'Training '
            if GlobalTrainingLoss > 0.0001:
                Overalllabel += str(round(GlobalTrainingLoss, 5)) + ' '
            if JournalSimplePrint:
                Overalllabel = 'Training '
        if iValTrain == 1:
            Overalllabel = 'Validation '
            if GlobalValidationLoss > 0.0001:
                Overalllabel += str(round(GlobalValidationLoss, 5)) + ' '
            if JournalSimplePrint:
                Overalllabel = 'Validation '
    else:
        Overalllabel = 'Full ' + str(round(GlobalLoss, 5)) + ' '
        if JournalSimplePrint:
            Overalllabel = 'Full '
    if not JournalSimplePrint:
        Overalllabel += RunName + ' '
    return Overalllabel


def Location_summed_plot(selectedfuture, Observations, FitPredictions, fill=True, otherlabs=[], otherfits=[],
                         extracomments=None, Dumpplot=False):
    #  plot sum over locations

    current_time = timenow()
    print(wraptotext(
        startbold + startred + current_time + ' Location_summed_plot ' + RunName + ' ' + RunComment + resetfonts))
    otherlen = len(otherlabs)
    basiclength = Num_Seq
    predictlength = LengthFutures
    if (not UseFutures) or (selectedfuture > 0):
        predictlength = 0
    totallength = basiclength + predictlength
    if extracomments is None:
        extracomments = []
        for PredictedQuantity in range(0, NpredperseqTOT):
            extracomments.append([' ', ''])

    NumberValTrainLoops = 1
    if SeparateValandTrainingPlots:
        NumberValTrainLoops = 2

    selectedfield = NumpredbasicperTime + NumpredFuturedperTime * (selectedfuture - 1)
    selectednumplots = NumpredFuturedperTime
    if selectedfuture == 0:
        selectedfield = 0
        selectednumplots = NumpredbasicperTime
    ActualQuantity = np.arange(selectednumplots, dtype=np.int32)
    if selectedfuture > 0:
        for ipred in range(0, NumpredbasicperTime):
            ifuture = FuturedPointer[ipred]
            if ifuture >= 0:
                ActualQuantity[ifuture] = ipred

    real = np.zeros([selectednumplots, NumberValTrainLoops, basiclength])
    predictsmall = np.zeros([selectednumplots, NumberValTrainLoops, basiclength])
    predict = np.zeros([selectednumplots, NumberValTrainLoops, totallength])
    if otherlen != 0:
        otherpredict = np.zeros([otherlen, selectednumplots, NumberValTrainLoops, totallength])

    for PlottedIndex in range(0, selectednumplots):
        PredictedPos = PlottedIndex + selectedfield
        ActualObservable = ActualQuantity[PlottedIndex]
        for iValTrain in range(0, NumberValTrainLoops):

            for iloc in range(0, Nloc):
                if SeparateValandTrainingPlots:
                    if iValTrain == 0:
                        if MappingtoTraining[iloc] < 0:
                            continue
                    if iValTrain == 1:
                        if MappingtoTraining[iloc] >= 0:
                            continue
                for itime in range(0, Num_Seq):
                    if np.math.isnan(Observations[itime, iloc, PredictedPos]):
                        real[PlottedIndex, iValTrain, itime] += normalizeforplot(PredictedPos, iloc,
                                                                                 FitPredictions[itime, iloc, PredictedPos])
                    else:
                        real[PlottedIndex, iValTrain, itime] += normalizeforplot(PredictedPos, iloc,
                                                                                 Observations[itime, iloc, PredictedPos])
                    predict[PlottedIndex, iValTrain, itime] += normalizeforplot(PredictedPos, iloc,
                                                                                FitPredictions[itime, iloc, PredictedPos])
                    for others in range(0, otherlen):
                        otherpredict[others, PlottedIndex, iValTrain, itime] += normalizeforplot(PredictedPos, iloc,
                                                                                                 FitPredictions[
                                                                                                     itime, iloc, PredictedPos] +
                                                                                                 otherfits[
                                                                                                     others, itime, iloc, PredictedPos])
                if selectedfuture == 0:
                    if FuturedPointer[PlottedIndex] >= 0:
                        for ifuture in range(selectedfuture, LengthFutures):
                            jfuture = NumpredbasicperTime + NumpredFuturedperTime * ifuture
                            predict[PlottedIndex, iValTrain, Num_Seq + ifuture] += normalizeforplot(PredictedPos, iloc,
                                                                                                    FitPredictions[
                                                                                                        itime, iloc,
                                                                                                        FuturedPointer[
                                                                                                            PlottedIndex] + jfuture])
                            for others in range(0, otherlen):
                                otherpredict[others, PlottedIndex, iValTrain, Num_Seq + ifuture] += normalizeforplot(
                                    PredictedPos, iloc, FitPredictions[itime, iloc, PlottedIndex + jfuture] + otherfits[
                                        others, itime, iloc, PlottedIndex + jfuture])
            for itime in range(0, basiclength):
                predictsmall[PlottedIndex, iValTrain, itime] = predict[PlottedIndex, iValTrain, itime]

    error = np.absolute(real - predictsmall)
    xsmall = np.arange(0, Num_Seq)

    neededrows = math.floor((selectednumplots * NumberValTrainLoops + 1.1) / 2)
    iValTrain = -1
    PlottedIndex = -1
    for rowloop in range(0, neededrows):
        if JournalSimplePrint:
            plt.rcParams["figure.figsize"] = [16, 6]
        else:
            plt.rcParams["figure.figsize"] = [48, 15]
        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)
        for kplot in range(0, 2):
            if NumberValTrainLoops == 2:
                iValTrain = kplot
            else:
                iValTrain = 0
            if iValTrain == 0:
                PlottedIndex += 1
                if PlottedIndex > (selectednumplots - 1):
                    PlottedIndex = selectednumplots - 1
            Overalllabel = setValTrainlabel(iValTrain)
            PredictedPos = PlottedIndex + selectedfield
            ActualObservable = ActualQuantity[PlottedIndex]

            eachplt = ax1
            if kplot == 1:
                eachplt = ax2

            Overalllabel = setValTrainlabel(iValTrain)

            maxplot = np.float32(totallength)
            if UseRealDatesonplots:
                StartDate = np.datetime64(InitialDate).astype('datetime64[D]') + np.timedelta64(
                    Tseq * Dailyunit + math.floor(Dailyunit / 2), 'D')
                EndDate = StartDate + np.timedelta64(totallength * Dailyunit)
                datemin, datemax = makeadateplot(figure, eachplt, datemin=StartDate, datemax=EndDate)
                Dateplot = True
                Dateaxis = np.empty(totallength, dtype='datetime64[D]')
                Dateaxis[0] = StartDate
                for idate in range(1, totallength):
                    Dateaxis[idate] = Dateaxis[idate - 1] + np.timedelta64(Dailyunit, 'D')
            else:
                Dateplot = False
                datemin = 0.0
                datemax = maxplot

            sumreal = 0.0
            sumerror = 0.0
            for itime in range(0, Num_Seq):
                sumreal += abs(real[PlottedIndex, iValTrain, itime])
                sumerror += error[PlottedIndex, iValTrain, itime]
            c_error = round(100.0 * sumerror / sumreal, 2)

            if UseRealDatesonplots:
                eachplt.plot(Dateaxis[0:real.shape[-1]], real[PlottedIndex, iValTrain, :], label=f'real')
                eachplt.plot(Dateaxis, predict[PlottedIndex, iValTrain, :], label='prediction')
                eachplt.plot(Dateaxis[0:error.shape[-1]], error[PlottedIndex, iValTrain, :], label=f'error', color="red")
                for others in range(0, otherlen):
                    eachplt.plot(Dateaxis[0:otherpredict.shape[-1]], otherpredict[others, PlottedIndex, iValTrain, :],
                                 label=otherlabs[others])

                if fill:
                    eachplt.fill_between(Dateaxis[0:predictsmall.shape[-1]], predictsmall[PlottedIndex, iValTrain, :],
                                         real[PlottedIndex, iValTrain, :], alpha=0.1, color="grey")
                    eachplt.fill_between(Dateaxis[0:error.shape[-1]], error[PlottedIndex, iValTrain, :], alpha=0.05,
                                         color="red")

            else:
                eachplt.plot(real[PlottedIndex, iValTrain, :], label=f'real')
                eachplt.plot(predict[PlottedIndex, iValTrain, :], label='prediction')
                eachplt.plot(error[PlottedIndex, iValTrain, :], label=f'error', color="red")
                for others in range(0, otherlen):
                    eachplt.plot(otherpredict[others, PlottedIndex, iValTrain, :], label=otherlabs[others])

                if fill:
                    eachplt.fill_between(xsmall, predictsmall[PlottedIndex, iValTrain, :], real[PlottedIndex, iValTrain, :],
                                         alpha=0.1, color="grey")
                    eachplt.fill_between(xsmall, error[PlottedIndex, iValTrain, :], alpha=0.05, color="red")

            if Earthquake and AddSpecialstoSummedplots:
                if NumberValTrainLoops == 2:
                    if iValTrain == 0:
                        Addfixedearthquakes(eachplt, datemin, datemax, quakecolor='black', Dateplot=Dateplot,
                                            vetoquake=PrimaryTrainingvetoquake)
                        Addfixedearthquakes(eachplt, datemin, datemax, quakecolor='purple', Dateplot=Dateplot,
                                            vetoquake=SecondaryTrainingvetoquake)
                    else:
                        Addfixedearthquakes(eachplt, datemin, datemax, quakecolor='black', Dateplot=Dateplot,
                                            vetoquake=PrimaryValidationvetoquake)
                        Addfixedearthquakes(eachplt, datemin, datemax, quakecolor='purple', Dateplot=Dateplot,
                                            vetoquake=SecondaryValidationvetoquake)
                else:
                    vetoquake = np.full(numberspecialeqs, False, dtype=np.bool)
                    Addfixedearthquakes(eachplt, datemin, datemax, quakecolor='black', Dateplot=Dateplot,
                                        vetoquake=vetoquake)

            extrastring = Overalllabel + current_time + ' ' + RunName + " "
            extrastring += f"Length={Num_Seq}, Location Summed Results {Predictionbasicname[ActualObservable]}, "
            yaxislabel = Predictionbasicname[ActualObservable]
            if JournalSimplePrint:
                extrastring = Overalllabel + ' ' + RunName + " "
            newyaxislabel = ""
            if selectedfuture > 0:
                yaxislabel = Predictionname[PredictionNameIndex[PredictedPos]]
                extrastring += " FUTURE " + yaxislabel
                if JournalSimplePrint:
                    newyaxislabel = yaxislabel.replace("Now", "at Now +")
                    newyaxislabel = newyaxislabel.replace("Back", "Back from Now +")
                else:
                    newyaxislabel = yaxislabel.replace("Months", "Months\n")
                    newyaxislabel = newyaxislabel.replace("weeks", "weeks\n")
                    newyaxislabel = newyaxislabel.replace("year", "year\n")
                    eachplt.text(0.05, 0.75, "FUTURE \n" + newyaxislabel, transform=eachplt.transAxes, color="black",
                                 fontsize=FONTSIZE, fontweight='bold')
            else:
                extrastring += Predictionbasicname[ActualObservable]
            if not JournalSimplePrint:
                extrastring += extracomments[PredictedPos][iValTrain]
            eachplt.set_title('\n'.join(wrap(extrastring, 130)), fontsize=FONTSIZE)
            if Dateplot:
                eachplt.set_xlabel('Years', fontsize=FONTSIZE)
            else:
                eachplt.set_xlabel(TimeIntervalUnitName + 's', fontsize=FONTSIZE)
            eachplt.set_ylabel(yaxislabel, color="black", fontweight='bold', fontsize=FONTSIZE)
            if JournalSimplePrint:
                eachplt.tick_params(axis='both', labelsize=FONTSIZE)
                eachplt.tick_params('x', direction='in', length=15, width=3, which='major')
                eachplt.tick_params('y', direction='in', length=10, width=3, which='major')
                if ActualObservable >= 2:
                    loclabel = 'center right'
                    eachplt.legend(fontsize=FONTSIZE, loc=loclabel, bbox_to_anchor=(0.5, 0., 0.5, 0.5))
                else:
                    loclabel = 'center left'
                    eachplt.legend(fontsize=FONTSIZE, loc=loclabel)
            else:
                eachplt.legend()
            eachplt.grid(False)

        figure.tight_layout()
        if Dumpplot and Dumpoutkeyplotsaspics:
            VT = 'Both'
            if NumberValTrainLoops == 1:
                VT = 'Full'
            plt.savefig(APPLDIR + '/Outputs/DLResults' + VT + str(PredictedPos) + RunName + '.png ', format='png')
        mysavefig("")
        plt.show()

    # Produce more detailed plots in time
    # ONLY done for first quantity as needed in HYdrology
    splitsize = Plotsplitsize
    if splitsize <= 1:
        return
    Numpoints = math.floor((Num_Seq + 0.001) / splitsize)
    extraone = Num_Seq % Numpoints

    neededrows = math.floor((splitsize * NumberValTrainLoops + 1.1) / 2)
    iValTrain = -1
    PlottedIndex = 0
    iseqnew = 0
    counttimes = 0
    for rowloop in range(0, neededrows):
        plt.rcParams["figure.figsize"] = [16, 6]
        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)
        for kplot in range(0, 2):
            if NumberValTrainLoops == 2:
                iValTrain = kplot
            else:
                iValTrain = 0
            Overalllabel = setValTrainlabel(iValTrain)
            eachplt = ax1
            if kplot == 1:
                eachplt = ax2
            sumreal = 0.0
            sumerror = 0.0

            if iValTrain == 0:
                iseqold = iseqnew
                iseqnew = iseqold + Numpoints
                if counttimes < extraone:
                    iseqnew += 1
                counttimes += 1
            for itime in range(iseqold, iseqnew):
                sumreal += abs(real[PlottedIndex, iValTrain, itime])
                sumerror += error[PlottedIndex, iValTrain, itime]
            c_error = round(100.0 * sumerror / sumreal, 2)

            eachplt.plot(xsmall[iseqold:iseqnew], predict[PlottedIndex, iValTrain, iseqold:iseqnew], label='prediction')
            eachplt.plot(xsmall[iseqold:iseqnew], real[PlottedIndex, iValTrain, iseqold:iseqnew], label=f'real')
            eachplt.plot(xsmall[iseqold:iseqnew], error[PlottedIndex, iValTrain, iseqold:iseqnew], label=f'error',
                         color="red")

            if fill:
                eachplt.fill_between(xsmall[iseqold:iseqnew], predictsmall[PlottedIndex, iValTrain, iseqold:iseqnew],
                                     real[PlottedIndex, iValTrain, iseqold:iseqnew], alpha=0.1, color="grey")
                eachplt.fill_between(xsmall[iseqold:iseqnew], error[PlottedIndex, iValTrain, iseqold:iseqnew], alpha=0.05,
                                     color="red")

            extrastring = Overalllabel + current_time + ' ' + RunName + " " + f"Range={iseqold}, {iseqnew} Rel Error {c_error} Location Summed Results {Predictionbasicname[PredictedPos]}, "
            eachplt.set_title('\n'.join(wrap(extrastring, 70)))
            eachplt.set_xlabel(TimeIntervalUnitName + 's')
            eachplt.set_ylabel(Predictionbasicname[PredictedPos])
            eachplt.grid(True)
            eachplt.legend()
        figure.tight_layout()
        plt.show()


def normalizeforplot(casesdeath, Locationindex, value):
    if np.math.isnan(value):
        return value
    if Plotrealnumbers:
        predaveragevaluespointer = PredictionAverageValuesPointer[casesdeath]
        newvalue = value / QuantityStatistics[predaveragevaluespointer, 2] + QuantityStatistics[predaveragevaluespointer, 0]
        rootflag = QuantityTakeroot[predaveragevaluespointer]
        if rootflag == 2:
            newvalue = newvalue ** 2
        if rootflag == 3:
            newvalue = newvalue ** 3
    else:
        newvalue = value
    if PopulationNorm:
        newvalue *= Locationpopulation[Locationindex]
    return newvalue


# PLOT individual city data
def plot_by_fips(fips, Observations, FitPredictions, dots=True, fill=True):
    Locationindex = FIPSintegerlookup[fips]
    current_time = timenow()
    print(startbold + startred + current_time + ' plot by location ' + str(Locationindex) + ' ' + str(fips) + ' ' +
          Locationname[Locationindex] + ' ' + RunName + ' ' + RunComment + resetfonts)

    basiclength = Num_Seq
    predictlength = LengthFutures
    if not UseFutures:
        predictlength = 0
    totallength = basiclength + predictlength
    real = np.zeros([NumpredbasicperTime, basiclength])
    predictsmall = np.zeros([NumpredbasicperTime, basiclength])
    predict = np.zeros([NumpredbasicperTime, totallength])

    for PredictedQuantity in range(0, NumpredbasicperTime):
        for itime in range(0, Num_Seq):
            if np.math.isnan(Observations[itime, Locationindex, PredictedQuantity]):
                Observations[itime, Locationindex, PredictedQuantity] = FitPredictions[
                    itime, Locationindex, PredictedQuantity]
            else:
                real[PredictedQuantity, itime] = normalizeforplot(PredictedQuantity, Locationindex,
                                                                  Observations[itime, Locationindex, PredictedQuantity])
                predict[PredictedQuantity, itime] = normalizeforplot(PredictedQuantity, Locationindex, FitPredictions[
                    itime, Locationindex, PredictedQuantity])
        if FuturedPointer[PredictedQuantity] >= 0:
            for ifuture in range(0, LengthFutures):
                jfuture = NumpredbasicperTime + NumpredFuturedperTime * ifuture
                predict[PredictedQuantity, Num_Seq + ifuture] += normalizeforplot(PredictedQuantity, Locationindex,
                                                                                  FitPredictions[
                                                                                      itime, Locationindex, FuturedPointer[
                                                                                          PredictedQuantity] + jfuture])
        for itime in range(0, basiclength):
            predictsmall[PredictedQuantity, itime] = predict[PredictedQuantity, itime]

    error = np.absolute(real - predictsmall)
    xsmall = np.arange(0, Num_Seq)

    neededrows = math.floor((NumpredbasicperTime + 1.1) / 2)
    iplot = -1
    for rowloop in range(0, neededrows):
        plt.rcParams["figure.figsize"] = [16, 6]
        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)
        for kplot in range(0, 2):
            iplot += 1
            if iplot > (NumpredbasicperTime - 1):
                iplot = NumpredbasicperTime - 1
            eachplt = ax1
            if kplot == 1:
                eachplt = ax2

            sumreal = 0.0
            sumerror = 0.0
            for itime in range(0, Num_Seq):
                sumreal += abs(real[iplot, itime])
                sumerror += error[iplot, itime]
            c_error = round(100.0 * sumerror / sumreal, 2)
            RMSEstring = ''
            if not Plotrealnumbers:
                sumRMSE = 0.0
                count = 0.0
                for itime in range(0, Num_Seq):
                    sumRMSE += (real[iplot, itime] - predict[iplot, itime]) ** 2
                    count += 1.0
                RMSE_error = round(100.0 * sumRMSE / count, 4)
                RMSEstring = ' RMSE ' + str(RMSE_error)

            x = list(range(0, totallength))
            if dots:
                eachplt.scatter(x, predict[iplot])
                eachplt.scatter(xsmall, real[iplot])

            eachplt.plot(predict[iplot], label=f'{fips} prediction')
            eachplt.plot(real[iplot], label=f'{fips} real')
            eachplt.plot(error[iplot], label=f'{fips} error', color="red")
            if fill:
                eachplt.fill_between(xsmall, predictsmall[iplot], real[iplot], alpha=0.1, color="grey")
                eachplt.fill_between(xsmall, error[iplot], alpha=0.05, color="red")

            name = Locationname[Locationindex]
            if Plotrealnumbers:
                name = "Actual Numbers " + name
            stringpopulation = " "
            if not Hydrology:
                stringpopulation = " Population " + str(Locationpopulation[Locationindex])

            titlestring = current_time + ' ' + RunName + f" {name}, Label={fips}" + stringpopulation + f" Length={Num_Seq}, Abs Rel Error={c_error}%" + RMSEstring + ' ' + RunName
            eachplt.set_title('\n'.join(wrap(titlestring, 70)))
            eachplt.set_xlabel(TimeIntervalUnitName + 's')
            eachplt.set_ylabel(Predictionbasicname[iplot])
            eachplt.grid(True)
            eachplt.legend()

        figure.tight_layout()
        plt.show();


def cumulative_error(real, predicted):
    error = np.absolute(real - predicted).sum()
    basevalue = np.absolute(real).sum()
    return 100.0 * error / basevalue


# Plot summed results by Prediction Type
# selectedfuture one more than usual future index
def plot_by_futureindex(selectedfuture, Observations, FitPredictions, fill=True, extrastring=''):
    current_time = timenow()
    print(startbold + startred + current_time + ' plot by Future Index ' + str(
        selectedfuture) + ' ' + RunName + ' ' + RunComment + resetfonts)

    selectedfield = NumpredbasicperTime + NumpredFuturedperTime * (selectedfuture - 1)
    if selectedfuture == 0:
        selectedfield = 0
    real = np.zeros([NumpredFuturedperTime, Num_Seq])
    predictsmall = np.zeros([NumpredFuturedperTime, Num_Seq])
    validdata = 0

    for PredictedQuantity in range(0, NumpredFuturedperTime):
        for iloc in range(0, Nloc):
            for itime in range(0, Num_Seq):
                real[PredictedQuantity, itime] += Observations[itime, iloc, selectedfield + PredictedQuantity]
                predictsmall[PredictedQuantity, itime] += FitPredictions[itime, iloc, selectedfield + PredictedQuantity]
        for itime in range(0, Num_Seq):
            if np.math.isnan(real[PredictedQuantity, itime]):
                real[PredictedQuantity, itime] = predictsmall[PredictedQuantity, itime]
            else:
                if PredictedQuantity == 0:
                    validdata += 1

    error = np.absolute(real - predictsmall)
    xsmall = np.arange(0, Num_Seq)

    neededrows = math.floor((NumpredFuturedperTime + 1.1) / 2)
    iplot = -1
    for rowloop in range(0, neededrows):
        plt.rcParams["figure.figsize"] = [16, 6]
        figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)
        for kplot in range(0, 2):
            iplot += 1
            if iplot > (NumpredbasicperTime - 1):
                iplot = NumpredbasicperTime - 1
            eachplt = ax1
            if kplot == 1:
                eachplt = ax2
            sumreal = 0.0
            sumerror = 0.0
            for itime in range(0, Num_Seq):
                sumreal += abs(real[iplot, itime])
                sumerror += error[iplot, itime]
            c_error = round(100.0 * sumerror / sumreal, 2)

            eachplt.plot(predictsmall[iplot, :], label='prediction')
            eachplt.plot(real[iplot, :], label=f'real')
            eachplt.plot(error[iplot, :], label=f'error', color="red")

            if fill:
                eachplt.fill_between(xsmall, predictsmall[iplot, :], real[iplot, :], alpha=0.1, color="grey")
                eachplt.fill_between(xsmall, error[iplot, :], alpha=0.05, color="red")
            errorstring = " Error % " + str(c_error)
            printstring = current_time + " Future Index " + str(selectedfuture) + " " + RunName
            printstring += " " + f"Length={Num_Seq}, Location Summed Results {Predictionbasicname[iplot]}, " + errorstring + " " + extrastring
            eachplt.set_title('\n'.join(wrap(printstring, 70)))
            eachplt.set_xlabel(TimeIntervalUnitName + 's')
            eachplt.set_ylabel(Predictionbasicname[iplot])
            eachplt.grid(True)
            eachplt.legend()
        figure.tight_layout()
        plt.show()


"""###Calculate NNSE

"""


def mean_absolute_error(y_true, y_pred):
    return np.mean(np.abs(y_true - y_pred))


def root_mean_squared_error(y_true, y_pred):
    return np.sqrt(np.mean(np.square(y_true - y_pred)))


def normalized_nash_sutcliffe_efficiencySTavg(y_true, y_pred):  # axis 0 space 1 time
    NSE = 1 - np.sum(np.square(y_true - y_pred)) / np.sum(np.square(y_true - np.mean(y_true)))
    return 1 / (2 - NSE)


def normalized_nash_sutcliffe_efficiencySsum(y_true, y_pred):  # axis 0 space 1 time
    NSE = 1 - np.sum(np.square(np.sum(y_true, axis=0) - np.sum(y_pred, axis=0))) / np.sum(
        np.square(np.sum(y_true, axis=0) - np.mean(np.sum(y_true, axis=0))))
    return 1 / (2 - NSE)


def symmetric_mean_absolute_percentage(y_true, y_pred):
    value = 2 * abs(y_true - y_pred) / (abs(y_true) + abs(y_pred))
    # for cases when both ground truth and predicted value are zero
    value = np.where(np.isnan(value), 0, value)
    return np.mean(value)


# Calculate NNSE
# Sum (Obsevations - Mean)^2 / [Sum (Obsevations - Mean)^2 + Sum(Observations-Predictions)^2]
def FindNNSE(Observations, FitPredictions, Label=''):
    NNSEList = np.empty(NpredperseqTOT, dtype=np.int)
    NumberNNSEcalc = 0
    for ipred in range(0, NpredperseqTOT):
        if CalculateNNSE[ipred]:
            NNSEList[NumberNNSEcalc] = ipred
            NumberNNSEcalc += 1
    if NumberNNSEcalc == 0:
        return
    StoreNNSE = np.zeros([Nloc, NumberNNSEcalc], dtype=np.float64)
    YTRUE = np.zeros([Nloc, Num_Seq, NumberNNSEcalc], dtype=np.float64)
    YPRED = np.zeros([Nloc, Num_Seq, NumberNNSEcalc], dtype=np.float64)

    current_time = timenow()
    print(wraptotext(
        startbold + startred + current_time + ' Calculate NNSE ' + Label + ' ' + RunName + ' ' + RunComment + resetfonts))
    for NNSEpredindex in range(0, NumberNNSEcalc):
        PredictedQuantity = NNSEList[NNSEpredindex]
        averageNNSE = 0.0
        averageNNSETraining = 0.0
        averageNNSEValidation = 0.0
        line = ''
        for Locationindex in range(0, Nloc):
            QTObssq = 0.0
            QTDiffsq = 0.0
            QTObssum = 0.0
            for itime in range(0, Num_Seq):
                Observed = Observations[itime, Locationindex, PredictedQuantity]
                if np.math.isnan(Observed):
                    Observed = FitPredictions[itime, Locationindex, PredictedQuantity]
                real = normalizeforplot(PredictedQuantity, Locationindex, Observed)
                predict = normalizeforplot(PredictedQuantity, Locationindex, FitPredictions[itime,
                                                                                            Locationindex, PredictedQuantity])
                YTRUE[Locationindex, itime, NNSEpredindex] = real
                YPRED[Locationindex, itime, NNSEpredindex] = predict
                QTObssq += real ** 2
                QTDiffsq += (real - predict) ** 2
                QTObssum += real
            Obsmeasure = QTObssq - (QTObssum ** 2 / Num_Seq)
            StoreNNSE[Locationindex, NNSEpredindex] = Obsmeasure / (Obsmeasure + QTDiffsq)
            if MappingtoTraining[Locationindex] >= 0:
                averageNNSETraining += StoreNNSE[Locationindex, NNSEpredindex]
            if MappingtoValidation[Locationindex] >= 0:
                averageNNSEValidation += StoreNNSE[Locationindex, NNSEpredindex]
            averageNNSE += StoreNNSE[Locationindex, NNSEpredindex]
            line += str(round(StoreNNSE[Locationindex, NNSEpredindex], 3)) + ' '

        if ValidationNloc > 0:
            averageNNSEValidation = averageNNSEValidation / ValidationNloc
        averageNNSETraining = averageNNSETraining / TrainingNloc
        averageNNSE = averageNNSE / Nloc

        # Location Summed
        QTObssq = 0.0
        QTDiffsq = 0.0
        QTObssum = 0.0
        QTObssqT = 0.0
        QTDiffsqT = 0.0
        QTObssumT = 0.0
        QTObssqV = 0.0
        QTDiffsqV = 0.0
        QTObssumV = 0.0
        for itime in range(0, Num_Seq):
            real = 0.0
            predict = 0.0
            realT = 0.0
            predictT = 0.0
            realV = 0.0
            predictV = 0.0
            for Locationindex in range(0, Nloc):
                Observed = Observations[itime, Locationindex, PredictedQuantity]
                if np.math.isnan(Observed):
                    Observed = FitPredictions[itime, Locationindex, PredictedQuantity]
                localreal = normalizeforplot(PredictedQuantity, Locationindex, Observed)
                localpredict = normalizeforplot(PredictedQuantity, Locationindex, FitPredictions[itime,
                                                                                                 Locationindex, PredictedQuantity])
                real += localreal
                predict += localpredict
                if MappingtoTraining[Locationindex] >= 0:
                    realT += localreal
                    predictT += localpredict
                if MappingtoValidation[Locationindex] >= 0:
                    realV += localreal
                    predictV += localpredict

            QTObssq += real ** 2
            QTDiffsq += (real - predict) ** 2
            QTObssum += real
            QTObssqT += realT ** 2
            QTDiffsqT += (realT - predictT) ** 2
            QTObssumT += realT
            QTObssqV += realV ** 2
            QTDiffsqV += (realV - predictV) ** 2
            QTObssumV += realV
        Obsmeasure = QTObssq - (QTObssum ** 2 / Num_Seq)
        SummedNNSE = Obsmeasure / (Obsmeasure + QTDiffsq)
        ObsmeasureT = QTObssqT - (QTObssumT ** 2 / Num_Seq)
        SummedNNSET = ObsmeasureT / (ObsmeasureT + QTDiffsqT)
        ObsmeasureV = QTObssqV - (QTObssumV ** 2 / Num_Seq)
        if ValidationNloc > 0:
            SummedNNSEV = ObsmeasureV / (ObsmeasureV + QTDiffsqV)
        else:
            SummedNNSEV = 0.0

        line = ''
        if PredictedQuantity >= NumpredbasicperTime:
            line = startred + 'Future ' + resetfonts
        print(wraptotext(line + 'NNSE ' + startbold + Label + ' ' + str(PredictedQuantity) + ' ' + Predictionname[
            PredictionNameIndex[PredictedQuantity]] + startred + ' Averaged ' +
                         str(round(averageNNSE, 3)) + resetfonts + ' Training ' + str(round(averageNNSETraining, 3)) +
                         ' Validation ' + str(round(averageNNSEValidation, 3)) + startred + startbold + ' Summed ' +
                         str(round(SummedNNSE, 3)) + resetfonts + ' Training ' + str(round(SummedNNSET, 3)) +
                         ' Validation ' + str(round(SummedNNSEV, 3)), size=200))

    for NNSEpredindex in range(0, NumberNNSEcalc):
        PredictedQuantity = NNSEList[NNSEpredindex]
        MAE = mean_absolute_error(YTRUE[:, :, NNSEpredindex], YPRED[:, :, NNSEpredindex])
        RMS = root_mean_squared_error(YTRUE[:, :, NNSEpredindex], YPRED[:, :, NNSEpredindex])
        NNSE1 = normalized_nash_sutcliffe_efficiencySsum(YTRUE[:, :, NNSEpredindex], YPRED[:, :, NNSEpredindex])
        NNSE2 = normalized_nash_sutcliffe_efficiencySTavg(YTRUE[:, :, NNSEpredindex], YPRED[:, :, NNSEpredindex])
        SMAP = symmetric_mean_absolute_percentage(YTRUE[:, :, NNSEpredindex], YPRED[:, :, NNSEpredindex])

        line = ''
        if PredictedQuantity >= NumpredbasicperTime:
            line = startred + 'Future ' + resetfonts
        print(wraptotext(line + startbold + Label + ' ' + str(PredictedQuantity) + ' ' + Predictionname[
            PredictionNameIndex[PredictedQuantity]] + resetfonts + ' MAE ' +
                         str(round(MAE, 5)) + ' RMS ' + str(round(RMS, 5)) + ' NNSE Space Sum ' + str(
            round(NNSE1, 5)) + ' NNSE Space-Time Avg ' +
                         str(round(NNSE2, 5)) + ' SMAP ' + str(round(SMAP, 5)), size=200))


def weightedcustom_lossGCF1(y_actual, y_pred, sample_weight):
    tupl = np.shape(y_actual)

    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    sw = sample_weight[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.reduce_sum(tf.multiply(tf.math.square(y_actual - y_pred), sw))
    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


def numpycustom_lossGCF1(y_actual, y_pred, sample_weight):
    tupl = np.shape(y_actual)

    flagGCF = np.isnan(y_actual)
    y_actual = y_actual[np.logical_not(flagGCF)]
    y_pred = y_pred[np.logical_not(flagGCF)]
    sw = sample_weight[np.logical_not(flagGCF)]
    tensordiff = np.sum(np.multiply(np.square(y_actual - y_pred), sw))
    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


def weightedcustom_lossGCF1(y_actual, y_pred, sample_weight):
    tupl = np.shape(y_actual)

    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    sw = sample_weight[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.reduce_sum(tf.multiply(tf.math.square(y_actual - y_pred), sw))
    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


"""### Custom Loss Functions"""


def custom_lossGCF1(y_actual, y_pred):
    tupl = np.shape(y_actual)
    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.reduce_sum(tf.math.square(y_actual - y_pred))

    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


@tf.autograph.experimental.do_not_convert
def custom_lossGCF1spec(y_actual, y_pred):
    global tensorsw
    tupl = np.shape(y_actual)
    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    sw = tensorsw[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.reduce_sum(tf.multiply(tf.math.square(y_actual - y_pred), sw))

    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


def custom_lossGCF1A(y_actual, y_pred):
    print(np.shape(y_actual), np.shape(y_pred))
    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.square(y_actual - y_pred)
    return tf.math.reduce_mean(tensordiff)


# Basic TF does NOT supply sample_weight
def custom_lossGCF1B(y_actual, y_pred, sample_weight=None):
    tupl = np.shape(y_actual)

    flagGCF = tf.math.is_nan(y_actual)
    y_actual = y_actual[tf.math.logical_not(flagGCF)]
    y_pred = y_pred[tf.math.logical_not(flagGCF)]
    sw = sample_weight[tf.math.logical_not(flagGCF)]
    tensordiff = tf.math.reduce_sum(tf.multiply(tf.math.square(y_actual - y_pred), sw))
    if len(tupl) >= 2:
        tensordiff /= tupl[0]
    if len(tupl) >= 3:
        tensordiff /= tupl[1]
    if len(tupl) >= 4:
        tensordiff /= tupl[2]
    return tensordiff


def custom_lossGCF4(y_actual, y_pred):
    tensordiff = y_actual - y_pred
    newtensordiff = tf.where(tf.math.is_nan(tensordiff), tf.zeros_like(tensordiff), tensordiff)
    return tf.math.reduce_mean(tf.math.square(newtensordiff))


"""### Utility: Shuffle, Finalize"""


def SetSpacetime(BasicTimes):
    global GlobalTimeMask
    Time = None
    if (MaskingOption == 0) or (not GlobalSpacetime):
        return Time
    NumTOTAL = BasicTimes.shape[1]
    BasicTimes = BasicTimes.astype(np.int16)
    BasicTimes = np.reshape(BasicTimes, (BasicTimes.shape[0], NumTOTAL, 1))
    addons = np.arange(0, Tseq, dtype=np.int16)
    addons = np.reshape(addons, (1, 1, Tseq))
    Time = BasicTimes + addons
    Time = np.reshape(Time, (BasicTimes.shape[0], NumTOTAL * Tseq))
    BasicPureTime = np.arange(0, Tseq, dtype=np.int16)
    BasicPureTime = np.reshape(BasicPureTime, (Tseq, 1))
    GlobalTimeMask = tf.where((BasicPureTime - np.transpose(BasicPureTime)) > 0, 0.0, 1.0)
    GlobalTimeMask = np.reshape(GlobalTimeMask, (1, 1, 1, Tseq, Tseq))
    return Time


def shuffleDLinput(Xin, yin, AuxiliaryArray=None, Spacetime=None):
    # Auxiliary array could be weight or location/time tracker
    # These are per batch so sorted axis is first

    np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))
    trainingorder = list(range(0, len(Xin)))
    random.shuffle(trainingorder)

    Xinternal = list()
    yinternal = list()
    if AuxiliaryArray is not None:
        AuxiliaryArrayinternal = list()
    if Spacetime is not None:
        Spacetimeinternal = list()
    for i in trainingorder:
        Xinternal.append(Xin[i])
        yinternal.append(yin[i])
        if AuxiliaryArray is not None:
            AuxiliaryArrayinternal.append(AuxiliaryArray[i])
        if Spacetime is not None:
            Spacetimeinternal.append(Spacetime[i])
    X = np.array(Xinternal)
    y = np.array(yinternal)
    if (AuxiliaryArray is None) and (Spacetime is None):
        return X, y
    if (AuxiliaryArray is not None) and (Spacetime is None):
        AA = np.array(AuxiliaryArrayinternal)
        return X, y, AA
    if (AuxiliaryArray is None) and (Spacetime is not None):
        St = np.array(Spacetimeinternal)
        return X, y, St
    AA = np.array(AuxiliaryArrayinternal)
    St = np.array(Spacetimeinternal)
    return X, y, AA, St


# Simple Plot of Loss from history
def finalizeDL(ActualModel, recordtrainloss, recordvalloss, validationfrac, X_in, y_in, modelflag, LabelFit=''):
    # Ouput Loss v Epoch
    histlen = len(recordtrainloss)
    trainloss = recordtrainloss[histlen - 1]
    plt.rcParams["figure.figsize"] = [8, 6]
    plt.plot(recordtrainloss)
    if (validationfrac > 0.001) and len(recordvalloss) > 0:
        valloss = recordvalloss[histlen - 1]
        plt.plot(recordvalloss)
    else:
        valloss = 0.0

    current_time = timenow()
    print(startbold + startred + current_time + ' ' + RunName + ' finalizeDL ' + RunComment + resetfonts)
    plt.title(LabelFit + ' ' + RunName + ' model loss ' + str(round(trainloss, 7)) + ' Val ' + str(round(valloss, 7)))
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.yscale("log")
    plt.grid(True)
    plt.legend(['train', 'val'], loc='upper left')
    plt.show()

    # Setup TFT
    if modelflag == 2:
        global SkipDL2F, IncreaseNloc_sample, DecreaseNloc_sample
        SkipDL2F = True
        IncreaseNloc_sample = 1
        DecreaseNloc_sample = 1
        TFToutput_map = TFTpredict(TFTmodel, TFTtest_datacollection)
        VisualizeTFT(TFTmodel, TFToutput_map)
    else:
        FitPredictions = DLprediction(X_in, y_in, ActualModel, modelflag, LabelFit=LabelFit)
        for debugfips in ListofTestFIPS:
            if debugfips != '':
                debugfipsoutput(debugfips, FitPredictions, X_in, y_in)
    return


def debugfipsoutput(debugfips, FitPredictions, Xin, Observations):
    print(startbold + startred + 'debugfipsoutput for ' + str(debugfips) + RunName + ' ' + RunComment + resetfonts)
    # Set Location Number in Arrays
    LocationNumber = FIPSstringlookup[debugfips]

    # Sequences to look at
    Seqcount = 5
    Seqnumber = np.empty(Seqcount, dtype=np.int)
    Seqnumber[0] = 0
    Seqnumber[1] = int(Num_Seq / 4) - 1
    Seqnumber[2] = int(Num_Seq / 2) - 1
    Seqnumber[3] = int((3 * Num_Seq) / 4) - 1
    Seqnumber[4] = Num_Seq - 1

    # Window Positions to look at
    Wincount = 5
    Winnumber = np.empty(Wincount, dtype=np.int)
    Winnumber[0] = 0
    Winnumber[1] = int(Tseq / 4) - 1
    Winnumber[2] = int(Tseq / 2) - 1
    Winnumber[3] = int((3 * Tseq) / 4) - 1
    Winnumber[4] = Tseq - 1

    if SymbolicWindows:
        InputSequences = np.empty([Seqcount, Wincount, NpropperseqTOT], dtype=np.float32)
        for jseq in range(0, Seqcount):
            iseq = Seqnumber[jseq]
            for jwindow in range(0, Wincount):
                window = Winnumber[jwindow]
                InputSequences[jseq, jwindow] = Xin[LocationNumber, iseq + jseq]
    else:
        InputSequences = Xin

        # Location Info

    print('\n' + startbold + startred + debugfips + ' # ' + str(LocationNumber) + ' ' +
          Locationname[LocationNumber] + ' ' + Locationstate[LocationNumber] + ' Pop '
          + str(Locationpopulation[LocationNumber]) + resetfonts)
    plot_by_fips(int(debugfips), Observations, FitPredictions)

    # Print Input Data to Test
    # Static Properties
    print(startbold + startred + 'Static Properties ' + debugfips + ' ' +
          Locationname[LocationNumber] + resetfonts)
    line = ''
    for iprop in range(0, NpropperTimeStatic):
        if SymbolicWindows:
            val = InputSequences[0, 0, iprop]
        else:
            val = InputSequences[0, LocationNumber, 0, iprop]
        line += startbold + InputPropertyNames[PropertyNameIndex[iprop]] + resetfonts + ' ' + str(round(val, 3)) + ' '
    print('\n'.join(wrap(line, 200)))

    # Dynamic Properties
    for iprop in range(NpropperTimeStatic, NpropperTime):
        print('\n')
        for jwindow in range(0, Wincount):
            window = Winnumber[jwindow]
            line = startbold + InputPropertyNames[PropertyNameIndex[iprop]] + ' W= ' + str(window) + resetfonts
            for jseq in range(0, Seqcount):
                iseq = Seqnumber[jseq]
                line += startbold + startred + ' ' + str(iseq) + ')' + resetfonts
                if SymbolicWindows:
                    val = InputSequences[jseq, jwindow, iprop]
                else:
                    val = InputSequences[iseq, LocationNumber, window, iprop]
                line += ' ' + str(round(val, 3))
            print('\n'.join(wrap(line, 200)))

    # Total Input
    print('\n')
    line = startbold + 'Props: ' + resetfonts
    for iprop in range(0, NpropperseqTOT):
        if iprop % 5 == 0:
            line += startbold + startred + ' ' + str(iprop) + ')' + resetfonts
        line += ' ' + InputPropertyNames[PropertyNameIndex[iprop]]
    print('\n'.join(wrap(line, 200)))
    for jseq in range(0, Seqcount):
        iseq = Seqnumber[jseq]
        for jwindow in range(0, Wincount):
            window = Winnumber[jwindow]
            line = startbold + 'Input: All in Seq ' + str(iseq) + ' W= ' + str(window) + resetfonts
            for iprop in range(0, NpropperseqTOT):
                if iprop % 5 == 0:
                    line += startbold + startred + ' ' + str(iprop) + ')' + resetfonts
                if SymbolicWindows:
                    val = InputSequences[jseq, jwindow, iprop]
                else:
                    val = InputSequences[iseq, LocationNumber, window, iprop]
                result = str(round(val, 3))
                line += ' ' + result
            print('\n'.join(wrap(line, 200)))

    # Total Prediction
    print('\n')
    line = startbold + 'Preds: ' + resetfonts
    for ipred in range(0, NpredperseqTOT):
        if ipred % 5 == 0:
            line += startbold + startred + ' ' + str(ipred) + ')' + resetfonts
        line += ' ' + Predictionname[PredictionNameIndex[ipred]]
    for jseq in range(0, Seqcount):
        iseq = Seqnumber[jseq]
        line = startbold + 'Preds: All in Seq ' + str(iseq) + resetfonts
        for ipred in range(0, NpredperseqTOT):
            fred = Observations[iseq, LocationNumber, ipred]
            if np.math.isnan(fred):
                result = 'NaN'
            else:
                result = str(round(fred, 3))
            if ipred % 5 == 0:
                line += startbold + startred + ' ' + str(ipred) + ')' + resetfonts
            line += ' ' + result
        print('\n'.join(wrap(line, 200)))


"""###DLPrediction2F Sensitivity"""


def printloss(name, mean, var, SampleSize, lineend=''):
    mean /= SampleSize
    var /= SampleSize
    std = math.sqrt(var - mean ** 2)
    print(name + ' Mean ' + str(round(mean, 5)) + ' Std Deviation ' + str(round(std, 7)) + ' ' + lineend)


def DLprediction2F(Xin, yin, DLmodel, modelflag):
    # Input is the windows [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT] (SymbolicWindows False)
    # Input is  the sequences [Nloc] [Num_Time-1] [NpropperseqTOT] (SymbolicWindows True)
    # Input Predictions are always [Num_Seq] [NLoc] [NpredperseqTOT]
    # Label Array is always [Num_Seq][Nloc] [0=Window(first sequence)#, 1=Location]

    if SkipDL2F:
        return
    if GarbageCollect:
        gc.collect()
    global OuterBatchDimension, Nloc_sample, d_sample, max_d_sample

    SensitivityAnalyze = np.full((NpropperseqTOT), False, dtype=np.bool)
    SensitivityChange = np.zeros((NpropperseqTOT), dtype=np.float32)
    SensitvitybyPrediction = False
    if ReadApril2021Covid:
        for iprop in range(0, NpropperseqTOT):
            if iprop >= 15:
                continue
            if modelflag == 2:
                SensitivityAnalyze[iprop] = DLmodel.CheckProperty(iprop)
                continue
            SensitivityAnalyze[iprop] = True
    if RunName == 'EARTHQ-EMA1LR7':
        for iprop in range(0, NpropperseqTOT):
            if (iprop > 21) or (iprop < 4):
                continue
            if modelflag == 2:
                SensitivityAnalyze[iprop] = DLmodel.CheckProperty(iprop)
                continue
            SensitivityAnalyze[iprop] = True
    if RunName == 'EARTHQ-EMA1LR8':
        for iprop in range(0, NpropperseqTOT):
            if (iprop > 13) or (iprop < 4):
                continue
            if modelflag == 2:
                SensitivityAnalyze[iprop] = DLmodel.CheckProperty(iprop)
                continue
            SensitivityAnalyze[iprop] = True

    something = 0
    SensitivityList = []
    for iprop in range(0, NpropperseqTOT):
        if SensitivityAnalyze[iprop]:
            something += 1
            SensitivityList.append(iprop)
    if something == 0:
        return
    ScaleProperty = 0.99
    SampleSize = 1

    SensitivityFitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT, 1 + something], dtype=np.float32)
    FRanges = np.full((NpredperseqTOT), 1.0, dtype=np.float32)
    current_time = timenow()
    print(wraptotext(startbold + startred + 'DLPrediction2F ' + current_time + ' ' + RunName + RunComment + resetfonts))

    sw = np.empty_like(yin, dtype=np.float32)
    for i in range(0, sw.shape[0]):
        for j in range(0, sw.shape[1]):
            for k in range(0, NpredperseqTOT):
                sw[i, j, k] = Predictionwgt[k]
    labelarray = np.empty([Num_Seq, Nloc, 2], dtype=np.int32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            labelarray[iseq, iloc, 0] = iseq
            labelarray[iseq, iloc, 1] = iloc

    Totaltodo = Num_Seq * Nloc
    Nloc_sample = Nloc  # default

    if IncreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
    elif DecreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)

    if Totaltodo % Nloc_sample != 0:
        printexit('Invalid Nloc_sample ' + str(Nloc_sample) + " " + str(Totaltodo))
    d_sample = Tseq * Nloc_sample
    max_d_sample = d_sample
    OuterBatchDimension = int(Totaltodo / Nloc_sample)
    print(' Predict with ' + str(Nloc_sample) + ' sequences per sample and batch size ' + str(OuterBatchDimension))

    print(startbold + startred + 'Sensitivity using Property ScaleFactor ' + str(round(ScaleProperty, 3)) + resetfonts)
    for Sensitivities in range(0, 1 + something):
        if Sensitivities == 0:  # BASIC unmodified run
            iprop = -1
            print(startbold + startred + 'Basic Predictions' + resetfonts)
            if SymbolicWindows:
                ReshapedSequencesTOTmodified = ReshapedSequencesTOT  # NOT used if modelflag == 2
                if modelflag == 2:
                    DLmodel.MakeMapping()
            else:
                Xinmodified = Xin
        else:
            iprop = SensitivityList[Sensitivities - 1]
            maxminplace = PropertyNameIndex[iprop]
            lastline = ''
            if iprop < Npropperseq:
                lastline = ' Normed Mean ' + str(round(QuantityStatistics[maxminplace, 5], 4))
            print(startbold + startred + 'Property ' + str(iprop) + ' ' + InputPropertyNames[
                maxminplace] + resetfonts + lastline)
            if SymbolicWindows:
                if modelflag == 2:
                    DLmodel.SetupProperty(iprop)
                    DLmodel.ScaleProperty(ScaleProperty)
                    DLmodel.MakeMapping()
                else:
                    ReshapedSequencesTOTmodified = np.copy(ReshapedSequencesTOT)
                    ReshapedSequencesTOTmodified[:, :, iprop] = ScaleProperty * ReshapedSequencesTOTmodified[:, :, iprop]
            else:
                Xinmodified = np.copy(Xin)
                Xinmodified[:, :, :, iprop] = ScaleProperty * Xinmodified[:, :, :, iprop]
        CountFitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
        meanvalue2 = 0.0
        meanvalue3 = 0.0
        meanvalue4 = 0.0
        variance2 = 0.0
        variance3 = 0.0
        variance4 = 0.0

        samplebar = notebook.trange(SampleSize, desc='Full Samples', unit='sample')
        bbar = notebook.trange(OuterBatchDimension, desc='Batch    loop', unit='sample')
        for shuffling in range(0, SampleSize):
            if GarbageCollect:
                gc.collect()
            yuse = yin
            labeluse = labelarray
            y2 = np.reshape(yuse, (-1, NpredperseqTOT)).copy()
            labelarray2 = np.reshape(labeluse, (-1, 2))

            if SymbolicWindows:
                # Xin X2 X3 not used rather ReshapedSequencesTOT
                labelarray2, y2 = shuffleDLinput(labelarray2, y2)
                ReshapedSequencesTOTuse = ReshapedSequencesTOTmodified
            else:
                Xuse = Xinmodified
                X2 = np.reshape(Xuse, (-1, Tseq, NpropperseqTOT)).copy()
                X2, y2, labelarray2 = shuffleDLinput(X2, y2, labelarray2)
                X3 = np.reshape(X2, (-1, d_sample, NpropperseqTOT))

            y3 = np.reshape(y2, (-1, Nloc_sample, NpredperseqTOT))
            sw = np.reshape(sw, (-1, Nloc_sample, NpredperseqTOT))
            labelarray3 = np.reshape(labelarray2, (-1, Nloc_sample, 2))

            quan2 = 0.0
            quan3 = 0.0
            quan4 = 0.0
            for Batchindex in range(0, OuterBatchDimension):
                if GarbageCollect:
                    gc.collect()

                if SymbolicWindows:
                    if modelflag == 2:  # Note first index of InputVector Location, Second is sequence number; labelarray3 is opposite
                        InputVector = np.empty((Nloc_sample, 2), dtype=np.int32)
                        for iloc_sample in range(0, Nloc_sample):
                            InputVector[iloc_sample, 0] = labelarray3[Batchindex, iloc_sample, 1]
                            InputVector[iloc_sample, 1] = labelarray3[Batchindex, iloc_sample, 0]
                    else:
                        X3local = list()
                        for iloc_sample in range(0, Nloc_sample):
                            LocLocal = labelarray3[Batchindex, iloc_sample, 1]
                            SeqLocal = labelarray3[Batchindex, iloc_sample, 0]
                            X3local.append(ReshapedSequencesTOTuse[LocLocal, SeqLocal:SeqLocal + Tseq])
                        InputVector = np.array(X3local)
                else:
                    InputVector = X3[Batchindex]

                Labelsused = labelarray3[Batchindex]
                Time = None
                if modelflag == 0:
                    InputVector = np.reshape(InputVector, (-1, Tseq, NpropperseqTOT))
                elif modelflag == 1:
                    Time = SetSpacetime(np.reshape(Labelsused[:, 0], (1, -1)))
                    InputVector = np.reshape(InputVector, (1, Tseq * Nloc_sample, NpropperseqTOT))
                PredictedVector = DLmodel(InputVector, training=PredictionTraining, Time=Time)
                PredictedVector = np.reshape(PredictedVector, (1, Nloc_sample, NpredperseqTOT))

                swbatched = sw[Batchindex, :, :]
                if LocationBasedValidation:
                    swT = np.zeros([1, Nloc_sample, NpredperseqTOT], dtype=np.float32)
                    swV = np.zeros([1, Nloc_sample, NpredperseqTOT], dtype=np.float32)
                    for iloc_sample in range(0, Nloc_sample):
                        fudgeT = Nloc / TrainingNloc
                        fudgeV = Nloc / ValidationNloc
                        iloc = Labelsused[iloc_sample, 1]
                        if MappingtoTraining[iloc] >= 0:
                            swT[0, iloc_sample, :] = swbatched[iloc_sample, :] * fudgeT
                        else:
                            swV[0, iloc_sample, :] = swbatched[iloc_sample, :] * fudgeV
                TrueVector = y3[Batchindex]
                TrueVector = np.reshape(TrueVector, (1, Nloc_sample, NpredperseqTOT))
                swbatched = np.reshape(swbatched, (1, Nloc_sample, NpredperseqTOT))

                losspercall = numpycustom_lossGCF1(TrueVector, PredictedVector, swbatched)
                quan2 += losspercall
                bbar.update(1)
                if LocationBasedValidation:
                    losspercallTr = numpycustom_lossGCF1(TrueVector, PredictedVector, swT)
                    quan3 += losspercallTr
                    losspercallVl = numpycustom_lossGCF1(TrueVector, PredictedVector, swV)
                    quan4 += losspercallVl

                for iloc_sample in range(0, Nloc_sample):
                    LocLocal = Labelsused[iloc_sample, 1]
                    SeqLocal = Labelsused[iloc_sample, 0]
                    yyhat = PredictedVector[0, iloc_sample]
                    CountFitPredictions[SeqLocal, LocLocal, :] += FRanges
                    SensitivityFitPredictions[SeqLocal, LocLocal, :, Sensitivities] += yyhat

                fudge = 1.0 / (1.0 + Batchindex)
                mean2 = quan2 * fudge
                if LocationBasedValidation:
                    mean3 = quan3 * fudge
                    mean4 = quan4 * fudge
                    bbar.set_postfix(AvLoss=mean2, AvTr=mean3, AvVl=mean4, Loss=losspercall, Tr=losspercallTr,
                                     Vl=losspercallVl)
                else:
                    bbar.set_postfix(Loss=losspercall, AvLoss=mean2)

                    # Processing at the end of Sampling Loop
            fudge = 1.0 / OuterBatchDimension
            quan2 *= fudge
            quan3 *= fudge
            quan4 *= fudge
            meanvalue2 += quan2
            variance2 += quan2 ** 2
            variance3 += quan3 ** 2
            variance4 += quan4 ** 2
            if LocationBasedValidation:
                meanvalue3 += quan3
                meanvalue4 += quan4
            samplebar.update(1)
            if LocationBasedValidation:
                samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Tr=quan3, Val=quan4)
            else:
                samplebar.set_postfix(Shuffle=shuffling, Loss=quan2)
            bbar.reset()
        # End Shuffling loop

        if Sensitivities == 0:
            iprop = -1
            lineend = startbold + startred + 'Basic Predictions' + resetfonts
        else:
            iprop = SensitivityList[Sensitivities - 1]
            nameplace = PropertyNameIndex[iprop]
            maxminplace = PropertyAverageValuesPointer[iprop]
            lastline = ' Normed Mean ' + str(round(QuantityStatistics[maxminplace, 5], 4))
            lineend = startbold + startred + 'Property ' + str(iprop) + ' ' + InputPropertyNames[
                nameplace] + resetfonts + lastline
            if modelflag == 2:
                DLmodel.ResetProperty()

        meanvalue2 /= SampleSize

        global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
        printloss(' Full Loss ', meanvalue2, variance2, SampleSize, lineend=lineend)
        meanvalue2 /= SampleSize
        GlobalLoss = meanvalue2
        GlobalTrainingLoss = 0.0
        GlobalValidationLoss = 0.0

        if LocationBasedValidation:
            printloss(' Training Loss ', meanvalue3, variance3, SampleSize, lineend=lineend)
            printloss(' Validation Loss ', meanvalue4, variance4, SampleSize, lineend=lineend)
            meanvalue3 /= SampleSize
            meanvalue4 /= SampleSize
            GlobalTrainingLoss = meanvalue3
            GlobalValidationLoss = meanvalue4

        if PlotinDL2F:
            label = 'Sensitivity ' + str(Sensitivities)
            extracomments = []
            for PredictedPos in range(0, NpredperseqTOT):
                labelfull = label + ' Pred ' + str(PredictedPos)
                extracomments.append([labelfull, labelfull])
            Location_summed_plot(0, yin, SensitivityFitPredictions[:, :, :, Sensitivities], extracomments=extracomments,
                                 Dumpplot=False)

        # Sequence Location Predictions
        SensitivityFitPredictions[:, :, :, Sensitivities] = np.divide(SensitivityFitPredictions[:, :, :, Sensitivities],
                                                                      CountFitPredictions[:, :, :])
        if Sensitivities == 0:
            Goldstandard = np.sum(np.abs(SensitivityFitPredictions[:, :, :, Sensitivities]), axis=(0, 1))
            TotalGS = np.sum(Goldstandard)
            continue
        Change = np.sum(
            np.abs(np.subtract(SensitivityFitPredictions[:, :, :, Sensitivities], SensitivityFitPredictions[:, :, :, 0])),
            axis=(0, 1))
        TotalChange = np.sum(Change)
        SensitivityChange[iprop] = TotalChange
        print(str(round(TotalChange, 5)) + ' GS ' + str(round(TotalGS, 5)) + ' ' + lineend)
        if SensitvitybyPrediction:
            for ipred in range(0, NpredperseqTOT):
                print(str(round(Change[ipred], 5)) + ' GS ' + str(round(Goldstandard[ipred], 5))
                      + ' ' + str(ipred) + ' ' + Predictionname[PredictionNameIndex[ipred]] + ' wgt ' + str(
                    round(Predictionwgt[ipred], 3)))

    print(startbold + startred + '\nSummarize Changes Total ' + str(round(TotalGS, 5)) + ' Property ScaleFactor ' + str(
        round(ScaleProperty, 3)) + resetfonts)
    for Sensitivities in range(1, 1 + something):
        iprop = SensitivityList[Sensitivities - 1]
        nameplace = PropertyNameIndex[iprop]
        maxminplace = PropertyAverageValuesPointer[iprop]

        lastline = ' Normed Mean ' + str(round(QuantityStatistics[maxminplace, 5], 4))
        lastline += ' Normed Std ' + str(round(QuantityStatistics[maxminplace, 6], 4))
        TotalChange = SensitivityChange[iprop]
        NormedChange = TotalChange / ((1 - ScaleProperty) * TotalGS)
        stdmeanratio = 0.0
        stdchangeratio = 0.0
        if np.abs(QuantityStatistics[maxminplace, 5]) > 0.0001:
            stdmeanratio = QuantityStatistics[maxminplace, 6] / QuantityStatistics[maxminplace, 5]
        if np.abs(QuantityStatistics[maxminplace, 6]) > 0.0001:
            stdchangeratio = NormedChange / QuantityStatistics[maxminplace, 6]

        lratios = ' Normed Change ' + str(round(NormedChange, 5)) + ' /std ' + str(round(stdchangeratio, 5))
        lratios += ' Std/Mean ' + str(round(stdmeanratio, 5))
        print(str(iprop) + ' Change ' + str(round(TotalChange, 2)) + startbold + lratios
              + ' ' + InputPropertyNames[nameplace] + resetfonts + lastline)

    current_time = timenow()
    print(startbold + startred + '\nEND DLPrediction2F ' + current_time + ' ' + RunName + RunComment + resetfonts)
    return


"""### General DL Utilities"""


def get_model_summary(model):
    stream = io.StringIO()
    model.summary(print_fn=lambda x: stream.write(x + '\n'))
    summary_string = stream.getvalue()
    stream.close()
    return summary_string


def setDLinput(Spacetime=True):
    # Initial data is Flatten([Num_Seq][Nloc]) [Tseq] with values [Nprop-Sel + Nforcing + Add(ExPosEnc-Selin)] starting with   RawInputSequencesTOT
    # Predictions are Flatten([Num_Seq] [Nloc]) [Predvals=Npred+ExPosEnc-Selout] [Predtimes = Forecast-time range] starting with RawInputPredictionsTOT
    # No assumptions as to type of variables here
    if SymbolicWindows:
        X_predict = SymbolicInputSequencesTOT.reshape(OuterBatchDimension, 1, 1)
    else:
        X_predict = RawInputSequencesTOT.reshape(OuterBatchDimension, Tseq, NpropperseqTOT)
    y_predict = RawInputPredictionsTOT.reshape(OuterBatchDimension, NpredperseqTOT)
    if Spacetime:
        SpacetimeforMask_predict = SpacetimeforMask.reshape(OuterBatchDimension, 1, 1).copy()
        return X_predict, y_predict, SpacetimeforMask_predict
    return X_predict, y_predict


def setSeparateDLinput(model, Spacetime=False):
    # Initial data is Flatten([Num_Seq][Nloc]) [Tseq] with values [Nprop-Sel + Nforcing + Add(ExPosEnc-Selin)] starting with   RawInputSequencesTOT
    # Predictions are Flatten([Num_Seq] [Nloc]) [Predvals=Npred+ExPosEnc-Selout] [Predtimes = Forecast-time range] starting with RawInputPredictionsTOT
    # No assumptions as to type of variables here
    # model = 0 LSTM =1 transformer
    if model == 0:
        Spacetime = False
    X_val = None
    y_val = None
    Spacetime_val = None
    Spacetime_train = None
    if SymbolicWindows:
        InputSequences = np.empty([Num_Seq, TrainingNloc], dtype=np.int32)
        for iloc in range(0, TrainingNloc):
            InputSequences[:, iloc] = SymbolicInputSequencesTOT[:, ListofTrainingLocs[iloc]]
        if model == 0:
            X_train = InputSequences.reshape(Num_Seq * TrainingNloc, 1, 1)
        else:
            X_train = InputSequences
        if Spacetime:
            Spacetime_train = X_train.copy()

        if LocationValidationFraction > 0.001:
            UsedValidationNloc = ValidationNloc
            if FullSetValidation:
                UsedValidationNloc = Nloc
            ValInputSequences = np.empty([Num_Seq, UsedValidationNloc], dtype=np.int32)
            if FullSetValidation:
                for iloc in range(0, Nloc):
                    ValInputSequences[:, iloc] = SymbolicInputSequencesTOT[:, iloc]
            else:
                for iloc in range(0, ValidationNloc):
                    ValInputSequences[:, iloc] = SymbolicInputSequencesTOT[:, ListofValidationLocs[iloc]]
            if model == 0:
                X_val = ValInputSequences.reshape(Num_Seq * UsedValidationNloc, 1, 1)
            else:
                X_val = ValInputSequences
            if Spacetime:
                Spacetime_val = X_val.copy()

    else:  # Symbolic Windows false Calculate Training
        InputSequences = np.empty([Num_Seq, TrainingNloc, Tseq, NpropperseqTOT], dtype=np.float32)
        for iloc in range(0, TrainingNloc):
            InputSequences[:, iloc, :, :] = RawInputSequencesTOT[:, ListofTrainingLocs[iloc], :, :]
        if model == 0:
            X_train = InputSequences.reshape(Num_Seq * TrainingNloc, Tseq, NpropperseqTOT)
        else:
            X_train = InputSequences
        if Spacetime:
            Spacetime_train = np.empty([Num_Seq, TrainingNloc], dtype=np.int32)
            for iloc in range(0, TrainingNloc):
                Spacetime_train[:, iloc] = SpacetimeforMask[:, ListofTrainingLocs[iloc]]

        if LocationValidationFraction > 0.001:  # Symbolic Windows false Calculate Validation
            UsedValidationNloc = ValidationNloc
            if FullSetValidation:
                UsedValidationNloc = Nloc
            ValInputSequences = np.empty([Num_Seq, UsedValidationNloc, Tseq, NpropperseqTOT], dtype=np.float32)
            if FullSetValidation:
                for iloc in range(0, Nloc):
                    ValInputSequences[:, iloc, :, :] = RawInputSequencesTOT[:, iloc, :, :]
            else:
                for iloc in range(0, ValidationNloc):
                    ValInputSequences[:, iloc, :, :] = RawInputSequencesTOT[:, ListofValidationLocs[iloc], :, :]
            if model == 0:
                X_val = ValInputSequences.reshape(Num_Seq * UsedValidationNloc, Tseq, NpropperseqTOT)
            else:
                X_val = ValInputSequences
            if Spacetime:
                Spacetime_val = np.empty([Num_Seq, UsedValidationNloc], dtype=np.int32)
                if FullSetValidation:
                    for iloc in range(0, Nloc):
                        Spacetime_val[:, iloc] = SpacetimeforMask[:, iloc]
                else:
                    for iloc in range(0, ValidationNloc):
                        Spacetime_val[:, iloc] = SpacetimeforMask[:, ListofValidationLocs[iloc]]

    # Calculate training predictions
    InputPredictions = np.empty([Num_Seq, TrainingNloc, NpredperseqTOT], dtype=np.float32)
    for iloc in range(0, TrainingNloc):
        InputPredictions[:, iloc, :] = RawInputPredictionsTOT[:, ListofTrainingLocs[iloc], :]
    if model == 0:
        y_train = InputPredictions.reshape(OuterBatchDimension, NpredperseqTOT)
    else:
        y_train = InputPredictions

    # Calculate validation predictions
    if LocationValidationFraction > 0.001:
        ValInputPredictions = np.empty([Num_Seq, UsedValidationNloc, NpredperseqTOT], dtype=np.float32)
        if FullSetValidation:
            for iloc in range(0, Nloc):
                ValInputPredictions[:, iloc, :] = RawInputPredictionsTOT[:, iloc, :]
        else:
            for iloc in range(0, ValidationNloc):
                ValInputPredictions[:, iloc, :] = RawInputPredictionsTOT[:, ListofValidationLocs[iloc], :]
        if model == 0:
            y_val = ValInputPredictions.reshape(Num_Seq * ValidationNloc, NpredperseqTOT)
        else:
            y_val = ValInputPredictions

    if Spacetime:
        return X_train, y_train, Spacetime_train, X_val, y_val, Spacetime_val
    else:
        return X_train, y_train, X_val, y_val


def InitializeDLforTimeSeries(message, processindex, y_predict):
    if (processindex == 0):
        current_time = timenow()
        line = (startbold + current_time + ' ' + message + resetfonts + " Window Size " + str(Tseq) +
                " Number of samples over time that sequence starts at and location:" + str(OuterBatchDimension) +
                " Number input features per sequence:" + str(NpropperseqTOT) +
                " Number of predicted outputs per sequence:" + str(NpredperseqTOT) +
                " Batch_size:" + str(LSTMbatch_size) +
                " n_nodes:" + str(number_LSTMnodes) +
                " epochs:" + str(TFTTransformerepochs))
        print(wraptotext(line))
        checkNaN(y_predict)


"""### Tensorflow  Monitor"""


class TensorFlowTrainingMonitor():
    def __init__(self):

        # These OPERATIONAL variables control saving of best fits
        self.lastsavedepoch = -1  # Epoch number where last saved fit done
        self.BestLossValueSaved = NaN  # Training Loss value of last saved fit
        self.BestValLossValueSaved = NaN  # Validation Loss value of last saved fit
        self.Numsuccess = 0  # count little successes up to SuccessLimit
        self.Numfailed = 0
        self.LastLossValue = NaN  # Loss on previous epoch
        self.MinLossValue = NaN  # Saved minimum loss value
        self.LastValLossValue = NaN  # Validation Loss on previous epoch
        self.MinValLossValue = NaN  # validation loss value at last save
        self.BestLossSaved = False  # Boolean to indicate that best Loss value saved
        self.saveMinLosspath = ''  # Checkpoint path for saved network
        self.epochcount = 0
        self.NumberTimesSaved = 0  # Number of Checkpointing steps for Best Loss
        self.NumberTimesRestored = 0  # Number of Checkpointing Restores
        self.LittleJumpdifference = NaN
        self.LittleValJumpdifference = NaN
        self.AccumulateSuccesses = 0
        self.AccumulateFailures = np.zeros(5, dtype=np.int)
        self.RestoreReasons = np.zeros(8, dtype=np.int)
        self.NameofFailures = ['Success', 'Train Only Failed', 'Val Only Failed', 'Both Failed', 'NaN']
        self.NameofRestoreReasons = ['Both Big Jump', 'Both Little Jump', 'Train Big Jump', 'Train Little Jump',
                                     'Val Big Jump', 'Val Little Jump', ' Failure Limit', ' NaN']
        # End OPERATIONAL Control set up for best fit checkpointing

        # These are parameters user can set
        self.UseBestAvailableLoss = True
        self.LittleJump = 2.0  # Multiplier for checking jump compared to recent changes
        self.ValLittleJump = 2.0  # Multiplier for checking jump compared to recent changes
        self.startepochs = -1  # Ignore this number of epochs to let system get started
        self.SuccessLimit = 20  # Don't keep saving. Wait for this number of (little) successes
        self.FailureLimit = 10  # Number of failures before restore
        self.BadJumpfraction = 0.2  # This fractional jump will trigger attempt to go back to saved value
        self.ValBadJumpfraction = 0.2  # This fractional jump will trigger attempt to go back to saved value
        self.ValidationFraction = 0.0  # Must be used validation fraction
        DownplayValidationIncrease = True

        # End parameters user can set

        self.checkpoint = None
        self.CHECKPOINTDIR = ''
        self.RunName = ''

        self.train_epoch = 0.0
        self.val_epoch = 0.0
        tfepochstep = None
        recordtrainloss = []
        recordvalloss = []

    def SetControlParms(self, UseBestAvailableLoss=None, LittleJump=None, startepochs=None, ValLittleJump=None,
                        ValBadJumpfraction=None, SuccessLimit=None, FailureLimit=None, BadJumpfraction=None,
                        DownplayValidationIncrease=True):
        if UseBestAvailableLoss is not None:
            self.UseBestAvailableLoss = UseBestAvailableLoss
        if LittleJump is not None:
            self.LittleJump = LittleJump
        if ValLittleJump is not None:
            self.ValLittleJump = ValLittleJump
        if startepochs is not None:
            self.startepochs = startepochs
        if SuccessLimit is not None:
            self.SuccessLimit = SuccessLimit
        if FailureLimit is not None:
            self.FailureLimit = FailureLimit
        if BadJumpfraction is not None:
            self.BadJumpfraction = BadJumpfraction
        if ValBadJumpfraction is not None:
            self.ValBadJumpfraction = ValBadJumpfraction
        if DownplayValidationIncrease:
            self.ValBadJumpfraction = 200.0
            self.ValLittleJump = 2000.0
        elif ValLittleJump is None:
            self.ValLittleJump = 2.0
        elif ValBadJumpfraction is None:
            self.ValBadJumpfraction = 0.2

    def SetCheckpointParms(self, checkpointObject, CHECKPOINTDIR, RunName='', Restoredcheckpoint=False, Restored_path='',
                           ValidationFraction=0.0, SavedTrainLoss=NaN, SavedValLoss=NaN):
        self.ValidationFraction = ValidationFraction
        self.checkpoint = checkpointObject
        self.CHECKPOINTDIR = CHECKPOINTDIR
        self.RunName = RunName
        if Restoredcheckpoint:
            self.BestLossSaved = True
            self.saveMinLosspath = Restored_path  # Checkpoint path for saved network
            self.LastLossValue = SavedTrainLoss
            self.LastValLossValue = SavedValLoss
            self.BestLossValueSaved = SavedTrainLoss
            self.BestValLossValueSaved = SavedValLoss
            self.lastsavedepoch = self.epochcount
            self.MinLossValue = SavedTrainLoss
            self.MinValLossValue = SavedValLoss

    def EpochEvaluate(self, epochcount, train_epoch, val_epoch, tfepochstep, recordtrainloss, recordvalloss):
        FalseReturn = 0
        TrueReturn = 1
        self.epochcount = epochcount
        self.train_epoch = train_epoch
        self.val_epoch = val_epoch
        self.tfepochstep = tfepochstep
        self.recordtrainloss = recordtrainloss
        self.recordvalloss = recordvalloss

        Needtorestore = False
        Failreason = 5  # nonsense
        LossChange = 0.0
        ValLossChange = 0.0
        if np.math.isnan(self.train_epoch) or np.math.isnan(self.val_epoch):
            Restoreflag = 7
            self.RestoreReasons[Restoreflag] += 1
            Needtorestore = True
            Failreason = 4
            self.AccumulateFailures[Failreason] += 1
            print(str(self.epochcount) + ' NAN Seen Reason ' + str(Failreason) + ' #succ ' + str(
                self.Numsuccess) + ' #fail ' + str(self.Numfailed) + ' ' + str(round(self.train_epoch, 6)) + ' ' + str(
                round(self.val_epoch, 6)), flush=True)
            return TrueReturn, self.train_epoch, self.val_epoch

        if self.epochcount <= self.startepochs:
            return FalseReturn, self.train_epoch, self.val_epoch

        if not np.math.isnan(self.LastLossValue):
            LossChange = self.train_epoch - self.LastLossValue
            if self.ValidationFraction > 0.001:
                ValLossChange = self.val_epoch - self.LastValLossValue
        if LossChange <= 0:
            if self.ValidationFraction > 0.001:
                # Quick Fix
                self.Numsuccess += 1
                self.AccumulateSuccesses += 1
                if ValLossChange <= 0:
                    Failreason = 0
                else:
                    Failreason = 2
            else:
                self.Numsuccess += 1
                self.AccumulateSuccesses += 1
                Failreason = 0
        else:
            Failreason = 1
            if self.ValidationFraction > 0.001:
                if ValLossChange > 0:
                    Failreason = 3
        if Failreason > 0:
            self.Numfailed += 1
        self.AccumulateFailures[Failreason] += 1

        if (not np.math.isnan(self.LastLossValue)) and (Failreason > 0):
            print(str(self.epochcount) + ' Reason ' + str(Failreason) + ' #succ ' + str(self.Numsuccess) + ' #fail ' + str(
                self.Numfailed) + ' ' + str(round(self.train_epoch, 6))
                  + ' ' + str(round(self.LastLossValue, 6)) + ' ' + str(round(self.val_epoch, 6)) + ' ' + str(
                round(self.LastValLossValue, 6)), flush=True)
        self.LastLossValue = self.train_epoch
        self.LastValLossValue = self.val_epoch

        StoreMinLoss = False
        if not np.math.isnan(self.MinLossValue):
            #      if (self.train_epoch < self.MinLossValue) and (self.val_epoch <= self.MinValLossValue):
            if (self.train_epoch < self.MinLossValue):
                if self.Numsuccess >= self.SuccessLimit:
                    StoreMinLoss = True
        else:
            StoreMinLoss = True
        if StoreMinLoss:
            self.Numsuccess = 0
            extrastuff = ''
            extrastuff_val = ' '
            if not np.math.isnan(self.MinLossValue):
                extrastuff = ' Previous ' + str(round(self.MinLossValue, 7))
                self.LittleJumpdifference = self.MinLossValue - self.train_epoch
                if self.ValidationFraction > 0.001:
                    if not np.math.isnan(self.MinValLossValue):
                        extrastuff_val = ' Previous ' + str(round(self.MinValLossValue, 7))
                        LittleValJumpdifference = max(self.MinValLossValue - self.val_epoch, self.LittleJumpdifference)
            self.saveMinLosspath = self.checkpoint.save(file_prefix=self.CHECKPOINTDIR + self.RunName + 'MinLoss')
            if not self.BestLossSaved:
                print('\nInitial Checkpoint at ' + self.saveMinLosspath + ' from ' + self.CHECKPOINTDIR)
            self.MinLossValue = self.train_epoch
            self.MinValLossValue = self.val_epoch
            if self.ValidationFraction > 0.001:
                extrastuff_val = ' Val Loss ' + str(round(self.val_epoch, 7)) + extrastuff_val
            print(' Epoch ' + str(self.epochcount) + ' Loss ' + str(
                round(self.train_epoch, 7)) + extrastuff + extrastuff_val + ' Failed ' + str(self.Numfailed), flush=True)
            self.Numfailed = 0
            self.BestLossSaved = True
            self.BestLossValueSaved = self.train_epoch
            self.BestValLossValueSaved = self.val_epoch
            self.lastsavedepoch = self.epochcount
            self.NumberTimesSaved += 1
            return FalseReturn, self.train_epoch, self.val_epoch

        RestoreTrainflag = -1
        Trainrestore = False
        if LossChange > 0.0:
            if LossChange > self.BadJumpfraction * self.train_epoch:
                Trainrestore = True
                RestoreTrainflag = 0
            if not np.math.isnan(self.LittleJumpdifference):
                if LossChange > self.LittleJumpdifference * self.LittleJump:
                    Trainrestore = True
                    if RestoreTrainflag < 0:
                        RestoreTrainflag = 1
            if self.BestLossSaved:
                if self.train_epoch < self.MinLossValue:
                    Trainrestore = False
                    RestoreTrainflag = -1

        RestoreValflag = -1
        Valrestore = False
        if ValLossChange > 0.0:
            if ValLossChange > self.ValBadJumpfraction * self.val_epoch:
                Valrestore = True
                RestoreValflag = 0
            if not np.math.isnan(self.LittleValJumpdifference):
                if ValLossChange > self.LittleValJumpdifference * self.ValLittleJump:
                    Valrestore = True
                    if RestoreValflag < 0:
                        RestoreValflag = 1
            if self.BestLossSaved:
                if self.val_epoch < self.MinValLossValue:
                    Valrestore = False
                    RestoreValflag = -1
        Restoreflag = -1
        if Trainrestore and Valrestore:
            Needtorestore = True
            if RestoreTrainflag == 0:
                Restoreflag = 0
            else:
                Restoreflag = 1
        elif Trainrestore:
            Needtorestore = True
            Restoreflag = RestoreTrainflag + 2
        elif Valrestore:
            Needtorestore = True
            Restoreflag = RestoreValflag + 4
        if (self.Numfailed >= self.FailureLimit) and (Restoreflag == -1):
            Restoreflag = 6
            Needtorestore = True
        if Restoreflag >= 0:
            self.RestoreReasons[Restoreflag] += 1
        if Needtorestore and (not self.BestLossSaved):
            print('bad Jump ' + str(round(LossChange, 7)) + ' Epoch ' + str(self.epochcount) + ' But nothing saved')
            return FalseReturn, self.train_epoch, self.val_epoch
        if Needtorestore:
            return TrueReturn, self.train_epoch, self.val_epoch
        else:
            return FalseReturn, self.train_epoch, self.val_epoch

    def RestoreBestFit(self):
        if self.BestLossSaved:
            self.checkpoint.tfrecordvalloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
            self.checkpoint.tfrecordtrainloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
            self.checkpoint.restore(save_path=self.saveMinLosspath).expect_partial()
            self.tfepochstep = self.checkpoint.tfepochstep
            self.recordvalloss = self.checkpoint.tfrecordvalloss.numpy().tolist()
            self.recordtrainloss = self.checkpoint.tfrecordtrainloss.numpy().tolist()
            trainlen = len(self.recordtrainloss)
            self.Numsuccess = 0
            extrastuff = ''
            if self.ValidationFraction > 0.001:
                vallen = len(self.recordvalloss)
                if vallen > 0:
                    extrastuff = ' Replaced Val Loss ' + str(round(self.recordvalloss[vallen - 1], 7)) + ' bad val ' + str(
                        round(self.val_epoch, 7))
                else:
                    extrastuff = ' No previous Validation Loss'
            print(str(self.epochcount) + ' Failed ' + str(self.Numfailed) + ' Restored Epoch ' + str(
                trainlen - 1) + ' Replaced Loss ' + str(round(self.recordtrainloss[trainlen - 1], 7))
                  + ' bad ' + str(round(self.train_epoch, 7)) + extrastuff + ' Checkpoint at ' + self.saveMinLosspath)
            self.train_epoch = self.recordtrainloss[trainlen - 1]
            self.Numfailed = 0
            self.LastLossValue = self.train_epoch
            self.NumberTimesRestored += 1
            if self.ValidationFraction > 0.001:
                vallen = len(self.recordvalloss)
                if vallen > 0:
                    self.val_epoch = self.recordvalloss[vallen - 1]
                else:
                    self.val_epoch = 0.0
            return self.tfepochstep, self.recordtrainloss, self.recordvalloss, self.train_epoch, self.val_epoch

    def PrintEndofFit(self, Numberofepochs):
        print(startbold + 'Number of Saves ' + str(self.NumberTimesSaved) + ' Number of Restores ' + str(
            self.NumberTimesRestored))
        print('Epochs Requested ' + str(Numberofepochs) + ' Actually Stored ' + str(len(self.recordtrainloss)) + ' ' + str(
            self.tfepochstep.numpy())
              + ' Successes ' + str(self.AccumulateSuccesses) + resetfonts)
        trainlen = len(self.recordtrainloss)
        train_epoch1 = self.recordtrainloss[trainlen - 1]
        lineforval = ''
        if self.ValidationFraction > 0.001:
            lineforval = ' Last val ' + str(round(self.val_epoch, 7))
        print(startbold + 'Last loss ' + str(round(self.train_epoch, 7)) + ' Last loss in History ' + str(
            round(train_epoch1, 7)) + ' Best Saved Loss '
              + str(round(self.BestLossValueSaved, 7)) + lineforval + resetfonts)
        print(startbold + startred + "\nFailure Reasons" + resetfonts)
        for ireason in range(0, len(self.AccumulateFailures)):
            print('Optimization Failure ' + str(ireason) + ' ' + self.NameofFailures[ireason] + ' ' + str(
                self.AccumulateFailures[ireason]))
        print(startbold + startred + "\nRestore Reasons" + resetfonts)
        for ireason in range(0, len(self.RestoreReasons)):
            print('Backup to earlier fit ' + str(ireason) + ' ' + self.NameofRestoreReasons[ireason] + ' ' + str(
                self.RestoreReasons[ireason]))

    def BestPossibleFit(self):  # Use Best Saved if appropriate
        if self.UseBestAvailableLoss:
            if self.BestLossSaved:
                if self.BestLossValueSaved < self.train_epoch:
                    self.checkpoint.tfrecordvalloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
                    self.checkpoint.tfrecordtrainloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
                    self.checkpoint.restore(save_path=self.saveMinLosspath).expect_partial()
                    self.tfepochstep = self.checkpoint.tfepochstep
                    self.recordvalloss = self.checkpoint.tfrecordvalloss.numpy().tolist()
                    self.recordtrainloss = self.checkpoint.tfrecordtrainloss.numpy().tolist()
                    trainlen = len(self.recordtrainloss)
                    Oldtraining = self.train_epoch
                    self.train_epoch = self.recordtrainloss[trainlen - 1]
                    extrainfo = ''
                    if self.ValidationFraction > 0.001:
                        vallen = len(self.recordvalloss)
                        if vallen > 0:
                            extrainfo = '\nVal Loss ' + str(round(self.recordvalloss[vallen - 1], 7)) + ' old Val ' + str(
                                round(self.val_epoch, 7))
                            self.val_epoch = self.recordvalloss[vallen - 1]
                        else:
                            self.val_epoch = 0.0
                            extrainfo = '\n no previous validation loss'
                    print(startpurple + startbold + 'Switch to Best Saved Value. Restored Epoch ' + str(trainlen - 1)
                          + '\nNew Loss ' + str(round(self.recordtrainloss[trainlen - 1], 7)) + ' old ' + str(
                        round(Oldtraining, 7))
                          + extrainfo + '\nCheckpoint at ' + self.saveMinLosspath + resetfonts)

                else:
                    print(startpurple + startbold + '\nFinal fit is best: train ' + str(
                        round(self.train_epoch, 7)) + ' Val Loss ' + str(round(self.val_epoch, 7)) + resetfonts)
        return self.tfepochstep, self.recordtrainloss, self.recordvalloss, self.train_epoch, self.val_epoch


"""###Record Parameters Used"""


def PrintLSTMandBasicStuff(model):
    if SymbolicWindows:
        print(' Tseq ' + str(Tseq) + startbold + startred + ' Symbolic Windows used to save space' + resetfonts)
    else:
        print(' Tseq ' + str(Tseq) + startbold + startred + ' Symbolic Windows NOT used' + resetfonts)
    print('Training Locations ' + str(TrainingNloc) + ' Validation Locations ' + str(ValidationNloc) +
          ' Sequences ' + str(Num_Seq))
    if LocationBasedValidation:
        print(startbold + startred + " Location Based Validation with fraction " + str(
            LocationValidationFraction) + resetfonts)
        if RestartLocationBasedValidation:
            print(startbold + startred + " Using Validation set saved in " + RestartValidationSetRunName + resetfonts)
    print('\nAre futures predicted ' + str(UseFutures) + ' Custom Loss Pointer ' + str(
        CustomLoss) + ' Class weights used ' + str(UseClassweights))

    print('\nProperties per sequence ' + str(NpropperseqTOT))
    print('\n' + startbold + startpurple + 'Properties ' + resetfonts)
    labelline = 'Name   '
    for propval in range(0, 7):
        labelline += QuantityStatisticsNames[propval] + '    '
    print('\n' + startbold + labelline + resetfonts)
    for iprop in range(0, NpropperseqTOT):
        line = startbold + startpurple + str(iprop) + ' ' + InputPropertyNames[PropertyNameIndex[iprop]] + resetfonts
        jprop = PropertyAverageValuesPointer[iprop]
        line += ' Root ' + str(QuantityTakeroot[jprop])
        for proppredval in range(0, 7):
            line += ' ' + str(round(QuantityStatistics[jprop, proppredval], 3))
        print(line)

    print('\nPredictions per sequence ' + str(NpredperseqTOT))
    print('\n' + startbold + startpurple + 'Predictions ' + resetfonts)
    print('\n' + startbold + labelline + resetfonts)
    for ipred in range(0, NpredperseqTOT):
        line = startbold + startpurple + str(ipred) + ' ' + Predictionname[PredictionNameIndex[ipred]] + ' wgt ' + str(
            round(Predictionwgt[ipred], 3)) + resetfonts + ' '
        jpred = PredictionAverageValuesPointer[ipred]
        line += ' Root ' + str(QuantityTakeroot[jpred])
        for proppredval in range(0, 7):
            line += ' ' + str(round(QuantityStatistics[jpred, proppredval], 3))
        print(line)
    print('\n')
    print(
        'Plotrealnumbers ' + str(Plotrealnumbers) + ' Root Cases Deaths ' + str(RootCasesDeaths) + ' JournalSimplePrint ' +
        str(JournalSimplePrint) + ' UseRealDatesonplots ' + str(UseRealDatesonplots) + ' Plot in DLPrediction2F ' + str(
            PlotinDL2F))

    if model == 0:
        print('Number of LSTMworkers ' + str(number_of_LSTMworkers))
        print('Number of epochs for each LSTMworker ' + str(LSTMepochs))
        print('LSTM Validation Fraction ' + str(LSTMvalidationfrac) + ' Used LSTM Validation Fraction ' + str(
            UsedLSTMvalidationfrac))
        print('Batch size for LSTM ' + str(LSTMbatch_size))
        print('LSTM Optimizer ' + str(LSTMoptimizer))
    else:
        print('Number of epochs for Transformer ' + str(Transformerepochs))

    print('LSTM Activation Method ' + str(LSTMactivationvalue))
    print('LSTM recurrent Activation method ' + str(LSTMrecurrent_activation))
    print('LSTM Dropout Layer 1 ' + str(LSTMdropout1) + ' LSTM Recurrent Dropout Layer 1 ' + str(
        LSTMrecurrent_dropout1) + ' LSTM Dropout Layer >= 2 ' + str(
        LSTMdropout2) + ' LSTM Recurrent Dropout Layer >=2 ' + str(LSTMrecurrent_dropout2))
    print('Number of hidden LSTM nodes ' + str(number_LSTMnodes) + ' Is there a third LSTM layer? ' + str(LSTMThirdLayer))
    print('LSTM Initial Embedding layer ' + str(LSTMInitialMLP) + ' Final LSTM Layer ' + str(LSTMFinalMLP))
    print('LSTM Verbose Option ' + str(LSTMverbose))


"""##LSTM Model

### LSTM Model and Layer Class
"""


class MyLSTMmodel(tf.keras.Model):
    def __init__(self, **kwargs):
        super(MyLSTMmodel, self).__init__(**kwargs)
        self.fullLSTM = MyLSTMlayer()

    def call(self, inputs):
        outputs = self.fullLSTM(inputs)
        return outputs

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])


class MyLSTMlayer(tf.keras.Model):
    # Class for a simple multiple layer LSTM with FCN at start and end
    # All parameters defined externally
    # structured so MyLSTMlayer can be used standalone or in part of a transformer

    def __init__(self, **kwargs):
        super(MyLSTMlayer, self).__init__(**kwargs)
        if (LSTMInitialMLP > 0) and (not LSTMSkipInitial):
            self.dense_1 = tf.keras.layers.Dense(LSTMInitialMLP, activation=LSTMactivationvalue)
        self.LSTM_1 = tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout=LSTMrecurrent_dropout1, dropout=LSTMdropout1,
                                           activation=LSTMactivationvalue, return_sequences=True,
                                           recurrent_activation=LSTMrecurrent_activation)
        self.LSTM_2 = tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout=LSTMrecurrent_dropout1, dropout=LSTMdropout1,
                                           activation=LSTMactivationvalue, return_sequences=LSTMThirdLayer,
                                           recurrent_activation=LSTMrecurrent_activation)
        if (LSTMThirdLayer):
            self.LSTM_3 = tf.keras.layers.LSTM(number_LSTMnodes, recurrent_dropout=LSTMrecurrent_dropout1,
                                               dropout=LSTMdropout1,
                                               activation=LSTMactivationvalue, return_sequences=False,
                                               recurrent_activation=LSTMrecurrent_activation)
        self.dense_2 = tf.keras.layers.Dense(LSTMFinalMLP, activation=LSTMactivationvalue)
        self.dense_f = tf.keras.layers.Dense(NpredperseqTOT)

    def call(self, inputs, training=None):
        if (LSTMInitialMLP > 0) and (not LSTMSkipInitial):
            Runningdata = self.dense_1(inputs)
            Runningdata = self.LSTM_1(Runningdata, training=training)
        else:
            Runningdata = self.LSTM_1(inputs, training=training)
        Runningdata = self.LSTM_2(Runningdata, training=training)
        if (LSTMThirdLayer):
            Runningdata = self.LSTM_3(Runningdata, training=training)
        if (LSTMFinalMLP > 0):
            Runningdata = self.dense_2(Runningdata)
        Outputdata = self.dense_f(Runningdata)
        return Outputdata

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])


"""### LSTM Class + Custom Training"""


class MyLSTMcustommodel(tf.keras.Model):
    def __init__(self, **kwargs):
        super(MyLSTMcustommodel, self).__init__(**kwargs)
        self.fullLSTM = MyLSTMlayer()

    def compile(self, optimizer, loss, lr):
        super(MyLSTMcustommodel, self).compile()
        if optimizer == 'adam':
            self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
        else:
            self.optimizer = tf.keras.optimizers.get(optimizer)
        Dictopt = self.optimizer.get_config()
        print(startbold + startred + 'Optimizer ' + resetfonts, Dictopt)
        self.loss_object = loss
        self.loss_tracker = tf.keras.metrics.Mean(name="loss")
        self.loss_tracker.reset_states()
        self.val_tracker = tf.keras.metrics.Mean(name="val")
        self.val_tracker.reset_states()
        return

    def resetmetrics(self):
        self.loss_tracker.reset_states()
        self.val_tracker.reset_states()
        return

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])

    @tf.function
    def train_step(self, data, Time=None):
        if len(data) == 3:
            X_train, y_train, sw_train = data
        else:
            X_train, y_train = data
            sw_train = []

        with tf.GradientTape() as tape:
            predictions = self(X_train, training=True)
            loss = self.loss_object(y_train, predictions, sw_train)

        gradients = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))
        self.loss_tracker.update_state(loss)
        return {"loss": self.loss_tracker.result()}

    @tf.function
    def test_step(self, data, Time=None):
        if len(data) == 3:
            X_val, y_val, sw_val = data
        else:
            X_val, y_val = data
            sw_val = []

        predictions = self(X_val, training=False)
        loss = self.loss_object(y_val, predictions, sw_val)

        self.val_tracker.update_state(loss)
        return {"val_loss": self.val_tracker.result()}

    def call(self, inputs, training=None, Time=None):
        outputs = self.fullLSTM(inputs, training=training)
        return outputs


def RunLSTMCustomVersion():
    # Run the LSTM model defined by Model and Layer class with custom training
    # Use Tensorflow datasets

    garbagecollectcall = 0
    global LSTMvalidationfrac
    global UsedLSTMvalidationfrac

    if LocationBasedValidation:
        UsedLSTMvalidationfrac = LocationValidationFraction
        X_predict, y_predict, X_val, y_val = setSeparateDLinput(0)
        InitializeDLforTimeSeries('Class custom  Version with location-based validation ', processindex, y_predict)
        epochsize = X_predict.shape[0]
        if UsedLSTMvalidationfrac > 0.001:
            epochsize = X_predict.shape[0] + X_val.shape[0]
        if UseClassweights:
            sw = np.empty_like(y_predict, dtype=np.float32)
            for j in range(0, sw.shape[0]):
                for i in range(0, NpredperseqTOT):
                    sw[j, i] = Predictionwgt[i]
            X_train, y_train, sw_train = shuffleDLinput(X_predict, y_predict, sw)
            train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, sw_train))
        else:
            X_train, y_train = shuffleDLinput(X_predict, y_predict)
            train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
            sw_train = []

        if UsedLSTMvalidationfrac > 0.001:
            if UseClassweights:
                sw_val = np.empty_like(y_val, dtype=np.float32)
                for j in range(0, sw_val.shape[0]):
                    for i in range(0, NpredperseqTOT):
                        sw_val[j, i] = Predictionwgt[i]
                val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val, sw_val))
            else:
                val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))
                sw_val = []

    # Dimensions are X_predict: OuterBatchDimension,Tseq,NpropperseqTOT
    # OR if SymbolicWindows OuterBatchDimension,1,1
    # y_predict OuterBatchDimension,NpredperseqTOT
    else:
        X_predict, y_predict = setDLinput(Spacetime=False)
        InitializeDLforTimeSeries('Class custom  Version ', processindex, y_predict)
        epochsize = X_predict.shape[0]

        if UseClassweights:
            sw = np.empty_like(y_predict, dtype=np.float32)
            for j in range(0, sw.shape[0]):
                for i in range(0, NpredperseqTOT):
                    sw[j, i] = Predictionwgt[i]
            X_train, y_train, sw_train = shuffleDLinput(X_predict, y_predict, sw)
            print(X_predict.shape)
            print(X_train.shape)
            print(y_predict.shape)
            print(y_train.shape)
            print(sw.shape)
            print(sw_train.shape)
            print(Predictionwgt)

            train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, sw_train))
        else:
            X_train, y_train = shuffleDLinput(X_predict, y_predict)
            train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
            sw_train = []

        val_dataset = []
        if UsedLSTMvalidationfrac > 0.001:
            total = X_train.shape[0]
            totval = int(UsedLSTMvalidationfrac * total)
            print(" Validation samples ", totval, " Training samples ", total - totval)
            if totval > 0:
                val_dataset = train_dataset.take(totval)
                train_dataset = train_dataset.skip(totval)
            else:
                UsedLSTMvalidationfrac = 0.0

    train_dataset = train_dataset.shuffle(buffer_size=OuterBatchDimension, reshuffle_each_iteration=True)
    train_dataset = train_dataset.batch(LSTMbatch_size)
    if UsedLSTMvalidationfrac > 0.001:
        val_dataset = val_dataset.batch(LSTMbatch_size)

    myLSTMcustommodel = MyLSTMcustommodel(name='myLSTMcustommodel')

    myLSTMcustommodel.compile(loss=weightedcustom_lossGCF1, optimizer=LSTMoptimizer, lr=LSTMlearning_rate)

    recordtrainloss = []
    recordvalloss = []
    tfrecordtrainloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfrecordvalloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfepochstep = tf.Variable(0, trainable=False)

    usecustomfit = True
    if usecustomfit and UseClassweights:

        # Set up checkpoints to read or write
        mycheckpoint = tf.train.Checkpoint(optimizer=myLSTMcustommodel.optimizer,
                                           model=myLSTMcustommodel, tfepochstep=tf.Variable(0),
                                           tfrecordtrainloss=tfrecordtrainloss, tfrecordvalloss=tfrecordvalloss)

        # This restores back up
        if Restorefromcheckpoint:
            save_path = inputCHECKPOINTDIR + inputRunName + inputCheckpointpostfix
            mycheckpoint.restore(save_path=save_path).expect_partial()
            tfepochstep = mycheckpoint.tfepochstep
            recordvalloss = mycheckpoint.tfrecordvalloss.numpy().tolist()
            recordtrainloss = mycheckpoint.tfrecordtrainloss.numpy().tolist()
            trainlen = len(recordtrainloss)
            extrainfo = ''
            vallen = len(recordvalloss)
            SavedTrainLoss = recordtrainloss[trainlen - 1]
            SavedValLoss = 0.0
            if vallen > 0:
                extrainfo = ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
                SavedValLoss = recordvalloss[vallen - 1]
            print(
                startbold + 'Network restored from ' + save_path + '\nLoss ' + str(round(recordtrainloss[trainlen - 1], 7))
                + extrainfo + ' Epochs ' + str(tfepochstep.numpy()) + resetfonts)
            LSTMTFMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=True,
                                             Restored_path=save_path, ValidationFraction=UsedLSTMvalidationfrac,
                                             SavedTrainLoss=SavedTrainLoss,
                                             SavedValLoss=SavedValLoss)
        else:
            LSTMTFMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=False,
                                             ValidationFraction=UsedLSTMvalidationfrac)

        # This just does analysis
        if AnalysisOnly:
            if OutputNetworkPictures:
                outputpicture1 = APPLDIR + '/Outputs/Model_' + RunName + '1.png'
                outputpicture2 = APPLDIR + '/Outputs/Model_' + RunName + '2.png'
                tf.keras.utils.plot_model(myLSTMcustommodel.build_graph([Tseq, NpropperseqTOT]),
                                          show_shapes=True, to_file=outputpicture1,
                                          show_dtype=True,
                                          expand_nested=True)
                tf.keras.utils.plot_model(myLSTMcustommodel.fullLSTM.build_graph([Tseq, NpropperseqTOT]),
                                          show_shapes=True, to_file=outputpicture2,
                                          show_dtype=True,
                                          expand_nested=True)
            if SymbolicWindows:
                finalizeDL(myLSTMcustommodel, recordtrainloss, recordvalloss, UsedLSTMvalidationfrac,
                           ReshapedSequencesTOT, RawInputPredictionsTOT, 0, LabelFit='Non-sampled LSTM Fit')
            else:
                finalizeDL(myLSTMcustommodel, recordtrainloss, recordvalloss, UsedLSTMvalidationfrac,
                           RawInputSequencesTOT, RawInputPredictionsTOT, 0, LabelFit='Non-sampled LSTM Fit')
            SummarizeFullLSTMModel(myLSTMcustommodel)
            return

        # Initialize progress bars
        pbar = notebook.trange(LSTMepochs, desc='Training loop', unit='epoch')
        bbar = notebook.trange(epochsize, desc='Batch    loop', unit='sample')

        train_epoch = 0.0  # Training Loss this epoch
        val_epoch = 0.0  # Validation Loss this epoch

        Ctime1 = 0.0
        Ctime2 = 0.0
        Ctime3 = 0.0
        Ctime4 = 0.0
        Ctime5 = 0.0
        Ctime6 = 0.0
        Ctime7 = 0.0
        GarbageCollect = True

        for e in pbar:
            myLSTMcustommodel.resetmetrics()
            train_lossoverbatch = []
            val_lossoverbatch = []

            if batchperepoch:
                qbar = notebook.trange(epochsize, desc='Batch loop epoch ' + str(e))

            for batch, (X_train, y_train, sw_train) in enumerate(train_dataset.take(-1)):
                StopWatch.start('label7')
                Numinbatch = X_train.shape[0]
                # SymbolicWindows X_train is indexed by Batch index, 1(replace by Window), 1 (replace by properties)
                if SymbolicWindows:
                    StopWatch.start('label1')
                    X_train = X_train.numpy()
                    X_train = np.reshape(X_train, Numinbatch)
                    iseqarray = np.right_shift(X_train, 16)
                    ilocarray = np.bitwise_and(X_train, 0b1111111111111111)
                    StopWatch.stop('label1')
                    Ctime1 += StopWatch.get('label1', digits=4)
                    StopWatch.start('label3')
                    X_train_withSeq = list()
                    for iloc in range(0, Numinbatch):
                        X_train_withSeq.append(
                            ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                    #         X_train_withSeq=[ReshapedSequencesTOT[ilocarray[iloc],iseqarray[iloc]:iseqarray[iloc]+Tseq] for iloc in range(0,Numinbatch)]
                    StopWatch.stop('label3')
                    Ctime3 += StopWatch.get('label3', digits=5)
                    StopWatch.start('label2')
                    loss = myLSTMcustommodel.train_step((np.array(X_train_withSeq), y_train, sw_train))
                    StopWatch.stop('label2')
                    Ctime2 += StopWatch.get('label2', digits=4)

                else:
                    StopWatch.start('label2')
                    loss = myLSTMcustommodel.train_step((X_train, y_train, sw_train))
                    StopWatch.stop('label2')
                    Ctime2 += StopWatch.get('label2', digits=4)

                if GarbageCollect:
                    StopWatch.start('label4')

                    if SymbolicWindows:
                        X_train_withSeq = None
                    X_train = None
                    y_train = None
                    sw_train = None
                    if garbagecollectcall > GarbageCollectionLimit:
                        garbagecollectcall = 0
                        gc.collect()
                    garbagecollectcall += 1
                    StopWatch.stop('label4')
                    Ctime4 += StopWatch.get('label4', digits=5)

                localloss = loss["loss"].numpy()
                train_lossoverbatch.append(localloss)

                if batchperepoch:
                    qbar.update(LSTMbatch_size)
                    qbar.set_postfix(Loss=localloss, Epoch=e)
                bbar.update(Numinbatch)
                bbar.set_postfix(Loss=localloss, Epoch=e)
                StopWatch.stop('label7')
                Ctime7 += StopWatch.get('label7', digits=5)
            # End Training step for one batch

            # Start Validation
            if UsedLSTMvalidationfrac > 0.001:
                StopWatch.start('label5')
                for batch, (X_val, y_val, sw_val) in enumerate(val_dataset.take(-1)):
                    Numinbatch = X_val.shape[0]
                    # SymbolicWindows X_val is indexed by Batch index, 1(replace by Window), 1 (replace by properties)
                    if SymbolicWindows:
                        StopWatch.start('label1')
                        X_val = X_val.numpy()
                        X_val = np.reshape(X_val, Numinbatch)
                        iseqarray = np.right_shift(X_val, 16)
                        ilocarray = np.bitwise_and(X_val, 0b1111111111111111)
                        StopWatch.stop('label1')
                        Ctime1 += StopWatch.get('label1', digits=4)
                        StopWatch.start('label3')
                        X_valFull = list()
                        for iloc in range(0, Numinbatch):
                            X_valFull.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                        StopWatch.stop('label3')
                        Ctime3 += StopWatch.get('label3', digits=5)
                        StopWatch.start('label2')
                        loss = myLSTMcustommodel.test_step((np.array(X_valFull), y_val, sw_val))
                        StopWatch.stop('label2')
                        Ctime2 += StopWatch.get('label2', digits=4)

                    else:
                        loss = myLSTMcustommodel.test_step((X_val, y_val, sw_val))

                    localval = loss["val_loss"].numpy()
                    val_lossoverbatch.append(localval)

                    bbar.update(X_val.shape[0])
                    bbar.set_postfix(Val_loss=localval, Epoch=e)
                StopWatch.stop('label5')
                Ctime5 += StopWatch.get('label5', digits=5)
            # End Batch

            train_epoch = train_lossoverbatch[-1]
            recordtrainloss.append(train_epoch)
            mycheckpoint.tfrecordtrainloss = tf.Variable(recordtrainloss)

            val_epoch = 0.0
            if UsedLSTMvalidationfrac > 0.001:
                val_epoch = val_lossoverbatch[-1]
                recordvalloss.append(val_epoch)
                mycheckpoint.tfrecordvalloss = tf.Variable(recordvalloss)

            pbar.set_postfix(Loss=train_epoch, Val=val_epoch)
            bbar.reset()
            tfepochstep = tfepochstep + 1
            mycheckpoint.tfepochstep.assign(tfepochstep)

            # Decide on best fit
            StopWatch.start('label6')
            MonitorResult, train_epoch, val_epoch = LSTMTFMonitor.EpochEvaluate(e, train_epoch, val_epoch,
                                                                                tfepochstep, recordtrainloss, recordvalloss)
            if MonitorResult == 1:
                tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = LSTMTFMonitor.RestoreBestFit()  # Restore Best Fit
            StopWatch.stop('label6')
            Ctime6 += StopWatch.get('label6', digits=5)
            continue
        # *********************** End of Epoch Loop

        # Print Fit details
        print(
            startbold + 'Times Symbolic-1 ' + str(round(Ctime1, 5)) + ' Symbolic-2 ' + str(round(Ctime3, 5)) + ' TF ' + str(
                round(Ctime2, 5)) + ' GarbageC ' + str(round(Ctime4, 5)) + resetfonts)
        print(startbold + 'Times Training ' + str(round(Ctime7, 5)) + ' Validation ' + str(
            round(Ctime5, 5)) + ' Monitor ' + str(round(Ctime6, 5)) + resetfonts)
        LSTMTFMonitor.PrintEndofFit(LSTMepochs)

        # Set Best Possible Fit
        tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = LSTMTFMonitor.BestPossibleFit()

        if Checkpointfinalstate:
            savepath = mycheckpoint.save(file_prefix=CHECKPOINTDIR + RunName)
            print('Checkpoint at ' + savepath + ' from ' + CHECKPOINTDIR)
        trainlen = len(recordtrainloss)
        extrainfo = ''
        if UsedLSTMvalidationfrac > 0.001:
            vallen = len(recordvalloss)
            extrainfo = ' Val Epoch ' + str(vallen - 1) + ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
        print(
            'Train Epoch ' + str(trainlen - 1) + ' Train Loss ' + str(round(recordtrainloss[trainlen - 1], 7)) + extrainfo)


    else:
        the_callbacks = [TqdmCallback()]
        modelresult = myLSTMcustommodel.fit(train_dataset,
                                            validation_data=val_dataset,
                                            epochs=LSTMepochs,
                                            batch_size=None,
                                            verbose=LSTMverbose,
                                            callbacks=the_callbacks
                                            )
        recordtrainloss = modelresult.history['loss']
        recordvalloss = modelresult.history['val_loss']

    SummarizeFullLSTMModel(myLSTMcustommodel)
    if OutputNetworkPictures:
        outputpicture1 = APPLDIR + '/Outputs/Model_' + RunName + '1.png'
        outputpicture2 = APPLDIR + '/Outputs/Model_' + RunName + '2.png'
        tf.keras.utils.plot_model(myLSTMcustommodel.build_graph([Tseq, NpropperseqTOT]),
                                  show_shapes=True, to_file=outputpicture1,
                                  show_dtype=True,
                                  expand_nested=True)
        tf.keras.utils.plot_model(myLSTMcustommodel.fullLSTM.build_graph([Tseq, NpropperseqTOT]),
                                  show_shapes=True, to_file=outputpicture2,
                                  show_dtype=True,
                                  expand_nested=True)
    if SymbolicWindows:
        finalizeDL(myLSTMcustommodel, recordtrainloss, recordvalloss, UsedLSTMvalidationfrac, ReshapedSequencesTOT,
                   RawInputPredictionsTOT, 0)
    else:
        finalizeDL(myLSTMcustommodel, recordtrainloss, recordvalloss, UsedLSTMvalidationfrac, RawInputSequencesTOT,
                   RawInputPredictionsTOT, 0)
    return


def SummarizeFullLSTMModel(DLmodel):
    DLmodel.fullLSTM.summary()
    DLmodel.summary()
    return


"""##LSTM Run & Output

### Prepare LSTM
"""

# Run LSTM Only
if UseLSTMModel:
    AnalysisOnly = True
    Dumpoutkeyplotsaspics = True
    Restorefromcheckpoint = False
    Checkpointfinalstate = True
    if AnalysisOnly:
        Restorefromcheckpoint = True
        Checkpointfinalstate = False
    if Restorefromcheckpoint:
        inputRunName = RunName
        inputCHECKPOINTDIR = CHECKPOINTDIR
        #    inputRunName = 'Hydroln3A'
        inputCheckpointpostfix = 'MinLoss-54'
        inputCHECKPOINTDIR = APPLDIR + "/checkpoints/" + inputRunName + "dir/"

    batchperepoch = False  # if True output a batch bar for each epoch
    GlobalSpacetime = False
    IncreaseNloc_sample = 1
    DecreaseNloc_sample = 1

    Plotrealnumbers = False
    SkipDL2F = False
    PlotinDL2F = False

    # Run Pure LSTM
    LSTMbatch_size = TrainingNloc  # Total number of counties for Covid
    LSTMbatch_size = 128
    LSTMbatch_size = min(LSTMbatch_size, TrainingNloc)
    LSTMepochs = 80
    LSTMlearning_rate = 0.0003 * 0.1

    number_LSTMnodes = 160
    LSTMFinalMLP = 160
    LSTMInitialMLP = 160
    LSTMThirdLayer = False

    processindex = 0
    standaloneLSTMrun = False
    ClassLSTMrun = True
    CustomTraining = True

    if ClassLSTMrun and CustomTraining:
        FullSetValidation = False
        LSTMTFMonitor = TensorFlowTrainingMonitor()
        if Hydrology:
            LSTMTFMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
        if Earthquake:
            LSTMTFMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
        if ReadJan2021Covid or ReadApril2021Covid:
            LSTMTFMonitor.SetControlParms(SuccessLimit=3, FailureLimit=2)

    current_time = timenow()
    runtype = ''
    if Restorefromcheckpoint:
        runtype = 'Restarted '
    if standaloneLSTMrun or ClassLSTMrun:
        print(wraptotext(startbold + startred + current_time + ' ' + runtype + RunName + ' ' + RunComment + resetfonts))
        PrintLSTMandBasicStuff(0)

    if ClassLSTMrun:
        if SymbolicWindows:
            CustomTraining = True
        if CustomTraining:
            RunLSTMCustomVersion()
    if standaloneLSTMrun or ClassLSTMrun:
        print(startbold + startpurple + 'LSTM run completed ' + runtype + RunName + ' ' + RunComment + resetfonts) \
        sys.exit(0)
    print(
        startbold + startpurple + current_time + ' UTC Start Hybrid Transformer run ' + RunName + ' ' + RunComment + resetfonts)

"""#Science Transformer Model

## Important Parameters defining Transformer project
"""

if UseScienceTransformerModel or UseTFTModel:
    ActivateAttention = False
    DoubleQKV = False
    TimeShufflingOnly = False
    Transformerbatch_size = 1
    Transformervalidationfrac = 0.0
    UsedTransformervalidationfrac = 0.0
    Transformerepochs = 200
    Transformeroptimizer = 'adam'
    Transformerverbose = 0
    TransformerOnlyFullAttention = True
    d_model = 64
    d_Attention = 2 * d_model
    if TransformerOnlyFullAttention:
        d_Attention = d_model
    d_qk = d_model
    d_intermediateqk = 2 * d_model
    num_heads = 2
    num_Encoderlayers = 2
    EncoderDropout = 0.1
    EncoderActivation = 'selu'
    d_EncoderLayer = d_Attention
    d_merge = d_model
    d_ffn = 4 * d_model
    MaskingOption = 0

"""***Num_Seq*** Number of Sequences

***Nloc*** Number of locations

***Tseq*** Length of each sequence

***Npropperseq*** Number of internal properties per sequence including static or dynamic

***NpredperseqTOT*** Total number of predictions per sequence

***d_model*** Dimension of value embedding for every input [Model1] 

***num_heads*** Number of Attention Heads which must exactly divide ***d_model***

***num_Encoderlayers*** Number of layers in Encoder stage

***EncoderDropout*** Dropout in Encoder stage, 

***d_ffn*** Size of feedforward network in each encoder layer. It appears to bet to be 4 * ***d_model*** 

***MaskingOption*** defines masking used; = 0 none; =1 mask the future

***Transformerbatch_size*** is batch size of stochastic gradient descent

***Tseq*** is size of sequence window

***Transformervalidationfrac*** is fraction used for a validation dataset

***d_sample*** The number of units presented to the Transformer which could be dynamic. Each of these inputs is used to calculate attention and is Tseq times number of locations simultaneously presented

***max_d_sample*** The maximum number of units presented to the Transformer which is fixed. It is Tseq times maximum number of locations simultaneously presented

***TransformerOnlyFullAttention*** if True calculate classic attention over all d_sample members; if False calculate separate attentions in location and time

Describe the science data sets here

Initial data is [Num_Seq][Nloc][Tseq] with values [Nforcing + ExPosEnc-Selin + Nprop-Sel]

Predictions are [Num_Seq] [Nloc] [Predvals=Npred+ExPosEnc-Selout] [Predtimes = Forecast-time range]

A subset is included in each transformer call. There are 3 options
*   Simplest: (as in LSTM) samples are labelled by [Num_Seq] [Nloc] and have input length [Tseq] with multiple features [Nforcing + ExPosEnc-Selin + Nprop-Sel] mapped into a model for each input of length [Model1]. Predictions for each input are [Predvals] [Predtimes]
*   Straightforward improvement:  Divide Nloc into sublocation groups giving Nloc/Nsub groups with Nloc-Nsub locations in each group. There are many choices of groups including fixed disjoint subgroups, overlapping groups (so that each epoch surveys each location twice and this should help spread attention). Then each sample is labelled by [Num_Seq] [Nloc/Nsub] and have input length [Nloc-Nsub][Tseq] with multiple features [Nforcing + ExPosEnc-Selin + Nprop-Sel] mapped into a model for each input of length [Model1]. Predictions for each input are [Predvals] [Predtimes]
*   (Too) Clever: Use different selections for Encoder and Decoder steps. For example feed all Nloc locations into transformer but oinly use through multi-headed attention step. One only takes a subset of these through encoder and predictions. This ensures that attention covers all locations
*   Extend "Too clever"  or "Straightforward" method for multiple initial time values in each transformer input i.e. divide [Num_Seq] into [Num_Seq/Ntsub] groups and input [Num_Seq-Ntsub] time sequences into a single transformer. This spreads attention over time. 

We can represent all the above cases by lasbelling each data sample by
{[Num_Seq][Nloc]} [Tseq] where always members of sequences are complete and selection of sequences and location for a single data sample varies in options above. Each member of a data sample has [Nforcing + ExPosEnc-Selin + Nprop-Sel] internal degrees of freedom. These degrees of freedom will be mapped (embedded) in a model variable of length ***d_model***

Size of input is ***d_sample*** = Tseq * size {[Num_Seq][Nloc]} in a single data sample. This is important throughout network whereas [Nforcing + ExPosEnc-Selin + Nprop-Sel] is immediately embedded and becomes of length ***d_model***
"""

# Set up data
# Initial data is [For Batching][Nloc_sample] [Tseq] [NpropperseqTOT] starting with RawInputSequencesTOT
# Predictions are [For Batching][Nloc_sample] [NpredperseqTOT] starting with RawInputPredictionsTOT
#  For case Nloc_sample = Nloc, the Batching is identical to Time sequence label
# dsample Tseq * Nloc

if UseScienceTransformerModel:
    Nloc_sample = Nloc
    OuterBatchDimension = Num_Seq
    if Nloc % Nloc_sample != 0:
        print("Inconsistent location numbers " + str(Nloc) + ' ' + str(Nloc_sample))
        sys.exit()
    d_sample = Tseq * Nloc
    max_d_sample = d_sample
    Transformermaximum_position_encoding = max_d_sample
    if SymbolicWindows:
        X_Transformerdetailed = np.copy(SymbolicInputSequencesTOT)
    else:
        X_Transformerdetailed = np.copy(RawInputSequencesTOT)

    y_Transformerdetailed = np.copy(RawInputPredictionsTOT)

    print(
        "The maximum number of units presented to the Transformer which is fixed.It is Tseq times maximum number of locations simultaneously presented ",
        str(max_d_sample))
    print(
        "The actual number of units presented to the Transformer for this batch.It is Tseq times  number of locations simultaneously presented in  this batch ",
        str(max_d_sample))
    print(" Number of locations in each sample presented to the Transformer ", str(Nloc_sample))
    print("Number of locations times sequence window length in each sample presented to the Transformer ",
          str(OuterBatchDimension))

"""## Scaled dot product attention for Science

This seems unchanged for science case unless ***d_sample*** is too large. One wastes time then if softmaxes too small. It could be useful just to select the largest (e.g. take top 10 or remove all probabilities < 0.001) softmax values and just process with these

Below all vectors Q K V have size ***d_model/num_heads***. They are defined for each head and for each sample member of the ***d_sample*** members

This could use the  mask described earlier but that is not used in initial version

We have a hierarchial sequence label which limits number of softmaxes calculated although number of Q K V vectors are not reduced

### Scaled dot product attention: Q K V Softmax

<img src="https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png" width="500" alt="scaled_dot_product_attention">

The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:

$$\Large{Attention(Q, K, V) = softmax_k(\frac{QK^T}{\sqrt{d_k}}) V} $$

The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. 

For example, consider that `Q` and `K` have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of `dk`. Hence, *square root of `dk`* is used for scaling (and not any other number) because the matmul of `Q` and `K` should have a mean of 0 and variance of 1, and you get a gentler softmax.

The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output.
"""


def CalculateFullAttention(q, k, v, num_heads, mask=None):
    depth = tf.shape(k)[-1]
    dk = tf.cast(depth, tf.float32)  # dk is depth in all methods
    d_qk = num_heads * depth
    if SeparateHeads:  # Spread out to save space
        HeadedAttentionVectorList = []
        for ihead in range(0, num_heads):
            matmul_qk = tf.matmul(q[:, ihead, :, :], k[:, ihead, :, :],
                                  transpose_b=True)  # [Batch, ihead, d_sample, depth] [Batch, ihead, (d_sample, depth)T ]
            scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [Batch, d_sample, d_sample]
            matmul_qk = None
            # add the mask to the scaled tensor.
            if mask is not None:  # batch,d_sample, d_sample
                scaled_attention_logits += (mask * -1e9)

            # softmax is normalized on the last axis (seq_len_k = d_sample) so that the scores add up to 1.
            # scaled_attention_logits and attention_weights [Batch,  d_sample, d_sample]
            attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
            scaled_attention_logits = None
            if mask is not None:
                attention_weights = tf.where(mask > 0.2, 0.0, attention_weights)

            # [Batch,  d_sample, d_sample] [Batch,  d_sample, depth]
            OneheadAttentionVectorfull = tf.matmul(attention_weights, v[:, ihead, :, :])
            HeadedAttentionVectorList.append(OneheadAttentionVectorfull)  # [num_heads, Batch,  d_sample,  depth]

        AttentionVectorfull = tf.convert_to_tensor(HeadedAttentionVectorList)
        # [Batch, num_heads,  d_sample,  depth]
        AttentionVectorfull = tf.transpose(AttentionVectorfull, perm=[1, 0, 2, 3])
        HeadedAttentionVectorList = None
        OneheadAttentionVectorfull = None

    else:
        if ChopupMatrix:
            basicsize = math.floor((Nloc_sample + 0.001) / ChopupNumber)
            remainder = Nloc_sample % basicsize
            Tensorlist = []
            upperlimit = 0
            for choploop in range(0, ChopupNumber):
                lowerlimit = upperlimit
                upperlimit = lowerlimit + basicsize
                if choploop < remainder:
                    upperlimit += 1
                # q k v [Batch, num_heads, d_sample, depth]
                upperlimitSeq = upperlimit * Tseq
                lowerlimitSeq = lowerlimit * Tseq
                matmul_qk = tf.matmul(q[:, :, lowerlimitSeq:upperlimitSeq, :], k[:, :, lowerlimitSeq:upperlimitSeq, :],
                                      transpose_b=True)
                # [Batch, num_heads, d_sampleCHOP, depth] [Batch, num_heads, (d_sampleCHOP, depth)T ]
                scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [Batch, num_heads, d_sampleCHOP, d_sampleCHOP]

                # add the mask to the scaled tensor.
                if mask is not None:  # batch,d_sample, d_sample
                    smallmask = mask[:, lowerlimitSeq:upperlimitSeq, lowerlimitSeq:upperlimitSeq]
                    smallmask = tf.reshape(smallmask, [smallmask.shape[0], 1, smallmask.shape[1], smallmask.shape[2]])
                    scaled_attention_logits += (smallmask * -1e9)

                attention_weights = tf.nn.softmax(scaled_attention_logits,
                                                  axis=-1)  # scaled_attention_logits [Batch, num_heads, d_sampleCHOP, d_sampleCHOP]
                if mask is not None:
                    attention_weights = tf.where(smallmask > 0.2, 0.0, attention_weights)
                Tensorlist.append(tf.matmul(attention_weights, v[:, :, lowerlimitSeq:upperlimitSeq, :]))
            AttentionVectorfull = tf.concat(Tensorlist, axis=2)
            Tensorlist = None
            smallmask = None

        else:  # FULL ATTENTION Integrated all heads done together
            matmul_qk = tf.matmul(q, k,
                                  transpose_b=True)  # [Batch, num_heads, d_sample, depth] [Batch, num_heads, (d_sample, depth)T ]
            scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [Batch, num_heads, d_sample, d_sample]

            # add the mask to the scaled tensor.
            if mask is not None:  # batch,d_sample, d_sample
                mask = tf.reshape(mask, [mask.shape[0], 1, mask.shape[1], mask.shape[2]])
                scaled_attention_logits += (mask * -1e9)

                # softmax is normalized on the last axis (seq_len_k = d_sample) so that the scores add up to 1.
            # scaled_attention_logits [Batch, num_heads, d_sample, d_sample]
            attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
            if mask is not None:
                attention_weights = tf.where(mask > 0.2, 0.0, attention_weights)

            AttentionVectorfull = tf.matmul(attention_weights,
                                            v)  # [Batch, num_heads, d_sample, d_sample] [Batch, num_heads, d_sample, d_v]

    # Below done for FULL ATTENTION as only Attention whatever SeparateHeads
    AttentionVectortemp = tf.transpose(AttentionVectorfull, perm=[0, 2, 1, 3])  # [Batch,  d_sample, num_heads, d_v]
    AttentionVector = tf.reshape(AttentionVectortemp, [q.shape[0], d_sample, num_heads * d_v])  # restore shape
    AttentionVectortemp = None
    scaled_attention_logits = None
    attention_weights = None
    matmul_qk = None
    return AttentionVector


def scaled_dot_product_attention(q, k, v, mask=None):
    # Needs externally defined  num_heads, d_sample, Nloc_sample, Tseq, d_model
    # Calculates depth
    """
  Calculate the attention weights after Q K V found
  q, k, v must have matching leading dimensions.
  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.
  The mask has different shapes depending on its type(padding or look ahead)
  but it must be broadcastable for addition.

  Args:
    q: query shape == (..., seq_len_q, depth)
    k: key shape == (..., seq_len_k, depth)
    v: value shape == (..., seq_len_v, depth_v)
    mask: Float tensor with shape broadcastable
          to (..., seq_len_q, seq_len_k). Defaults to None.

In the science Transformer, Q K V are all Batch, num_heads, d_sample, depth
where Q K V all have same number of samples d_sample
depth is always d_model/num heads

d_sample is really [Nloc_sample][Tseq] and calculates separate Location and Time Attention

Original returned attention weights but ignored. We do NOT return but rather return two attention vectors in Location and Time
If TransformerOnlyFullAttention specified, it returns  traditional full attention vector
  Returns:
    AttentionVector1 concatenated with AttentionVector2
  """
    # To scale matmul_qk
    depth = tf.shape(k)[-1]
    dk = tf.cast(depth, tf.float32)  # dk is depth in all methods
    d_qk = num_heads * depth

    # This executes JUST ONE ATTENTION -  Full
    if TransformerOnlyFullAttention:
        AttentionVector = CalculateFullAttention(q, k, v, num_heads, mask)
        mask = None
    # End ONE WAY ATTENTION

    else:  # Two way Attention
        # FIRST Calculate Attention in Time. This requires no reordering and so can be redone with shape
        # Note matmul works for all number of indices and multiplication is only done on last 2 indices
        # so using qtime means we look at attention with location fixed
        qtime = tf.reshape(q, [-1, num_heads, Nloc_sample, Tseq, depth])
        ktime = tf.reshape(k, [-1, num_heads, Nloc_sample, Tseq, depth])
        vtime = tf.reshape(v, [-1, num_heads, Nloc_sample, Tseq, d_v])
        matmul_qk = tf.matmul(qtime, ktime,
                              transpose_b=True)  # [Batch, num_heads, Nloc_sample, Tseq, depth] [Batch, num_heads, Nloc_sample, (Tseq, depth)T ]
        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [Batch, num_heads, Nloc_sample, Tseq, Tseq]
        # add the mask to the scaled tensor.
        if mask is not None:
            #      mask = tf.reshape(mask,[mask.shape[0],Nloc_sample,Tseq,Nloc_sample,Tseq]) Calulate from full mask
            #      timemask= tf.transpose(mask,perm = [0,2,4,1,3])
            #      timemask = tf.linalg.diag_part(timemask)
            #      timemask = tf.transpose(timemask,perm = [0,3,1,2])
            #      timemask = tf.reshape(timemask,[timemask.shape[0],1,Nloc_sample, Tseq, Tseq])
            # Global Time Mask is [1,1,1,Tseq,Tseq]
            timemask = tf.convert_to_tensor(GlobalTimeMask, dtype=tf.float32)  # [Batch, num_heads, Nloc_sample, Tseq, Tseq]
            scaled_attention_logits += (timemask * -1e9)

        # softmax is normalized on the last axis (Tseq) so that the scores add up to 1 in time direction separately for each space.
        attention_weights = tf.nn.softmax(scaled_attention_logits,
                                          axis=-1)  # scaled_attention_logits [Batch, num_heads, Nloc_sample, Tseq, Tseq]
        if mask is not None:
            attention_weights = tf.where(timemask > 0.2, 0.0, attention_weights)

        AttentionVector1time = tf.matmul(attention_weights,
                                         vtime)  # [Batch, num_heads, Nloc_sample, Tseq, Tseq] [Batch, num_heads,  Nloc_sample, Tseq, d_v] becomes [Batch, num_heads, Nloc_sample, Tseq, depth]
        AttentionVector1temp = tf.transpose(AttentionVector1time,
                                            perm=[0, 2, 3, 1, 4])  # [Batch,  Nloc_sample, Tseq, num_heads, d_v]
        AttentionVector1 = tf.reshape(AttentionVector1temp, [q.shape[0], d_sample, d_v * num_heads])  # restore shape
        AttentionVector1time = None
        AttentionVector1temp = None
        timemask = None

        # Purely Space-based attention as second of two attentions
        # Note we don't do Space and Full together so calculated mask is for Space and saves space
        if SpacewiseSecondAttention:
            # Code below rewrites arrays to have 5 indices exposing space and time separately
            qspace = tf.transpose(qtime, perm=[1, 0, 3, 2, 4])  # [num_heads, Batch, Tseq, Nloc_sample,  depth]
            kspace = tf.transpose(ktime, perm=[1, 0, 3, 2, 4])  # [num_heads, Batch, Tseq, Nloc_sample,  depth]
            vspace = tf.transpose(vtime, perm=[1, 0, 3, 2, 4])  # [num_heads, Batch, Tseq, Nloc_sample,  d_v]
            if SeparateHeads:
                HeadedAttentionVectorList = []
                for ihead in range(0, num_heads):
                    # [Batch,ihead, Tseq, Nloc_sample, depth] [Batch, ihead,Tseq, (Nloc_sample, depth)T ]
                    matmul_qk = tf.matmul(qspace[ihead, :, :, :, :], kspace[ihead, :, :, :, :], transpose_b=True)
                    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [Batch, Tseq, Nloc_sample, Nloc_sample]
                    if mask is not None:
                        spacemask = tf.reshape(mask, [mask.shape[0], 1, Nloc_sample, Nloc_sample])
                        scaled_attention_logits += (spacemask * -1e9)
                    attention_weights = tf.nn.softmax(scaled_attention_logits,
                                                      axis=-1)  # scaled_attention_logits [Batch,  Tseq, Nloc_sample,  Nloc_sample]
                    if mask is not None:
                        attention_weights = tf.where(spacemask > 0.2, 0.0, attention_weights)
                        # [Batch,  Tseq, Nloc_sample, Nloc_sample] [Batch,  Tseq, Nloc_sample, depth]
                    OneheadAttentionVectorspace = tf.matmul(attention_weights, vspace[ihead, :, :, :, :])
                    HeadedAttentionVectorList.append(
                        OneheadAttentionVectorspace)  # [num_heads,Batch,  Tseq, Nloc_sample,  depth]
                AttentionVector2space = tf.convert_to_tensor(HeadedAttentionVectorList)
                OneheadAttentionVectorspace = None
                HeadedAttentionVectorList = None

            else:  # Fully Integrated
                matmul_qk = tf.matmul(qspace, kspace,
                                      transpose_b=True)  # [num_heads,Batch,  Tseq, Nloc_sample, depth] [num_heads, Batch, Tseq, (Nloc_sample, depth)T ]
                scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # [num_heads, Batch, Tseq, Nloc_sample, Nloc_sample]

                # add the mask to the scaled tensor.
                if mask is not None:
                    # mask = tf.reshape(mask,[mask.shape[0],Nloc_sample,Tseq,Nloc_sample,Tseq])
                    # spacemask= mask[:,:,0,:,0]
                    # spacemask = tf.reshape(spacemask,[mask.shape[0],1,1,Nloc_sample,Nloc_sample])
                    spacemask = tf.reshape(mask, [1, mask.shape[0], 1, Nloc_sample, Nloc_sample])
                    scaled_attention_logits += (spacemask * -1e9)

                # softmax is normalized on the last axis (Nloc_sample) so that the scores add up to 1 in location direction separately for each space.
                attention_weights = tf.nn.softmax(scaled_attention_logits,
                                                  axis=-1)  # scaled_attention_logits [num_heads, Batch, Tseq, Nloc_sample,  Nloc_sample]
                if mask is not None:
                    attention_weights = tf.where(spacemask > 0.2, 0.0, attention_weights)

                AttentionVector2space = tf.matmul(attention_weights, vspace)
            # [num_heads, Batch, Tseq, Nloc_sample,  Nloc_sample] [Batch, num_heads, Tseq, Nloc_sample,  d_v] becomes [Batch, num_heads, Tseq, Nloc_sample,  d_v]

            AttentionVector2temp = tf.transpose(AttentionVector2space,
                                                perm=[1, 3, 2, 0, 4])  # [Batch,  Nloc_sample, Tseq, num_heads, d_v]
            AttentionVector2 = tf.reshape(AttentionVector2temp, [q.shape[0], d_sample, d_v * num_heads])  # restore shape
            AttentionVector2space = None
            AttentionVector2temp = None
            spacemask = None
            qspace = None
            kspace = None
            vspace = None

        # Full time-space for second attention
        else:
            AttentionVector2 = CalculateFullAttention(q, k, v, num_heads, mask)

        # Combine two attentions
        AttentionVector = tf.concat([AttentionVector1, AttentionVector2], -1)  # [Batch, d_sample,2*d_v*num_heads]
        AttentionVector1 = None
        AttentionVector2 = None
        qtime = None
        ktime = None
        vtime = None

    # Either one-way or two-way attention
    scaled_attention_logits = None
    attention_weights = None
    mask = None
    matmul_qk = None
    return AttentionVector  # [Batch,  d_sample,d_Attention]


"""## **Multi-head attention for Science**

Multi-head attention should be identical between Science ad NLP 

Note assertion that ***num_heads*** divides ***d_model***

The annotation has seq_len and similar notations which is ***d_sample***

***depth*** is calculated. It is number of words in each instance of Q, K, V for one head. Note that Q, K, V are concatenated over heads for efficient computation

We suggest possibility of doing attention not across all d_sample inputs but rather separately in time and in location. This is implemented in "Scaled Dot Product Attention"

We also allow d_Attention final size to be different from input d_model. Further we put correction of splitting into "Scaled Dot Product Attention" as it is naturally combined with other tensor reshape/transformations

### Multi-head Attention Discussion and Science version

<img src="https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png" width="500" alt="multi-head attention">


Multi-head attention consists of four parts:
*    Linear layers and split into heads.
*    Scaled dot-product attention.
*    Concatenation of heads.
*    Final linear layer.

Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. 

The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.

Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality.
"""


class Active_QKV(tf.keras.layers.Layer):
    def __init__(self, d_intermediateqkv, d_finalqkv):
        super(Active_QKV, self).__init__()

        self.d_intermediateqkv = d_intermediateqkv
        self.d_finalqkv = d_finalqkv

        self.FirstDenseqkv = tf.keras.layers.Dense(self.d_intermediateqkv,
                                                   activation=EncoderActivation)  # (batch_size, d_qkv, d_intermediateqkv)
        self.SecondDenseqkv = tf.keras.layers.Dense(self.d_finalqkv)  # (batch_size, d_qk, d_finalqkv)
        self.TheDropoutqkv = tf.keras.layers.Dropout(EncoderDropout)

    def call(self, qkv, training=None):
        Running = self.FirstDenseqkv(qkv)
        Running = self.SecondDenseqkv(Running)
        ComplexQKV = self.TheDropoutqkv(Running, training=training)

        return ComplexQKV


class MultiHeadAttention(tf.keras.layers.Layer):
    # Feed in d_model, num_heads. Nothing assumed. Other sizes implied by tensors
    # seq_len = seq_len_q = seq_len_k= seq_len_v below is d_sample

    def __init__(self):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.d_intermediateqk = d_intermediateqk
        self.d_intermediatev = d_intermediatev
        self.d_qk = d_qk
        self.d_v = d_v

        assert self.d_qk % self.num_heads == 0

        self.depth = self.d_qk // self.num_heads

        if not ActivateAttention:
            self.wq = tf.keras.layers.Dense(self.d_qk)
            self.wk = tf.keras.layers.Dense(self.d_qk)
            if not Takevasinput:
                self.wv = tf.keras.layers.Dense(self.d_v * self.num_heads)
        if ActivateAttention:
            if self.d_intermediateqk > 0:
                self.wq_aa = Active_QKV(self.d_intermediateqk, self.d_qk)
                self.wk_aa = Active_QKV(self.d_intermediateqk, self.d_qk)
            else:
                self.wq_aa = tf.keras.layers.Dense(self.d_qk, activation=EncoderActivation)
                self.wk_aa = tf.keras.layers.Dense(self.d_qk, activation=EncoderActivation)
            if not Takevasinput:
                if self.d_intermediatev > 0:
                    self.wv_aa = Active_QKV(self.d_intermediatev, self.d_v)
                else:
                    self.wv_aa = tf.keras.layers.Dense(self.d_v, activation=EncoderActivation)

        self.finaldense = tf.keras.layers.Dense(d_Attention)

    def summarize(self):
        count_tot = self.count_params()
        count_v = 0
        if ActivateAttention:
            count_q = self.wq_aa.count_params()
            count_k = self.wk_aa.count_params()
            if not Takevasinput:
                count_v = self.wv_aa.count_params()
        else:
            count_q = self.wq.count_params()
            count_k = self.wk.count_params()
            if not Takevasinput:
                count_v = self.wv.count_params()
        count_final = self.finaldense.count_params()
        print('MHA Tot ' + str(count_tot) + ' Q K V ' + str(count_q) + ' ' + str(count_k) + ' ' + str(count_v)
              + ' Dense ' + str(count_final))

    def split_heads(self, x, batch_size):
        """Split the last dimension into (num_heads, depth).
    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)
    """
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, v, k, q, Mappedv, mask=None, training=None):
        batch_size = tf.shape(q)[0]

        if ActivateAttention:
            q = self.wq_aa(q, training=training)  # (batch_size, seq_len, d_qk)
            k = self.wk_aa(k, training=training)  # (batch_size, seq_len, d_qk)
            if not Takevasinput:
                v = self.wv_aa(v, training=training)  # (batch_size, seq_len, d_v)
        else:
            q = self.wq(q)  # (batch_size, seq_len, d_qk)
            k = self.wk(k)  # (batch_size, seq_len, d_qk)
            if not Takevasinput:
                v = self.wv(v)  # (batch_size, seq_len, d_v*self.num_heads)

        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)
        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)

        if Takevasinput:
            v = []
            for i in range(0, self.num_heads):
                v.append(Mappedv)
            v = tf.convert_to_tensor(v)
            v = tf.reshape(v, (batch_size, -1, self.num_heads, Mappedv.shape[-1]))
            v = tf.transpose(v, perm=[0, 2, 1, 3])
        else:
            v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth = D_v)

        # scaled_attention.shape == (batch_size,  seq_len_q, d_Attention)
        concat_attention = scaled_dot_product_attention(q, k, v, mask)
        output = self.finaldense(concat_attention)  # (batch_size, seq_len_q, d_Attention)

        return output


"""## **Point wise feed forward network** (Original and Science)

This is used in encoder (each) layer and the decoder.  The activation layer could be 'relu' or 'selu'.

dff in code is our parameter ***d_ffn*** (size of first layer in feef forward network) and defaults to 4 * ***d_model***

Point wise feed forward network consists of two fully-connected layers with a relu or selu activation in between.
"""


def point_wise_feed_forward_network(d_EncoderLayer, d_ffn):
    return tf.keras.Sequential([
        tf.keras.layers.Dense(d_ffn, activation=EncoderActivation),  # (batch_size, seq_len, d_ffn)
        tf.keras.layers.Dense(d_EncoderLayer)  # (batch_size, seq_len, d_EncoderLayer)
    ])


"""## **Encoder and decoder**

Note the process starts with an ***Encoder*** and finishes with a ***Decoder***. These share components like multi-headed attention. We expect to look at different Decoders for science as we want floating point numbers and not as in NLP, members of a vocabulary We expect that decoder could be similar for science and NLP as it is looking for structure and that is a set of relationships which could be similar between science and NLP. .

<img src="https://www.tensorflow.org/images/tutorials/transformer/transformer.png" width="600" alt="transformer">

The transformer model follows the same general pattern as a standard [sequence to sequence with attention model](nmt_with_attention.ipynb). 

* The input sentence is passed through `N` encoder layers that generates an output for each word/token in the sequence.
* The decoder attends on the encoder's output and its own input (self-attention) to predict the next word.

### Encoder layer (Original and Science)

Each encoder layer consists of sublayers:

1.   Multi-head attention (with padding mask) 
2.    Point wise feed forward networks. 

Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.

The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_EncoderLayer` (last) axis. There are N = ***num_Encoderlayers*** encoder layers in the transformer.


I am not clear why x and sublayer(x) (input and output, out1 + ffn_output) are added. I would have concatenated. I had a similar comment on positional encoding which is added to rather than being appended to input. For science the numbers matter -- its not just patterns!
"""


class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self):
        super(EncoderLayer, self).__init__()

        self.mha = MultiHeadAttention()
        self.ffn = point_wise_feed_forward_network(d_EncoderLayer, d_ffn)

        if oldencoderversion:
            self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
            self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)

        self.dropout1 = tf.keras.layers.Dropout(EncoderDropout)
        self.dropout2 = tf.keras.layers.Dropout(EncoderDropout)

    def summarize(self):
        self.mha.summarize()
        print(startbold + startpurple + 'point_wise_feed_forward_network Sequential Net' + resetfonts)
        self.ffn.summary()

    def call(self, x, xmapped, training=None, mask=None):

        # mha adjusts to shape[-1] of x being d_model or d_EncoderLayer
        attn_output = self.mha(x, x, x, xmapped, mask=mask, training=training)  # (batch_size, input_seq_len, d_model)

        attn_output = self.dropout1(attn_output, training=training)

        if oldencoderversion:
            if np.shape(x)[-1] == np.shape(attn_output)[-1]:
                addtogether = x + attn_output
            else:
                doublex = tf.concat([x, x], -1)
                if np.shape(doublex)[-1] != np.shape(attn_output)[-1]:
                    doublex = tf.concat([doublex, doublex], -1)
                addtogether = doublex + attn_output
            out1 = self.layernorm1(addtogether)  # (batch_size, input_seq_len, d_EncoderLayer)
        else:
            out1 = attn_output

        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_EncoderLayer)
        ffn_output = self.dropout2(ffn_output, training=training)
        if oldencoderversion:
            out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_EncoderLayer)
        else:
            out2 = ffn_output

        return out2


"""### Encoder

The `Encoder` consists of:
1.   Input Embedding
2.   Positional Encoding
3.   N encoder layers

The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder.

### Encoder (Science modified Original)
"""


class Encoder(tf.keras.Model):
    def __init__(self):
        super(Encoder, self).__init__()

        # self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
        self.dense_1 = tf.keras.layers.Dense(d_model, activation=EncoderActivation)

        self.enc_layers = [EncoderLayer() for _ in range(num_Encoderlayers)]
        self.dropout = tf.keras.layers.Dropout(EncoderDropout)

    def call(self, x, training=None, mask=None):
        # adding embedding and position encoding.
        # x = self.embedding(x)  # (batch_size, input_seq_len, d_model)
        # x *= tf.math.sqrt(tf.cast(d_model, tf.float32))
        xmapped = self.dense_1(x)
        xrunning = xmapped

        xrunning = self.dropout(xrunning, training=training)
        for i in range(num_Encoderlayers):
            xrunning = self.enc_layers[i](xrunning, xmapped, training=training, mask=mask)

        return xrunning, xmapped  # (batch_size, d_sample, d_EncoderLayer)


"""### Encoder for Science

The encoder for Science is very close to the NLP version
Its output is TWO arrays
* The result of self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) before NLP position encoding applied
* The same output of Encoder used in NLP

Both are (***Transformerbatch_size***, ***d_sample***, ***d_model***)

Note this is analogous to RESNET that adds input to output after several convolutional layers. We maybe incorrectly are concatenating not adding

This interpreted as original embedded data which would have been fed into an LSTM in that model plus a second vector summarizing result of attention analysis -- a form of generalized history

We will need to convert the ***d_sample*** index to two indices ***Tseq*** * size {[Num_Seq][Nloc]}

We can run members of size {[Num_Seq][Nloc]} together in LSTM although this is not how it is done normally in pure LSTM. Alternatively we can run each sample member separately

Note each member of sample has a separate encoder output

### Decoder for Science
This is not like the NLP Decoder. Rather it will use the same two layer LSTM we have already tested extensively in COVID.

There are two important changes
1. In COVID the equivalent of ***d_sample*** held just ***Tseq*** entries -- a single window for one location. Now we feed in a window of length Tseq as in COVID but the input data is muliple cases of size {[Num_Seq][Nloc]}. As we expect to start with one  sequence per network input this is just the number of locations.
2. For each presented case, we intend to use not ust the output of encoder but rather the concatenation of two vectors of length ***d_model***

* The result of self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model) before NLP position encoding applied
* The same output of Encoder used in NLP containing concatenated attention head results

There are two possibilities to consider
1. That described above with a single input to decoder of length 2 * ***d_model*** * ***d_sample/Tseq***
2. ***d_sample/Tseq*** separate runs (in parallel or one after the other) each containing one case. This is safest" approach as closely mimics that used in COVID

Note this LSTM subsystem ends with a small FCN and so we don't need an additional linear layer

# Transformer Model for Science
"""


class EncodertoLSTMmerge(tf.keras.Model):
    def __init__(self):
        super(EncodertoLSTMmerge, self).__init__()
        self.dense_merged = tf.keras.layers.Dense(d_merge, activation=EncoderActivation)

    def call(self, Originalinput, EncoderOutput, training=None):

        EncoderOutput = tf.reshape(EncoderOutput, [EncoderOutput.shape[0], Nloc_sample, Tseq, d_EncoderLayer])

        if ReuseInputinEncoder:
            Originalinput = tf.reshape(Originalinput, [Originalinput.shape[0], Nloc_sample, Tseq, Originalinput.shape[-1]])
            Merged = tf.concat([Originalinput, EncoderOutput], -1)
        else:
            Merged = EncoderOutput
        Merged = self.dense_merged(Merged)

        return Merged

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])


"""## Prediction and Visualization Transformer

###DLprediction2D

###DLPrediction2E
"""


def DLprediction2E(Xin, yin, DLmodel, modelflag):
    # Form restricted Attention separately over Training and Validation

    if not LocationBasedValidation:
        return
    if UsedTransformervalidationfrac < 0.001 or ValidationNloc <= 0:
        return
    if SkipDL2E:
        return
    if GarbageCollect:
        gc.collect()

    SampleSize = 1
    FitRanges_PartialAtt = np.zeros([Num_Seq, Nloc, NpredperseqTOT, 5], dtype=np.float32)
    FRanges = np.full((NpredperseqTOT), 1.0, dtype=np.float32)
    # 0 count 1 mean 2 Standard Deviation 3 Min 4 Max

    print(wraptotext(
        startbold + startred + 'DLPrediction2E Partial Attention ' + current_time + ' ' + RunName + RunComment + resetfonts))

    global OuterBatchDimension, Nloc_sample, d_sample, max_d_sample

    global FullSetValidation
    saveFullSetValidation = FullSetValidation
    FullSetValidation = False
    X_predict, y_predict, Spacetime_predict, X_val, y_val, Spacetime_val = setSeparateDLinput(1, Spacetime=True)
    FullSetValidation = saveFullSetValidation

    Nloc_sample = TrainingNloc
    OuterBatchDimension = Num_Seq
    d_sample = Tseq * TrainingNloc
    max_d_sample = d_sample
    UsedValidationNloc = ValidationNloc

    if SymbolicWindows:
        X_Transformertraining = np.reshape(X_predict, (OuterBatchDimension, Nloc_sample))
    else:
        X_Transformertraining = np.reshape(X_predict, (OuterBatchDimension, d_sample, NpropperseqTOT))
    y_Transformertraining = np.reshape(y_predict, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
    Spacetime_Transformertraining = np.reshape(Spacetime_predict, (OuterBatchDimension, Nloc_sample))

    if SymbolicWindows:
        X_Transformerval = np.reshape(X_val, (OuterBatchDimension, UsedValidationNloc))
    else:
        X_Transformerval = np.reshape(X_val, (OuterBatchDimension, UsedValidationNloc * Tseq, NpropperseqTOT))
    y_Transformerval = np.reshape(y_val, (OuterBatchDimension, UsedValidationNloc, NpredperseqTOT))
    Spacetime_Transformerval = np.reshape(Spacetime_val, (OuterBatchDimension, UsedValidationNloc))

    if UseClassweights:
        sw_Transformertraining = np.empty_like(y_predict, dtype=np.float32)
        for i in range(0, sw_Transformertraining.shape[0]): \
            for j in range(0, sw_Transformertraining.shape[1]):
                for k in range(0, NpredperseqTOT):
                    sw_Transformertraining[i, j, k] = Predictionwgt[k]
        sw_Transformerval = np.empty_like(y_val, dtype=np.float32)
        for i in range(0, sw_Transformerval.shape[0]):
            for jloc in range(0, sw_Transformerval.shape[1]):
                for k in range(0, NpredperseqTOT):
                    sw_Transformerval[i, jloc, k] = Predictionwgt[k]
    else:
        sw_Transformertraining = []
        sw_Transformerval = []

    if SymbolicWindows:
        X_Transformertrainingflat2 = np.reshape(X_Transformertraining, (-1, TrainingNloc))
        X_Transformertrainingflat1 = np.reshape(X_Transformertrainingflat2, (-1))
    else:
        X_Transformertrainingflat2 = np.reshape(X_Transformertraining, (-1, TrainingNloc, Tseq, NpropperseqTOT))
        X_Transformertrainingflat1 = np.reshape(X_Transformertrainingflat2, (-1, Tseq, NpropperseqTOT))
    y_Transformertrainingflat1 = np.reshape(y_Transformertraining, (-1, NpredperseqTOT))
    Spacetime_Transformertrainingflat1 = np.reshape(Spacetime_Transformertraining, (-1))
    if UseClassweights:
        sw_Transformertrainingflat1 = np.reshape(sw_Transformertraining, (-1, NpredperseqTOT))
    if SymbolicWindows:
        X_Transformervalflat2 = np.reshape(X_Transformerval, (-1, UsedValidationNloc))
        X_Transformervalflat1 = np.reshape(X_Transformervalflat2, (-1))
    else:
        X_Transformervalflat2 = np.reshape(X_Transformerval, (-1, UsedValidationNloc, Tseq, NpropperseqTOT))
        X_Transformervalflat1 = np.reshape(X_Transformervalflat2, (-1, Tseq, NpropperseqTOT))
    y_Transformervalflat1 = np.reshape(y_Transformerval, (-1, NpredperseqTOT))
    Spacetime_Transformervalflat1 = np.reshape(Spacetime_Transformerval, (-1))
    if UseClassweights:
        sw_Transformervalflat1 = np.reshape(sw_Transformerval, (-1, NpredperseqTOT))

    meanvalue2 = 0.0
    meanvalue3 = 0.0
    meanvalue4 = 0.0
    variance2 = 0.0
    variance3 = 0.0
    variance4 = 0.0

    # START LOOP OVER SAMPLES
    samplebar = notebook.trange(SampleSize, desc='Full Samples', unit='sample')
    epochsize = 2 * OuterBatchDimension
    if IncreaseNloc_sample > 1:
        epochsize = int(epochsize / IncreaseNloc_sample)
    elif DecreaseNloc_sample > 1:
        epochsize = int(epochsize * DecreaseNloc_sample)
    bbar = notebook.trange(epochsize, desc='Batch    loop', unit='sample')
    for shuffling in range(0, SampleSize):
        if GarbageCollect:
            gc.collect()

        # TRAINING SET
        if TimeShufflingOnly:
            X_train, y_train, sw_train, Spacetime_train = shuffleDLinput(X_Transformertraining,
                                                                         y_Transformertraining, sw_Transformertraining,
                                                                         Spacetime=Spacetime_Transformertraining)
        else:
            X_train, y_train, sw_train, Spacetime_train = shuffleDLinput(X_Transformertrainingflat1,
                                                                         y_Transformertrainingflat1,
                                                                         sw_Transformertrainingflat1,
                                                                         Spacetime=Spacetime_Transformertrainingflat1)

        Nloc_sample = TrainingNloc
        OuterBatchDimension = Num_Seq
        Totaltodo = Nloc_sample * OuterBatchDimension
        if IncreaseNloc_sample > 1:
            Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
        elif DecreaseNloc_sample > 1:
            Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)
        OuterBatchDimension = int(Totaltodo / Nloc_sample)
        if OuterBatchDimension * Nloc_sample != Totaltodo:
            printexit('Inconsistent Nloc_sample ' + str(Nloc_sample))
        d_sample = Tseq * Nloc_sample
        max_d_sample = d_sample

        if SymbolicWindows:
            X_train = np.reshape(X_train, (OuterBatchDimension, Nloc_sample))
        else:
            X_train = np.reshape(X_train, (OuterBatchDimension, d_sample, NpropperseqTOT))
        y_train = np.reshape(y_train, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        sw_train = np.reshape(sw_train, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        Spacetime_train = np.reshape(Spacetime_train, (OuterBatchDimension, Nloc_sample))

        quan3 = 0.0
        quan4 = 0.0
        losspercallVl = 0.0
        losspercallTr = 0.0
        TotalTr = 0.0
        TotalVl = 0.0
        for Trainingindex in range(0, OuterBatchDimension):
            if GarbageCollect:
                gc.collect()
            X_trainlocal = X_train[Trainingindex]
            if SymbolicWindows:
                X_trainlocal = np.reshape(X_trainlocal, [1, X_trainlocal.shape[0]])
            else:
                X_trainlocal = np.reshape(X_trainlocal, [1, X_trainlocal.shape[0], X_trainlocal.shape[1]])

            Numinbatch = X_trainlocal.shape[0]
            NuminAttention = X_trainlocal.shape[1]
            NumTOTAL = Numinbatch * NuminAttention
            # SymbolicWindows X_train is indexed by Batch index, Location List for Attention. Missing 1(replace by Window), 1 (replace by properties)
            if SymbolicWindows:
                X_trainlocal = np.reshape(X_trainlocal, NumTOTAL)
                iseqarray = np.right_shift(X_trainlocal, 16)
                ilocarray = np.bitwise_and(X_trainlocal, 0b1111111111111111)
                X_train_withSeq = list()
                for iloc in range(0, NumTOTAL):
                    X_train_withSeq.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                X_train_withSeq = np.array(X_train_withSeq)
                X_train_withSeq = np.reshape(X_train_withSeq, (Numinbatch, d_sample, NpropperseqTOT))
                Time = None
                if modelflag == 1:
                    Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                PredictedVector = DLmodel(X_train_withSeq, training=PredictionTraining, Time=Time)
            else:
                Spacetime_trainlocal = Spacetime_train[Trainingindex]
                iseqarray = np.right_shift(Spacetime_trainlocal, 16)
                ilocarray = np.bitwise_and(Spacetime_trainlocal, 0b1111111111111111)
                Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                PredictedVector = DLmodel(X_trainlocal, training=PredictionTraining, Time=Time)
            PredictedVector = np.reshape(PredictedVector, (1, Nloc_sample, NpredperseqTOT))

            TrueVector = y_train[Trainingindex]
            TrueVector = np.reshape(TrueVector, (1, Nloc_sample, NpredperseqTOT))
            sw_trainlocal = sw_train[Trainingindex]
            sw_trainlocal = np.reshape(sw_trainlocal, [1, sw_trainlocal.shape[0], sw_trainlocal.shape[1]])
            losspercallTr = numpycustom_lossGCF1(TrueVector, PredictedVector, sw_trainlocal)
            quan3 += losspercallTr

            for iloc_sample in range(0, Nloc_sample):
                LocLocal = ilocarray[iloc_sample]
                SeqLocal = iseqarray[iloc_sample]
                yyhat = PredictedVector[0, iloc_sample]
                if (FitRanges_PartialAtt[SeqLocal, LocLocal, 0, 0] < 0.1):
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3] = yyhat
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4] = yyhat
                else:
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3] = np.maximum(
                        FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3], yyhat)
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4] = np.minimum(
                        FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4], yyhat)
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 0] += FRanges
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 1] += yyhat
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 2] += np.square(yyhat)

            fudge = 1.0 / (1 + Trainingindex)
            TotalTr = quan3 * fudge
            bbar.set_postfix(TotalTr=TotalTr, Tr=losspercallTr)
            bbar.update(Transformerbatch_size)
        # END Training Batch Loop
        TotalTr = quan3 / OuterBatchDimension

        # VALIDATION SET
        Nloc_sample = UsedValidationNloc
        OuterBatchDimension = Num_Seq
        Totaltodo = Nloc_sample * OuterBatchDimension
        if IncreaseNloc_sample > 1:
            Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
        elif DecreaseNloc_sample > 1:
            Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)
        OuterBatchDimension = int(Totaltodo / Nloc_sample)
        if OuterBatchDimension * Nloc_sample != Totaltodo:
            printexit('Inconsistent Nloc_sample ' + str(Nloc_sample))
        d_sample = Tseq * Nloc_sample
        max_d_sample = d_sample

        if TimeShufflingOnly:
            X_val, y_val, sw_val, Spacetime_val = shuffleDLinput(
                X_Transformerval, y_Transformerval, sw_Transformerval, Spacetime_Transformerval)
        else:
            X_val, y_val, sw_val, Spacetime_val = shuffleDLinput(
                X_Transformervalflat1, y_Transformervalflat1, sw_Transformervalflat1, Spacetime_Transformervalflat1)
            if SymbolicWindows:
                X_val = np.reshape(X_val, (OuterBatchDimension, Nloc_sample))
            else:
                X_val = np.reshape(X_val, (OuterBatchDimension, d_sample, NpropperseqTOT))
        y_val = np.reshape(y_val, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        sw_val = np.reshape(sw_val, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        Spacetime_val = np.reshape(Spacetime_val, (OuterBatchDimension, Nloc_sample))

        # START VALIDATION Batch Loop
        for Validationindex in range(0, OuterBatchDimension):
            X_valbatch = X_val[Validationindex]
            y_valbatch = y_val[Validationindex]
            sw_valbatch = sw_val[Validationindex]
            Spacetime_valbatch = Spacetime_val[Validationindex]
            if SymbolicWindows:
                X_valbatch = np.reshape(X_valbatch, [1, X_valbatch.shape[0]])
            else:
                X_valbatch = np.reshape(X_valbatch, [1, X_valbatch.shape[0], X_valbatch.shape[1]])
            y_valbatch = np.reshape(y_valbatch, [1, y_valbatch.shape[0], y_valbatch.shape[1]])
            sw_valbatch = np.reshape(sw_valbatch, [1, sw_valbatch.shape[0], sw_valbatch.shape[1]])
            Numinbatch = X_valbatch.shape[0]
            NuminAttention = X_valbatch.shape[1]
            NumTOTAL = Numinbatch * NuminAttention

            if SymbolicWindows:
                X_valbatch = np.reshape(X_valbatch, NumTOTAL)
                iseqarray = np.right_shift(X_valbatch, 16)
                ilocarray = np.bitwise_and(X_valbatch, 0b1111111111111111)
                X_valbatch_withSeq = list()
                for iloc in range(0, NumTOTAL):
                    X_valbatch_withSeq.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                X_valbatch_withSeq = np.array(X_valbatch_withSeq)
                X_valbatch_withSeq = np.reshape(X_valbatch_withSeq, (Numinbatch, d_sample, NpropperseqTOT))
                Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                PredictedVector = DLmodel(X_valbatch_withSeq, training=PredictionTraining, Time=Time)
            else:
                Spacetime_valbatch = np.reshape(Spacetime_valbatch, -1)
                iseqarray = np.right_shift(Spacetime_valbatch, 16)
                ilocarray = np.bitwise_and(Spacetime_valbatch, 0b1111111111111111)
                Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                PredictedVector = DLmodel(X_valbatch, training=PredictionTraining, Time=Time)
            PredictedVector = np.reshape(PredictedVector, (1, Nloc_sample, NpredperseqTOT))

            TrueVector = np.reshape(y_valbatch, (1, Nloc_sample, NpredperseqTOT))
            sw_valbatch = np.reshape(sw_valbatch, (1, Nloc_sample, NpredperseqTOT))

            losspercallVl = numpycustom_lossGCF1(TrueVector, PredictedVector, sw_valbatch)
            quan4 += losspercallVl

            for iloc_sample in range(0, Nloc_sample):
                LocLocal = ilocarray[iloc_sample]
                SeqLocal = iseqarray[iloc_sample]
                yyhat = PredictedVector[0, iloc_sample]
                if (FitRanges_PartialAtt[SeqLocal, LocLocal, 0, 0] < 0.1):
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3] = yyhat
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4] = yyhat
                else:
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3] = np.maximum(
                        FitRanges_PartialAtt[SeqLocal, LocLocal, :, 3], yyhat)
                    FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4] = np.minimum(
                        FitRanges_PartialAtt[SeqLocal, LocLocal, :, 4], yyhat)
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 0] += FRanges
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 1] += yyhat
                FitRanges_PartialAtt[SeqLocal, LocLocal, :, 2] += np.square(yyhat)
            TotalVl = quan4 / (1 + Validationindex)
            losspercall = (TotalTr * TrainingNloc + TotalVl * ValidationNloc) / Nloc
            bbar.update(Transformerbatch_size)
            bbar.set_postfix(Loss=losspercall, TotalTr=TotalTr, TotalVl=TotalVl, Vl=losspercallVl)
        # END VALIDATION BATCH LOOP

        # Processing at the end of Sampling Loop
        fudge = 1.0 / OuterBatchDimension
        quan2 = (quan3 * TrainingNloc + quan4 * ValidationNloc) / Nloc
        quan2 *= fudge
        meanvalue2 += quan2
        variance2 += quan2 ** 2
        if LocationBasedValidation:
            quan3 *= fudge
            quan4 *= fudge
            meanvalue3 += quan3
            meanvalue4 += quan4
            variance3 += quan3 ** 2
            variance4 += quan4 ** 2
        samplebar.update(1)
        if LocationBasedValidation:
            samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Tr=quan3, Val=quan4)
        else:
            samplebar.set_postfix(Shuffle=shuffling, Loss=quan2)
        bbar.reset()
    # End Shuffling loop

    printloss(' Full Loss ', meanvalue2, variance2, SampleSize)
    printloss(' Training Loss ', meanvalue3, variance3, SampleSize)
    printloss(' Validation Loss ', meanvalue4, variance4, SampleSize)
    global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
    GlobalLoss = meanvalue2
    GlobalTrainingLoss = meanvalue3
    GlobalValidationLoss = meanvalue4

    FitRanges_PartialAtt[:, :, :, 1] = np.divide(FitRanges_PartialAtt[:, :, :, 1], FitRanges_PartialAtt[:, :, :, 0])
    FitRanges_PartialAtt[:, :, :, 2] = np.sqrt(
        np.maximum(np.divide(FitRanges_PartialAtt[:, :, :, 2], FitRanges_PartialAtt[:, :, :, 0]) -
                   np.square(FitRanges_PartialAtt[:, :, :, 1]), 0.0))
    FitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            FitPredictions[iseq, iloc, :] = FitRanges_PartialAtt[iseq, iloc, :, 1]
    DLprediction3(yin, FitPredictions, ' Separate Attention mean values')
    FindNNSE(yin, FitPredictions, Label='Separate Attention')

    print(startbold + startred + 'END DLPrediction2E ' + current_time + ' ' + RunName + RunComment + resetfonts)
    return


def DLprediction2D(Xin, yin, DLmodel):
    # Only runs in Transformer mode
    # Input is the windows [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT] (SymbolicWindows False)
    # Input is  the sequences [Nloc] [Num_Time-1] [NpropperseqTOT] (SymbolicWindows True)
    # Input Predictions are always [Num_Seq] [NLoc] [NpredperseqTOT]
    # Label Array is always [Num_Seq][Nloc] [0=Window(first sequence)#, 1=Location]

    DLprediction2E(Xin, yin, DLmodel, 1)
    if SkipDL2D:
        return
    if GarbageCollect:
        gc.collect()
    global OuterBatchDimension, Nloc_sample, d_sample, max_d_sample

    SampleSize = 1

    FitRanges_FullAtt = np.zeros([Num_Seq, Nloc, NpredperseqTOT, 5], dtype=np.float32)
    FRanges = np.full((NpredperseqTOT), 1.0, dtype=np.float32)
    # 0 count 1 mean 2 Standard Deviation 3 Min 4 Max

    print(wraptotext(startbold + startred + 'DLPrediction2D ' + current_time + ' ' + RunName + RunComment + resetfonts))

    sw = np.empty_like(yin, dtype=np.float32)
    for i in range(0, sw.shape[0]):
        for j in range(0, sw.shape[1]):
            for k in range(0, NpredperseqTOT):
                sw[i, j, k] = Predictionwgt[k]
    labelarray = np.empty([Num_Seq, Nloc, 2], dtype=np.int32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            labelarray[iseq, iloc, 0] = iseq
            labelarray[iseq, iloc, 1] = iloc

    Totaltodo = Num_Seq * Nloc
    Nloc_sample = Nloc  # default

    if IncreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
    elif DecreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)

    if Totaltodo % Nloc_sample != 0:
        printexit('Invalid Nloc_sample ' + str(Nloc_sample) + " " + str(Totaltodo))
    d_sample = Tseq * Nloc_sample
    max_d_sample = d_sample
    OuterBatchDimension = int(Totaltodo / Nloc_sample)
    print(' Predict with ' + str(Nloc_sample) + ' sequences per sample and batch size ' + str(OuterBatchDimension))

    meanvalue2 = 0.0
    meanvalue3 = 0.0
    meanvalue4 = 0.0
    variance2 = 0.0
    variance3 = 0.0
    variance4 = 0.0

    samplebar = notebook.trange(SampleSize, desc='Full Samples', unit='sample')
    bbar = notebook.trange(OuterBatchDimension, desc='Batch    loop', unit='sample')
    for shuffling in range(0, SampleSize):
        if GarbageCollect:
            gc.collect()
        startvalue = 0
        endvalue = Num_Seq
        Xuse = Xin[startvalue:endvalue]
        yuse = yin[startvalue:endvalue]
        labeluse = labelarray[startvalue:endvalue]
        y2 = np.reshape(yuse, (-1, NpredperseqTOT)).copy()
        labelarray2 = np.reshape(labeluse, (-1, 2))

        if SymbolicWindows:
            # Xin X2 X3 not used rather ReshapedSequencesTOT
            labelarray2, y2 = shuffleDLinput(labelarray2, y2)
        else:
            X2 = np.reshape(Xuse, (-1, Tseq, NpropperseqTOT)).copy()
            X2, y2, labelarray2 = shuffleDLinput(X2, y2, labelarray2)
            X3 = np.reshape(X2, (-1, d_sample, NpropperseqTOT))
        y3 = np.reshape(y2, (-1, Nloc_sample, NpredperseqTOT))
        sw = np.reshape(sw, (-1, Nloc_sample, NpredperseqTOT))
        labelarray3 = np.reshape(labelarray2, (-1, Nloc_sample, 2))

        quan2 = 0.0
        quan3 = 0.0
        quan4 = 0.0
        for Batchindex in range(0, OuterBatchDimension):
            if GarbageCollect:
                gc.collect()

            if SymbolicWindows:
                X3local = list()
                for iloc_sample in range(0, Nloc_sample):
                    LocLocal = labelarray3[Batchindex, iloc_sample, 1]
                    SeqLocal = labelarray3[Batchindex, iloc_sample, 0]
                    X3local.append(ReshapedSequencesTOT[LocLocal, SeqLocal:SeqLocal + Tseq])
                InputVector = np.array(X3local)
            else:
                InputVector = X3[Batchindex]

            Labelsused = labelarray3[Batchindex]
            Time = SetSpacetime(np.reshape(Labelsused[:, 0], (1, -1)))
            InputVector = np.reshape(InputVector, (1, Tseq * Nloc_sample, NpropperseqTOT))
            PredictedVector = DLmodel(InputVector, training=PredictionTraining, Time=Time)
            PredictedVector = np.reshape(PredictedVector, (1, Nloc_sample, NpredperseqTOT))

            swbatched = sw[Batchindex, :, :]
            if LocationBasedValidation:
                swT = np.zeros([1, Nloc_sample, NpredperseqTOT], dtype=np.float32)
                swV = np.zeros([1, Nloc_sample, NpredperseqTOT], dtype=np.float32)
                for iloc_sample in range(0, Nloc_sample):
                    fudgeT = Nloc / TrainingNloc
                    fudgeV = Nloc / ValidationNloc
                    iloc = Labelsused[iloc_sample, 1]
                    if MappingtoTraining[iloc] >= 0:
                        swT[0, iloc_sample, :] = swbatched[iloc_sample, :] * fudgeT
                    else:
                        swV[0, iloc_sample, :] = swbatched[iloc_sample, :] * fudgeV
            TrueVector = y3[Batchindex]
            TrueVector = np.reshape(TrueVector, (1, Nloc_sample, NpredperseqTOT))
            swbatched = np.reshape(swbatched, (1, Nloc_sample, NpredperseqTOT))

            losspercall = numpycustom_lossGCF1(TrueVector, PredictedVector, swbatched)
            quan2 += losspercall
            bbar.update(1)
            if LocationBasedValidation:
                losspercallTr = numpycustom_lossGCF1(TrueVector, PredictedVector, swT)
                quan3 += losspercallTr
                losspercallVl = numpycustom_lossGCF1(TrueVector, PredictedVector, swV)
                quan4 += losspercallVl

            for iloc_sample in range(0, Nloc_sample):
                LocLocal = Labelsused[iloc_sample, 1]
                SeqLocal = Labelsused[iloc_sample, 0]
                yyhat = PredictedVector[0, iloc_sample]
                if (FitRanges_FullAtt[SeqLocal, LocLocal, 0, 0] < 0.1):
                    FitRanges_FullAtt[SeqLocal, LocLocal, :, 3] = yyhat
                    FitRanges_FullAtt[SeqLocal, LocLocal, :, 4] = yyhat
                else:
                    FitRanges_FullAtt[SeqLocal, LocLocal, :, 3] = np.maximum(FitRanges_FullAtt[SeqLocal, LocLocal, :, 3],
                                                                             yyhat)
                    FitRanges_FullAtt[SeqLocal, LocLocal, :, 4] = np.minimum(FitRanges_FullAtt[SeqLocal, LocLocal, :, 4],
                                                                             yyhat)
                FitRanges_FullAtt[SeqLocal, LocLocal, :, 0] += FRanges
                FitRanges_FullAtt[SeqLocal, LocLocal, :, 1] += yyhat
                FitRanges_FullAtt[SeqLocal, LocLocal, :, 2] += np.square(yyhat)

            fudge = 1.0 / (1.0 + Batchindex)
            mean2 = quan2 * fudge
            if LocationBasedValidation:
                mean3 = quan3 * fudge
                mean4 = quan4 * fudge
                bbar.set_postfix(AvLoss=mean2, AvTr=mean3, AvVl=mean4, Loss=losspercall, Tr=losspercallTr, Vl=losspercallVl)
            else:
                bbar.set_postfix(Loss=losspercall, AvLoss=mean2)

            # Processing at the end of Sampling Loop
        fudge = 1.0 / OuterBatchDimension
        quan2 *= fudge
        quan3 *= fudge
        quan4 *= fudge
        meanvalue2 += quan2
        variance2 += quan2 ** 2
        variance3 += quan3 ** 2
        variance4 += quan4 ** 2
        if LocationBasedValidation:
            meanvalue3 += quan3
            meanvalue4 += quan4
        samplebar.update(1)
        if LocationBasedValidation:
            samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Tr=quan3, Val=quan4)
        else:
            samplebar.set_postfix(Shuffle=shuffling, Loss=quan2)
        bbar.reset()
    # End Shuffling loop

    meanvalue2 /= SampleSize

    global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
    printloss(' Full Loss ', meanvalue2, variance2, SampleSize)
    meanvalue2 /= SampleSize
    GlobalLoss = meanvalue2
    GlobalTrainingLoss = 0.0
    GlobalValidationLoss = 0.0

    if LocationBasedValidation:
        printloss(' Training Loss ', meanvalue3, variance3, SampleSize)
        printloss(' Validation Loss ', meanvalue4, variance4, SampleSize)
        meanvalue3 /= SampleSize
        meanvalue4 /= SampleSize
        GlobalTrainingLoss = meanvalue3
        GlobalValidationLoss = meanvalue4

    FitRanges_FullAtt[:, :, :, 1] = np.divide(FitRanges_FullAtt[:, :, :, 1], FitRanges_FullAtt[:, :, :, 0])
    FitRanges_FullAtt[:, :, :, 2] = np.sqrt(
        np.maximum(np.divide(FitRanges_FullAtt[:, :, :, 2], FitRanges_FullAtt[:, :, :, 0]) -
                   np.square(FitRanges_FullAtt[:, :, :, 1]), 0.0))
    FitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            FitPredictions[iseq, iloc, :] = FitRanges_FullAtt[iseq, iloc, :, 1]
    DLprediction3(yin, FitPredictions, ' Full Attention mean values')
    FindNNSE(yin, FitPredictions, Label='Full Attention')

    print(startbold + startred + 'END DLPrediction2D ' + current_time + ' ' + RunName + RunComment + resetfonts)
    return


def printloss(name, mean, var, SampleSize, lineend=''):
    mean /= SampleSize
    var /= SampleSize
    std = math.sqrt(var - mean ** 2)
    print(name + ' Mean ' + str(round(mean, 5)) + ' Std Deviation ' + str(round(std, 7)) + ' ' + lineend)


"""###DLprediction2 numpysimplepartloss"""


def numpysimplepartloss(y_actual, y_pred):
    flagGCF = np.isnan(y_actual)
    y_actual1 = y_actual[np.logical_not(flagGCF)]
    y_pred1 = y_pred[np.logical_not(flagGCF)]
    loss = np.sum(np.square(y_actual1 - y_pred1))

    return loss


def DLprediction2(Xin, yin, DLmodel):
    # Input is the windows [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT] (SymbolicWindows False)
    # Input is  the sequences [Nloc] [Num_Time-1] [NpropperseqTOT] (SymbolicWindows True)
    # Input Predictions are always [Num_Seq] [NLoc] [NpredperseqTOT]
    # Label Array is always [Num_Seq][Nloc] [0=Window(first sequence)#, 1=Location]

    # Calculate predictions when data selected in time windows of various sizes
    if SkipDL2:
        return

    if GarbageCollect:
        gc.collect()

    TimeScope = [1, 2, 5, 10, 25, 50, math.floor(Num_Seq / 2), Num_Seq]
    NumberScopes = len(TimeScope)
    Timebest = []
    Timemean = []
    Timestd = []
    SampleSize = 1000

    print(wraptotext(startbold + startred + 'DLPrediction2 ' + current_time + ' ' + RunName + RunComment + ' ' + str(
        NumberScopes) + ' Time Scopes ' + resetfonts))
    sw = np.empty([Nloc, NpredperseqTOT], dtype=np.float32)
    for iloc in range(0, Nloc):
        for k in range(0, NpredperseqTOT):
            sw[iloc, k] = Predictionwgt[k]
    labelarray = np.empty([Num_Seq, Nloc, 2], dtype=np.int32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            labelarray[iseq, iloc, 0] = iseq
            labelarray[iseq, iloc, 1] = iloc

    global OuterBatchDimension, Nloc_sample, d_sample, max_d_sample
    OuterBatchDimension = Num_Seq
    Nloc_sample = Nloc
    d_sample = Tseq * Nloc
    max_d_sample = d_sample

    # LOOP OVER TIME SCOPES
    for TimeScopeLoop in range(0, NumberScopes):
        localtimeinterval = TimeScope[TimeScopeLoop]
        bestvalue2 = 0.0
        meanvalue2 = 0.0
        variance2 = 0.0
        gatherhist2 = []
        gatherhist3 = []
        gatherhist4 = []
        meanvalue3 = 0.0
        meanvalue4 = 0.0
        np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))
        possible = Num_Seq - localtimeinterval + 1

        samplebar = notebook.trange(SampleSize, desc='Time scope interval ' + str(localtimeinterval), unit='sample')
        for shuffling in range(0, SampleSize):
            if GarbageCollect:
                gc.collect()
            startvalue = np.random.randint(possible)  # Selected randomly
            endvalue = startvalue + localtimeinterval
            Xuse = Xin[startvalue:endvalue]
            yuse = yin[startvalue:endvalue]
            labeluse = labelarray[startvalue:endvalue]
            y2 = np.reshape(yuse, (-1, NpredperseqTOT)).copy()
            labelarray2 = np.reshape(labeluse, (-1, 2))

            if SymbolicWindows:
                # Xin X2 X3 not used rather ReshapedSequencesTOT
                labelarray2, y2 = shuffleDLinput(labelarray2, y2)
            else:
                X2 = np.reshape(Xuse, (-1, Tseq, NpropperseqTOT)).copy()
                X2, y2, labelarray2 = shuffleDLinput(X2, y2, labelarray2)
                X3 = np.reshape(X2, (-1, d_sample, NpropperseqTOT))
            y3 = np.reshape(y2, (-1, Nloc_sample, NpredperseqTOT))
            labelarray3 = np.reshape(labelarray2, (-1, Nloc_sample, 2))

            quan2 = 0.0
            quan3 = 0.0
            quan4 = 0.0
            ct3 = 0.0
            ct4 = 0.0
            Batchsizeused = 1

            for Batchindex in range(0, Batchsizeused):
                if SymbolicWindows:
                    X3local = list()
                    for iloc_sample in range(0, Nloc_sample):
                        LocLocal = labelarray3[Batchindex, iloc_sample, 1]
                        SeqLocal = labelarray3[Batchindex, iloc_sample, 0]
                        X3local.append(ReshapedSequencesTOT[LocLocal, SeqLocal:SeqLocal + Tseq])
                    InputVector = np.array(X3local)
                else:
                    InputVector = X3[Batchindex]

                Labelsused = labelarray3[Batchindex]
                # Calculate Time so we can set FutureMask [i 0:NumTOTAL.t in 0:Tseq, j 0:NumTOTAL u in 0:Tseq]= 1 if Time[j] > Time[i]
                # which Implies this case is vetoed
                Time = SetSpacetime(np.reshape(Labelsused[:, 0], (1, -1)))
                InputVector = np.reshape(InputVector, (1, Tseq * Nloc, NpropperseqTOT))
                PredictedVector = DLmodel(InputVector, training=PredictionTraining, Time=Time)
                PredictedVector = np.reshape(PredictedVector, (1, Nloc, NpredperseqTOT))

                swbatched = np.reshape(sw, (1, Nloc, NpredperseqTOT))
                if LocationBasedValidation:
                    swT = np.zeros([1, Nloc, NpredperseqTOT], dtype=np.float32)
                    swV = np.zeros([1, Nloc, NpredperseqTOT], dtype=np.float32)
                    for iloc_sample in range(0, Nloc_sample):
                        fudgeT = Nloc / TrainingNloc
                        fudgeV = Nloc / ValidationNloc
                        iloc = Labelsused[iloc_sample, 1]
                        if MappingtoTraining[iloc] >= 0:
                            swT[0, iloc_sample, :] = swbatched[0, iloc_sample, :] * fudgeT
                            ct3 += 1.0
                        else:
                            swV[0, iloc_sample, :] = swbatched[0, iloc_sample, :] * fudgeV
                            ct4 += 1.0
                    swT = np.reshape(swT, (1, Nloc, NpredperseqTOT))
                    swV = np.reshape(swV, (1, Nloc, NpredperseqTOT))
                TrueVector = y3[Batchindex]
                TrueVector = np.reshape(TrueVector, (1, Nloc, NpredperseqTOT))

                quan2 += numpycustom_lossGCF1(TrueVector, PredictedVector, swbatched)
                if LocationBasedValidation:
                    quan3 += numpycustom_lossGCF1(TrueVector, PredictedVector, swT)
                    quan4 += numpycustom_lossGCF1(TrueVector, PredictedVector, swV)

            fudge = 1.0 / Batchsizeused
            quan2 *= fudge
            meanvalue2 += quan2
            variance2 += quan2 ** 2
            if LocationBasedValidation:
                quan3 *= TrainingNloc / ct3
                meanvalue3 += quan3
                quan4 *= ValidationNloc / ct4
                meanvalue4 += quan4
                gatherhist3.append(quan3)
                gatherhist4.append(quan4)

            gatherhist2.append(quan2)
            if shuffling == 0:
                bestvalue2 = quan2
            else:
                if bestvalue2 > quan2:
                    bestvalue2 = quan2

            samplebar.update(1)
            if LocationBasedValidation:
                samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Bestloss=bestvalue2, Tr=quan3, Val=quan4)
            else:
                samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Bestloss=bestvalue2)

        # End Shuffling loop

        meanvalue2 /= SampleSize
        variance2 /= SampleSize
        std2 = math.sqrt(variance2 - meanvalue2 ** 2)
        Timemean.append(meanvalue2)
        Timestd.append(std2)
        Timebest.append(bestvalue2)
        plt.hist(gatherhist2, 30, facecolor='b', alpha=0.75)
        plt.title(
            RunComment + ' ' + RunName + ' Time Scope ' + str(localtimeinterval) + ' Mean ' + str(round(meanvalue2, 6)))
        plt.xlabel('Sum over Training plus Validation samples given time interval')
        plt.ylabel('Numbers')
        plt.grid(True)
        plt.show()
        if LocationBasedValidation:
            meanvalue3 /= SampleSize
            plt.hist(gatherhist3, 30, facecolor='b', alpha=0.75)
            plt.title(
                RunComment + ' ' + RunName + ' Time Scope ' + str(localtimeinterval) + ' Mean ' + str(round(meanvalue3, 6)))
            plt.xlabel('Sum over Training samples given time interval')
            plt.ylabel('Numbers')
            plt.grid(True)
            plt.show()
            meanvalue4 /= SampleSize
            plt.hist(gatherhist4, 30, facecolor='b', alpha=0.75)
            plt.title(RunComment + ' ' + RunName + ' Time Interval ' + str(localtimeinterval) + ' Mean ' + str(
                round(meanvalue4, 6)))
            plt.xlabel('Sum over Validation samples given time interval ' + str(localtimeinterval))
            plt.ylabel('Numbers')
            plt.grid(True)
            plt.show()

            corr = 0.0
            v3 = 0.0
            v4 = 0.0
            for ipos in range(0, SampleSize):
                tr = gatherhist3[ipos] - meanvalue3
                val = gatherhist4[ipos] - meanvalue4
                v3 += tr * tr
                v4 += val * val
                corr += tr * val
            v3 = math.sqrt(v3 / SampleSize)
            v4 = math.sqrt(v4 / SampleSize)
            corr /= (v3 * v4 * SampleSize)
            print(startbold + 'Time Interval ' + str(localtimeinterval) + ' Train ' + str(
                round(meanvalue3, 6)) + ' std ' + str(round(v3, 6))
                  + ' Val ' + str(round(meanvalue4, 6)) + ' std ' + str(round(v4, 6)) + ' Correlation ' + str(
                round(corr, 4)) + resetfonts)

            if LocationBasedValidation:
                Train = np.asarray(gatherhist3)
                Val = np.asarray(gatherhist4)
                Trainorder = np.argsort(Train)
                Train = np.take_along_axis(Train, Trainorder, axis=0)
                Val = np.take_along_axis(Val, Trainorder, axis=0)
                i1 = SampleSize / 2
                i2 = SampleSize / 4
                i3 = SampleSize / 10
                i4 = 10
                LengthList = [1, i4, i3, i2, i1, SampleSize]
                line = ""
                for i in range(0, len(LengthList)):
                    ilength = int(LengthList[i])
                    Cuttrain = np.mean(Train[0:ilength])
                    Cutval = np.mean(Val[0:ilength])
                    line += str(ilength) + " Tr " + str(round(Cuttrain, 5)) + " Vl " + str(round(Cutval, 5)) + " "
                print(line)
    # End TimeScope Loop

    for TimeScopeLoop in range(0, NumberScopes):
        localtimeinterval = TimeScope[TimeScopeLoop]
        print('Time Interval ' + str(localtimeinterval) + ' mean ' + str(round(Timemean[TimeScopeLoop], 6)) + ' STD ' +
              str(round(Timestd[TimeScopeLoop], 6)) + ' best ' + str(round(Timebest[TimeScopeLoop], 6)))

    print(startbold + startred + 'END DLPrediction2 ' + current_time + ' ' + RunName + RunComment + resetfonts)

    return


"""###DLPrediction2B"""


def DLprediction2B(Xin, yin, DLmodel):
    # Input is the windows [Num_Seq] [Nloc] [Tseq] [NpropperseqTOT] (SymbolicWindows False)
    # Input is  the sequences [Nloc] [Num_Time-1] [NpropperseqTOT] (SymbolicWindows True)
    # Input Predictions are always [Num_Seq] [NLoc] [NpredperseqTOT]

    # Calculate Predictions with full sampling and record range of values
    if SkipDL2B:
        return
    current_time = timenow()
    print(wraptotext(startbold + startpurple + current_time + ' ' + RunName + ' ' + RunComment +
                     ' DLprediction2B Full Sampling Predictions Follow' + resetfonts))
    if GarbageCollect:
        gc.collect()
    FitPredictions = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    FitRanges = np.zeros([Num_Seq, Nloc, NpredperseqTOT, 5], dtype=np.float32)
    FitPredictions0 = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    FitPredictions1 = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    FitPredictions2 = np.zeros([Num_Seq, Nloc, NpredperseqTOT], dtype=np.float32)
    # 0 count 1 mean 2 Standard Deviation 3 Min 4 Max

    global OuterBatchDimension, Nloc_sample, d_sample, max_d_sample
    Totaltodo = Num_Seq * Nloc
    Nloc_sample = Nloc  # default

    if IncreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
    elif DecreaseNloc_sample > 1:
        Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)

    if Totaltodo % Nloc_sample != 0:
        printexit('Invalid Nloc_sample ' + str(Nloc_sample) + " " + str(Totaltodo))
    d_sample = Tseq * Nloc_sample
    max_d_sample = d_sample
    OuterBatchDimension = int(Totaltodo / Nloc_sample)
    print(' Predict with ' + str(Nloc_sample) + ' sequences per sample and batch size ' + str(OuterBatchDimension))

    labelarray = np.empty([Num_Seq, Nloc, 2], dtype=np.int32)
    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            labelarray[iseq, iloc, 0] = iseq
            labelarray[iseq, iloc, 1] = iloc
    FRanges = np.empty([NpredperseqTOT], dtype=np.float32)
    for k in range(0, NpredperseqTOT):
        FRanges[k] = 1.0
    numpyPredictionwgt = np.asarray(Predictionwgt)

    RMSEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    IntrinsicRMSEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    MaxEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    MinEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    count = np.zeros([NpredperseqTOT], dtype=np.float64)
    floss = 0.0

    samplebar = notebook.trange(SampleSize, desc='Predict loop', unit='Complete Shuffle')
    bbar = notebook.trange(OuterBatchDimension, desc='Batch    loop', unit='sample')

    bestvalue1 = 0.0
    bestvalue2 = 0.0
    meanvalue1 = 0.0
    meanvalue2 = 0.0
    meanvalue3 = 0.0
    meanvalue4 = 0.0
    gatherhist1 = []
    gatherhist2 = []
    Ctime1 = 0.0
    Ctime2 = 0.0
    Ctime3 = 0.0
    for shuffling in range(0, SampleSize):
        if GarbageCollect:
            gc.collect()
        y2 = np.reshape(yin, (-1, NpredperseqTOT))
        labelarray2 = np.reshape(labelarray, (-1, 2))
        if SymbolicWindows:
            labelarray2, y2 = shuffleDLinput(labelarray2, y2)
            Locarray = labelarray2[:, 1]
            Seqarray = labelarray2[:, 0]
            Locarray = np.reshape(Locarray, (OuterBatchDimension, Nloc_sample))
            Seqarray = np.reshape(Seqarray, (OuterBatchDimension, Nloc_sample))
        else:
            X2 = np.reshape(Xin, (-1, Tseq, NpropperseqTOT))
            X2, y2, labelarray2 = shuffleDLinput(X2, y2, labelarray2)
            X3 = np.reshape(X2, (OuterBatchDimension, d_sample, NpropperseqTOT))
        y3 = np.reshape(y2, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        labelarray3 = np.reshape(labelarray2, (OuterBatchDimension, Nloc_sample, 2))

        quan1 = 0.0
        quan2 = 0.0
        quan3 = 0.0
        quan4 = 0.0
        count3 = 0
        count4 = 0
        for Batchindex in range(0, OuterBatchDimension):
            if GarbageCollect:
                gc.collect()
            StopWatch.start('label1')
            if SymbolicWindows:
                X3 = list()
                for iloc in range(0, Nloc_sample):
                    LocLocal = Locarray[Batchindex, iloc]
                    SeqLocal = Seqarray[Batchindex, iloc]
                    X3.append(ReshapedSequencesTOT[LocLocal, SeqLocal:SeqLocal + Tseq])
                InputVector = np.array(X3)
            else:
                InputVector = X3[Batchindex]
            InputVector = np.reshape(InputVector, (1, Tseq * Nloc_sample, NpropperseqTOT))
            # Calculate Time so we can set FutureMask [i 0:NumTOTAL.t in 0:Tseq, j 0:NumTOTAL u in 0:Tseq]= 1 if Time[j] > Time[i]
            # which Implies this case is vetoed
            Time = SetSpacetime(np.reshape(labelarray3[Batchindex, :, 0], (1, -1)))
            StopWatch.stop('label1')
            Ctime1 += StopWatch.get('label1', digits=4)

            StopWatch.start('label2')
            PredictedVector = DLmodel(InputVector, training=PredictionTraining, Time=Time)
            PredictedVector = np.reshape(PredictedVector, (Nloc_sample, NpredperseqTOT))
            Time = None
            StopWatch.stop('label2')
            Ctime2 += StopWatch.get('label2', digits=4)
            StopWatch.start('label3')
            losspercall = 0.0
            count5 = 0
            for iloc_sample in range(0, Nloc_sample):
                yyhat = PredictedVector[iloc_sample]

                iseq = labelarray3[Batchindex, iloc_sample, 0]
                iloc = labelarray3[Batchindex, iloc_sample, 1]
                yy = yin[iseq, iloc]
                FitPredictions0[iseq, iloc] = yyhat
                yy1 = yy[0:Npredperseq]
                yyhat1 = yyhat[0:Npredperseq]
                quan1 += numpycustom_lossGCF1(yy1, yyhat1, numpyPredictionwgt[0:Npredperseq])
                loss = numpycustom_lossGCF1(yy, yyhat, numpyPredictionwgt)
                quan2 += loss
                losspercall += loss
                if MappingtoTraining[iloc] >= 0:
                    quan3 += loss
                    count3 += 1
                    count5 += 1
                else:
                    quan4 += loss
                    count4 += 1

                if (FitRanges[iseq, iloc, 0, 0] < 0.1):
                    FitRanges[iseq, iloc, :, 3] = yyhat
                    FitRanges[iseq, iloc, :, 4] = yyhat
                else:
                    FitRanges[iseq, iloc, :, 3] = np.maximum(FitRanges[iseq, iloc, :, 3], yyhat)
                    FitRanges[iseq, iloc, :, 4] = np.minimum(FitRanges[iseq, iloc, :, 4], yyhat)
                FitRanges[iseq, iloc, :, 0] += FRanges
                FitRanges[iseq, iloc, :, 1] += yyhat
                FitRanges[iseq, iloc, :, 2] += np.square(yyhat)
            StopWatch.stop('label3')
            Ctime3 += StopWatch.get('label3', digits=4)
            bbar.update(1)
            losspercall /= float(Nloc_sample)
            Tr = 0.0
            if count3 > 0:
                Tr = quan3 / count3
            if count4 > 0:
                Vl = quan4 / count4
                bbar.set_postfix(Loss=losspercall, Tr=Tr, Vl=Vl, Cttr=count5)
            else:
                bbar.set_postfix(Loss=losspercall, Tr=Tr, Cttr=count5)

        fudge = 1.0 / (OuterBatchDimension * Nloc_sample)
        quan1 *= fudge
        quan2 *= fudge
        quan3 /= (Num_Seq * TrainingNloc)
        if ValidationNloc > 0:
            quan4 /= (Num_Seq * ValidationNloc)
        gatherhist1.append(quan1)
        gatherhist2.append(quan2)

        if shuffling == 0:
            FitPredictions1 = FitPredictions0.copy()
            FitPredictions2 = FitPredictions0.copy()
            bestvalue1 = quan1
            bestvalue2 = quan2
        if ((shuffling > 0) and (quan1 < bestvalue1)):
            FitPredictions1 = FitPredictions0.copy()
            bestvalue1 = quan1
        if ((shuffling > 0) and (quan2 < bestvalue2)):
            FitPredictions2 = FitPredictions0.copy()
            bestvalue2 = quan2

        meanvalue1 += quan1
        meanvalue2 += quan2
        meanvalue3 += quan3
        meanvalue4 += quan4

        samplebar.update(1)
        samplebar.set_postfix(Shuffle=shuffling, Loss=quan2, Bestloss=bestvalue2)
        bbar.reset()
    # End Shuffling loop

    current_time = timenow()
    print(
        startbold + startpurple + current_time + RunName + ' ' + RunComment + ' DLprediction2B Summarize Full Sampling Results' + resetfonts)
    print('Times ' + str(round(Ctime1, 5)) + ' ' + str(round(Ctime3, 5)) + ' TF ' + str(round(Ctime2, 5)))
    meanvalue1 /= SampleSize
    meanvalue2 /= SampleSize
    meanvalue3 /= SampleSize
    meanvalue4 /= SampleSize
    print(' Only observed Quantities Best ' + str(round(bestvalue1, 5)) + '  Mean ' + str(round(meanvalue1, 5)))
    print(' All predictions Best ' + str(round(bestvalue2, 5)) + '  Mean ' + str(round(meanvalue2, 5)))
    print(' All predictions Mean Training ' + str(round(meanvalue3, 5)) + '  Mean Validation ' + str(round(meanvalue4, 5)))

    global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
    GlobalLoss = meanvalue1
    if LocationBasedValidation:
        GlobalTrainingLoss = meanvalue3
        GlobalValidationLoss = meanvalue4

    plt.rcParams["figure.figsize"] = [8, 6]
    gatherhist1 = np.asarray(gatherhist1, dtype=np.float32)
    meanhist1 = np.mean(gatherhist1)
    plt.hist(gatherhist1, 50, density=False, facecolor='g', alpha=0.75)
    plt.title(RunComment + ' ' + RunName + ' Mean% ' + str(round(meanhist1, 6)))
    plt.xlabel('Sum over Basic Quantities mean%')
    plt.ylabel('Numbers')
    plt.grid(True)
    plt.show()
    gatherhist2 = np.asarray(gatherhist2, dtype=np.float32)
    meanhist2 = np.mean(gatherhist2)
    plt.hist(gatherhist2, 30, facecolor='r', alpha=0.75)
    plt.title(RunComment + ' ' + RunName + ' Mean% ' + str(round(meanhist2, 6)))
    plt.xlabel('Sum over all Predictions mean% ')
    plt.ylabel('Numbers')
    plt.grid(True)
    plt.show()

    DLprediction3(yin, FitPredictions1, ' Basic Quantities')
    DLprediction3(yin, FitPredictions2, ' Best sum over predictions', Dumpplot=True)

    FitRanges[:, :, :, 1] = np.divide(FitRanges[:, :, :, 1], FitRanges[:, :, :, 0])
    FitRanges[:, :, :, 2] = np.sqrt(np.maximum(np.divide(FitRanges[:, :, :, 2], FitRanges[:, :, :, 0]) -
                                               np.square(FitRanges[:, :, :, 1]), 0.0))
    print(
        wraptotext(RunComment + ' ' + RunName + '  DLprediction2B Best Basic Error% ' + str(round(100.0 * bestvalue1, 4)) +
                   ' Best Total Error% ' + str(round(100.0 * bestvalue2, 4))))

    for iseq in range(0, Num_Seq):
        for iloc in range(0, Nloc):
            FitPredictions[iseq, iloc, :] = FitRanges[iseq, iloc, :, 1]
            yy = yin[iseq, iloc]
            for i in range(0, NpredperseqTOT):
                if (math.isnan(yy[i])):
                    continue
                mse = Predictionwgt[i] * (yy[i] - FitPredictions[iseq, iloc, i]) ** 2
                RMSEbyclass[i] += mse
                if i < Npredperseq:
                    floss += mse
                IntrinsicRMSEbyclass[i] += FitRanges[iseq, iloc, i, 2] ** 2
                MaxEbyclass[i] += np.subtract(FitRanges[iseq, iloc, i, 3], FitRanges[iseq, iloc, i, 1])
                MinEbyclass[i] += np.subtract(FitRanges[iseq, iloc, i, 1], FitRanges[iseq, iloc, i, 4])
                count[i] += 1.0

    floss /= (Num_Seq * Nloc)
    RMSEbyclass1 = np.divide(RMSEbyclass, count)
    RMSEbyclass2 = np.sqrt(np.divide(IntrinsicRMSEbyclass, count))
    MaxEbyclass1 = np.divide(MaxEbyclass, count)
    MinEbyclass1 = np.divide(MinEbyclass, count)
    extracomments = []
    print('Total observed Loss ' + str(round(floss, 6)))
    for i in range(0, NpredperseqTOT):
        print('RMSE % ' + str(i) + ' ' + Predictionname[PredictionNameIndex[i]] + ' ' + str(round(count[i], 0)) + ' ' +
              str(round(RMSEbyclass1[i], 6)) + ' ' + str(round(100.0 * RMSEbyclass2[i], 4))
              + ' ' + str(round(100.0 * MaxEbyclass1[i], 4)) + ' ' + str(round(100.0 * MinEbyclass1[i], 4)))
        extracomments.append(['Loss Coeff ' + str(round(RMSEbyclass1[i], 5))
                              + ' Intrinsic RMSE% ' + str(round(100.0 * RMSEbyclass2[i], 4)), ' '])

    current_time = timenow()
    print(wraptotext(
        startbold + startpurple + current_time + ' ' + RunName + ' These FULL plots with uncertainties from DLprediction2B '
        + ' ' + RunComment + resetfonts))
    global SeparateValandTrainingPlots
    saveflag = SeparateValandTrainingPlots
    SeparateValandTrainingPlots = False
    Location_summed_plot(0, yin, FitPredictions, extracomments=extracomments)
    otherlabs2 = ['Max', 'Min']
    otherfits2 = np.array([np.subtract(FitRanges[:, :, :, 3], FitRanges[:, :, :, 1]),
                           np.subtract(FitRanges[:, :, :, 4], FitRanges[:, :, :, 1])])
    Location_summed_plot(0, yin, FitPredictions, extracomments=extracomments, otherlabs=otherlabs2, otherfits=otherfits2)
    SeparateValandTrainingPlots = saveflag
    print(startbold + startpurple + 'End DLprediction2B NNSE and Individual Plots Follow' + resetfonts)

    FindNNSE(yin, FitPredictions, Label='DL2B Full Att')
    if IndividualPlots:
        ProduceIndividualPlots(yin, FitPredictions)
    if Earthquake and EarthquakeImagePlots:
        ProduceSpatialQuakePlot(yin, FitPredictions)

    return FitPredictions


"""###DLPrediction3"""


def DLprediction3(yin, FitPredictions, LabelFit, Dumpplot=False):
    # Input Predictions are [Num_Seq] [NLoc] [NpredperseqTOT]
    # Use NumericalCutoff and TimeCutLabel from DLPrediction for start and End Sections

    current_time = timenow()
    print(wraptotext(startbold + startpurple + current_time + ' ' + RunName + ' These plots from DLprediction3 '
                     + LabelFit + ' ' + RunComment + resetfonts))
    RMSEbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSETRAINbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSEVALbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    RMSVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    AbsEbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    AbsVbyclass = np.zeros([NpredperseqTOT], dtype=np.float64)
    ObsVbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT], dtype=np.float64)
    Predbytimeandclass = np.zeros([Num_Seq, NpredperseqTOT], dtype=np.float64)
    countbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    countVALbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    countTRAINbyclass = np.zeros([NpredperseqTOT, 3], dtype=np.float64)
    totalcount = 0
    overcount = 0
    weightedcount = 0.0
    weightedovercount = 0.0
    weightedrmse1 = 0.0
    weightedrmse1TRAIN = 0.0
    weightedrmse1VAL = 0.0

    for iseq in range(0, Num_Seq):
        yyy = FitPredictions[iseq]
        for iloc in range(0, Nloc):
            yy = yin[iseq, iloc]
            yyhat = yyy[iloc]

            sum1 = 0.0
            for i in range(0, NpredperseqTOT):
                overcount += 1
                weightedovercount += Predictionwgt[i]

                if (math.isnan(yy[i])):
                    continue
                weightedcount += Predictionwgt[i]
                totalcount += 1
                mse1 = (yy[i] - yyhat[i]) ** 2
                mse = mse1 * Predictionwgt[i]
                sum1 += mse
                AbsEbyclass[i] += abs(yy[i] - yyhat[i])
                RMSVbyclass[i] += yy[i] ** 2
                AbsVbyclass[i] += abs(yy[i])
                RMSEbyclass[i, 0] += mse
                countbyclass[i, 0] += 1.0
                if iseq < NumericalCutoff:
                    countbyclass[i, 1] += 1.0
                    RMSEbyclass[i, 1] += mse
                else:
                    countbyclass[i, 2] += 1.0
                    RMSEbyclass[i, 2] += mse
                ObsVbytimeandclass[iseq, i] += abs(yy[i])
                Predbytimeandclass[iseq, i] += abs(yyhat[i])
                if LocationBasedValidation:
                    if MappingtoTraining[iloc] >= 0:
                        RMSETRAINbyclass[i, 0] += mse
                        countTRAINbyclass[i, 0] += 1.0
                        if iseq < NumericalCutoff:
                            RMSETRAINbyclass[i, 1] += mse
                            countTRAINbyclass[i, 1] += 1.0
                        else:
                            RMSETRAINbyclass[i, 2] += mse
                            countTRAINbyclass[i, 2] += 1.0
                    if MappingtoValidation[iloc] >= 0:
                        RMSEVALbyclass[i, 0] += mse
                        countVALbyclass[i, 0] += 1.0
                        if iseq < NumericalCutoff:
                            RMSEVALbyclass[i, 1] += mse
                            countVALbyclass[i, 1] += 1.0
                        else:
                            RMSEVALbyclass[i, 2] += mse
                            countVALbyclass[i, 2] += 1.0

            weightedrmse1 += sum1
            if LocationBasedValidation:
                if MappingtoTraining[iloc] >= 0:
                    weightedrmse1TRAIN += sum1
                if MappingtoValidation[iloc] >= 0:
                    weightedrmse1VAL += sum1

    weightedrmse1 *= 1.0 / (Num_Seq * Nloc)
    RMSEbyclass = np.divide(RMSEbyclass, countbyclass)
    if LocationBasedValidation:
        weightedrmse1TRAIN /= (Num_Seq * TrainingNloc)
        for i in range(0, NpredperseqTOT):
            RMSETRAINbyclass[i, 0] /= countTRAINbyclass[i, 0]
            RMSETRAINbyclass[i, 1] /= countTRAINbyclass[i, 1]
            RMSETRAINbyclass[i, 2] /= countTRAINbyclass[i, 2]
        if ValidationNloc > 0:
            weightedrmse1VAL /= (Num_Seq * ValidationNloc)
            for i in range(0, NpredperseqTOT):
                RMSEVALbyclass[i, 0] /= countVALbyclass[i, 0]
                RMSEVALbyclass[i, 1] /= countVALbyclass[i, 1]
                RMSEVALbyclass[i, 2] /= countVALbyclass[i, 2]

    line = ''
    global GlobalTrainingLoss, GlobalValidationLoss, GlobalLoss
    GlobalLoss = weightedrmse1
    if LocationBasedValidation:
        line = ' Training ' + str(round(weightedrmse1TRAIN, 6)) + ' Validation ' + str(round(weightedrmse1VAL, 6))
        GlobalTrainingLoss = weightedrmse1TRAIN
        GlobalValidationLoss = weightedrmse1VAL

    print(wraptotext(
        RunName + ' DLPrediction3 ' + LabelFit + ' Weighted sum over predicted values ' + str(round(weightedrmse1, 7))
        + line + ' ' + RunComment))
    print('Count ignoring NaN ' + str(round(weightedcount, 4)) + ' Counting NaN ' + str(round(weightedovercount, 4)))

    ObsvPred = np.sum(np.abs(ObsVbytimeandclass - Predbytimeandclass), axis=0)
    TotalObs = np.sum(ObsVbytimeandclass, axis=0)
    SummedEbyclass = np.divide(ObsvPred, TotalObs)
    RMSEbyclass1 = RMSEbyclass  # NO Sqrt
    RMSEbyclass2 = np.sqrt(np.divide(RMSEbyclass[:, 0], RMSVbyclass))
    RelEbyclass = np.divide(AbsEbyclass, AbsVbyclass)
    extracomments = []
    for i in range(0, NpredperseqTOT):
        line = startbold + startred + ' Loss Coeffs '
        for timecut in range(0, 3):
            line += TimeCutLabel[timecut] + 'Full ' + str(round(RMSEbyclass1[i, timecut], 6)) + resetfonts
        if LocationBasedValidation:
            RTRAIN = RMSETRAINbyclass[i]
            RVAL = np.full(3, 0.0, dtype=np.float32)
            if ValidationNloc > 0:
                RVAL = RMSEVALbyclass[i]
            for timecut in range(0, 3):
                line += startbold + startpurple + TimeCutLabel[timecut] + 'TRAIN ' + resetfonts + str(
                    round(RTRAIN[timecut], 6))
                line += startbold + ' VAL ' + resetfonts + str(round(RVAL[timecut], 6))
        else:
            RTRAIN = RMSEbyclass1[i]
            RVAL = np.full(3, 0.0, dtype=np.float32)
            for timecut in range(0, 3):
                line += TimeCutLabel[timecut] + 'FULL ' + str(round(RTRAIN[timecut], 6))
        print(wraptotext(
            str(i) + ' ' + startbold + Predictionname[PredictionNameIndex[i]] + resetfonts + ' All Counts ' + str(
                round(countbyclass[i, 0], 0)) + ' '
            + str(round(100.0 * RMSEbyclass2[i], 4)) + ' ' + str(round(100.0 * RelEbyclass[i], 4)) + ' ' + str(
                round(100.0 * SummedEbyclass[i], 4)) + line))
        extracomments.append(['Loss Coeffs F=' + str(round(RTRAIN[0], 5)) + ' S=' + str(round(RTRAIN[1], 5)) + ' E=' + str(
            round(RTRAIN[2], 5)),
                              'Loss Coeffs F=' + str(round(RVAL[0], 5)) + ' S=' + str(round(RVAL[1], 5)) + ' E=' + str(
                                  round(RVAL[2], 5))])

    print('\nNext plots from DLPrediction3 ' + LabelFit)
    Location_summed_plot(0, yin, FitPredictions, extracomments=extracomments, Dumpplot=Dumpplot)

    return


"""## Science Transformer Control Code"""


class CustomScienceTransformermodel(tf.keras.Model):
    def __init__(self, **kwargs):
        super(CustomScienceTransformermodel, self).__init__(**kwargs)

        self.Scienceencoder = Encoder()
        self.Sciencemerge = EncodertoLSTMmerge()
        self.fullLSTM = MyLSTMlayer()  # Identical to that used in standalone LSTM although we change golobal parameters to remove input layers

    def call(self, inputs, training=None, Time=None):
        # Timemask has dimension [OuterBatchDimension, d_sample, d_sample] = 1 (implies ignore) if [b,i,j] has time of [b,i] < time [b,j]
        # So time is flattened to one domension and is typically sets of Tseq entries
        #  and entries are ending time of each entry
        # Time size is number of items in batch times Nloc_sample times Tseq
        # Only set if (MaskingOption > 0) and GlobalSpacetime:
        mask = None
        if GlobalSpacetime and (Time is not None):
            zero = tf.constant(0.0, dtype=tf.float32)
            one = tf.constant(1.0, dtype=tf.float32)

            if SpacewiseSecondAttention and (not TransformerOnlyFullAttention):  # Space mask
                Timematrix = tf.reshape(Time, [Time.shape[0], -1, Tseq])
                Spacematrix = Timematrix[:, :, 0]
                Spacematrix = tf.reshape(Spacematrix, [Spacematrix.shape[0], -1, 1])
                mask = tf.where((Spacematrix - tf.transpose(Spacematrix, perm=[0, 2, 1])) > 0, zero, one)
            else:  # Full time+space mask
                Timematrix = tf.reshape(Time, [Time.shape[0], -1, 1])
                mask = tf.where((Timematrix - tf.transpose(Timematrix, perm=[0, 2, 1])) > 0, zero, one)

        restoreinputs = inputs
        EncoderOutput, Mappedinput = self.Scienceencoder(restoreinputs, training=training, mask=mask)

        # Here we expose separate dimensions Nloc_sample and Tseq
        if UseMappedinput:
            Mappedinput = tf.reshape(Mappedinput, [1, Nloc_sample * Tseq, Mappedinput.shape[-1]])
            compositeinputs = self.Sciencemerge(Mappedinput, EncoderOutput, training=training)
        else:
            compositeinputs = self.Sciencemerge(restoreinputs, EncoderOutput, training=training)

        # -1 is compositeinputs.shape[0]*Nloc_sample
        bigbatch = tf.reshape(compositeinputs, [-1, Tseq, compositeinputs.shape[3]])
        outputs = self.fullLSTM(bigbatch, training=training)
        return outputs

    def compile(self, optimizer, loss):
        super(CustomScienceTransformermodel, self).compile()
        self.optimizer = tf.keras.optimizers.get(optimizer)
        self.loss_object = loss
        self.loss_tracker = tf.keras.metrics.Mean(name="loss")
        self.loss_tracker.reset_states()
        self.val_tracker = tf.keras.metrics.Mean(name="val")
        self.val_tracker.reset_states()
        return

    def resetmetrics(self):
        self.loss_tracker.reset_states()
        self.val_tracker.reset_states()
        return

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])

    @tf.function
    def train_step(self, data, Time=None):
        if len(data) == 3:
            X_train, y_train, sw_train = data
        else:
            X_train, y_train = data
            sw_train = []

        # Collapse first two dimensions -- same is done for LSTM input
        #  X_train: OuterBatchDimension = Num_Seq batched to 1, d_sample = [Nloc_sample,Tseq], #properties]
        sw_train = tf.reshape(sw_train, [-1, sw_train.shape[2]])
        y_train = tf.reshape(y_train, [-1, y_train.shape[2]])

        with tf.GradientTape() as tape:
            predictions = self(X_train, training=True, Time=Time)
            loss = self.loss_object(y_train, predictions, sw_train)

        variables = self.Scienceencoder.trainable_variables + self.Sciencemerge.trainable_variables + self.fullLSTM.trainable_variables
        gradients = tape.gradient(loss, variables)
        self.optimizer.apply_gradients(zip(gradients, variables))
        self.loss_tracker.update_state(loss)
        return {"loss": self.loss_tracker.result()}

    @tf.function
    def test_step(self, data, Time=None):
        if len(data) == 3:
            X_val, y_val, sw_val = data
        else:
            X_val, y_val = data
            sw_val = []

        # Collapse first two dimensions -- same is done for LSTM input
        sw_val = tf.reshape(sw_val, [-1, sw_val.shape[2]])
        y_val = tf.reshape(y_val, [-1, y_val.shape[2]])

        predictions = self(X_val, training=False, Time=Time)

        loss = self.loss_object(y_val, predictions, sw_val)
        self.val_tracker.update_state(loss)
        return {"val_loss": self.val_tracker.result()}


def RunScienceTransformer():
    # Run the Science Transformer model defined by Model and Encoder/LSTM classes
    # There are a lot  of reshapings. X_Transformerdetailed and y_Transformerdetailed are viewed as unchanged
    # Others are gennerated here for lifetime of this call
    # Note shuffling done for a) Choice of Validation set where ONLY start time shuffled
    # and b) for batching where both shuffling over time and location performed
    # X_Transformertrainingplusval = np.reshape(X_Transformerdetailed, (OuterBatchDimension, d_sample, NpropperseqTOT))
    # y_Transformertrainingplusval = np.reshape(y_Transformerdetailed, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
    # Nloc Number of locations
    # d_sample is  Nloc*Tseq in order [Nloc_sample=Nloc] [Tseq]
    # OuterBatchDimension is Num_Seq and is batching dimension which is also shuffling dimension
    # It changes if conventional validation used
    # Note Transformer batching dimension smaller and different from LSTM

    global UsedTransformervalidationfrac, Transformervalidationfrac, OuterBatchDimension, Nloc_sample, d_sample, max_d_sample
    global processindex
    OuterBatchDimension = Num_Seq

    extrainitializationstring = 'Basic System'
    if usecustomfit:
        extrainitializationstring = 'Custom Class'

    if LocationBasedValidation:
        UsedTransformervalidationfrac = LocationValidationFraction
        X_predict, y_predict, Spacetime_predict, X_val, y_val, Spacetime_val = setSeparateDLinput(1, Spacetime=True)
        y_predicttocount = np.reshape(y_Transformerdetailed, (-1, NpredperseqTOT))
        InitializeDLforTimeSeries(extrainitializationstring + ' Class custom  Version with location-based validation ',
                                  processindex, y_predicttocount)
        Nloc_sample = TrainingNloc
        OuterBatchDimension = Num_Seq
        d_sample = Tseq * TrainingNloc
        max_d_sample = d_sample

        Total_train = Num_Seq
        Total_val = 0
        UsedValidationNloc = ValidationNloc
        if UsedTransformervalidationfrac > 0.001:
            Total_val = Num_Seq
            if FullSetValidation:
                UsedValidationNloc = Nloc
        Total_all = Total_train + Total_val

        if SymbolicWindows:
            X_Transformertraining = np.reshape(X_predict, (OuterBatchDimension, Nloc_sample))
        else:
            X_Transformertraining = np.reshape(X_predict, (OuterBatchDimension, d_sample, NpropperseqTOT))
        y_Transformertraining = np.reshape(y_predict, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        Spacetime_Transformertraining = np.reshape(Spacetime_predict, (OuterBatchDimension, Nloc_sample))
        if UsedTransformervalidationfrac > 0.001:
            if SymbolicWindows:
                X_Transformerval = np.reshape(X_val, (OuterBatchDimension, UsedValidationNloc))
            else:
                X_Transformerval = np.reshape(X_val, (OuterBatchDimension, UsedValidationNloc * Tseq, NpropperseqTOT))
            y_Transformerval = np.reshape(y_val, (OuterBatchDimension, UsedValidationNloc, NpredperseqTOT))
            Spacetime_Transformerval = np.reshape(Spacetime_val, (OuterBatchDimension, UsedValidationNloc))

        if UseClassweights:
            sw_Transformertraining = np.empty_like(y_predict, dtype=np.float32)
            for i in range(0, sw_Transformertraining.shape[0]):
                for j in range(0, sw_Transformertraining.shape[1]):
                    for k in range(0, NpredperseqTOT):
                        sw_Transformertraining[i, j, k] = Predictionwgt[k]
            if UsedTransformervalidationfrac > 0.001:
                fudge = Nloc / ValidationNloc
                sw_Transformerval = np.empty_like(y_val, dtype=np.float32)
                for i in range(0, sw_Transformerval.shape[0]):
                    for jloc in range(0, sw_Transformerval.shape[1]):
                        for k in range(0, NpredperseqTOT):
                            if FullSetValidation:
                                if MappingtoValidation[jloc] >= 0:
                                    sw_Transformerval[i, jloc, k] = Predictionwgt[k] * fudge
                                else:
                                    sw_Transformerval[i, jloc, k] = 0.0
                            else:
                                sw_Transformerval[i, jloc, k] = Predictionwgt[k]
            else:
                sw_Transformerval = []
        else:
            sw_Transformertraining = []
            sw_Transformerval = []

    else:  # Traditional Validation or no validation -- first set up if no validation
        OuterBatchDimension = Num_Seq
        UsedTransformervalidationfrac = Transformervalidationfrac
        UsedValidationNloc = Nloc
        Nloc_sample = Nloc
        d_sample = Tseq * Nloc
        max_d_sample = d_sample
        if SymbolicWindows:
            X_Transformertrainingplusval = np.reshape(X_Transformerdetailed, (OuterBatchDimension, Nloc_sample))
        else:
            X_Transformertrainingplusval = np.reshape(X_Transformerdetailed,
                                                      (OuterBatchDimension, d_sample, NpropperseqTOT))
        Spacetime_Transformertrainingplusval = SpacetimeforMask.copy()
        Spacetime_Transformertrainingplusval = np.reshape(Spacetime_Transformertrainingplusval,
                                                          (OuterBatchDimension, Nloc_sample))
        y_Transformertrainingplusval = np.reshape(y_Transformerdetailed, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
        X_Transformertrainingplusval, y_Transformertrainingplusval, Spacetime_Transformertrainingplusval = (
            shuffleDLinput(X_Transformertrainingplusval, y_Transformertrainingplusval,
                           Spacetime=Spacetime_Transformertrainingplusval))  # Shuffle for validation
        Total_all = X_Transformertrainingplusval.shape[0]
        Total_val = 0

        # Decide on validation fraction based on batching dimension -- sequences
        if UsedTransformervalidationfrac > 0.001:
            Total_val = int(UsedTransformervalidationfrac * Total_all)
            print(RunName + " Validation samples ", Total_val, " Training samples ", Total_all - Total_val,
                  " from sequences")
            if Total_val == 0:
                UsedTransformervalidationfrac = 0.0
        Total_train = Total_all - Total_val

        # set up if no validation
        y_predict = np.reshape(y_Transformertrainingplusval, (OuterBatchDimension * Nloc_sample, NpredperseqTOT))
        InitializeDLforTimeSeries(startbold + RunComment + ' ' + RunName + ' ' + extrainitializationstring +
                                  ' Transformer  Version ' + resetfonts, processindex, y_predict)

        # Set Sample Weights for whole sample
        if UseClassweights:
            sw = np.empty_like(y_Transformertrainingplusval, dtype=np.float32)
            for i in range(0, sw.shape[0]):
                for j in range(0, sw.shape[1]):
                    for k in range(0, NpredperseqTOT):
                        sw[i, j, k] = Predictionwgt[k]

        if UsedTransformervalidationfrac > 0.001:
            X_Transformerval = X_Transformertrainingplusval[0:Total_val]
            y_Transformerval = y_Transformertrainingplusval[0:Total_val]
            X_Transformertraining = X_Transformertrainingplusval[Total_val:]
            y_Transformertraining = y_Transformertrainingplusval[Total_val:]
            Spacetime_Transformerval = Spacetime_Transformertrainingplusval[0:Total_val]
            Spacetime_Transformertraining = Spacetime_Transformertrainingplusval[Total_val:]
            if UseClassweights:
                sw_Transformerval = sw[0:Total_val]
                sw_Transformertraining = sw[Total_val:]
        else:
            X_Transformertraining = X_Transformertrainingplusval
            y_Transformertraining = y_Transformertrainingplusval
            sw_Transformertraining = sw
            Spacetime_Transformertraining = Spacetime_Transformertrainingplusval

    epochsize = Total_all
    if not (usecustomfit and UseClassweights):
        printexit('Unsupported default fit')

    if SymbolicWindows:
        X_Transformertrainingflat2 = np.reshape(X_Transformertraining, (-1, TrainingNloc))
        X_Transformertrainingflat1 = np.reshape(X_Transformertrainingflat2, (-1))
    else:
        X_Transformertrainingflat2 = np.reshape(X_Transformertraining, (-1, TrainingNloc, Tseq, NpropperseqTOT))
        X_Transformertrainingflat1 = np.reshape(X_Transformertrainingflat2, (-1, Tseq, NpropperseqTOT))
    y_Transformertrainingflat1 = np.reshape(y_Transformertraining, (-1, NpredperseqTOT))
    #    X_Transformertrainingflat1 = np.reshape(X_Transformertrainingflat2, (-1))
    Spacetime_Transformertrainingflat1 = np.reshape(Spacetime_Transformertraining, (-1))
    if UseClassweights:
        sw_Transformertrainingflat1 = np.reshape(sw_Transformertraining, (-1, NpredperseqTOT))

    if UsedTransformervalidationfrac > 0.001:
        if SymbolicWindows:
            X_Transformervalflat2 = np.reshape(X_Transformerval, (-1, UsedValidationNloc))
            X_Transformervalflat1 = np.reshape(X_Transformervalflat2, (-1))
        else:
            X_Transformervalflat2 = np.reshape(X_Transformerval, (-1, UsedValidationNloc, Tseq, NpropperseqTOT))
            X_Transformervalflat1 = np.reshape(X_Transformervalflat2, (-1, Tseq, NpropperseqTOT))
        y_Transformervalflat1 = np.reshape(y_Transformerval, (-1, NpredperseqTOT))
        Spacetime_Transformervalflat1 = np.reshape(Spacetime_Transformerval, (-1))
        if UseClassweights:
            sw_Transformervalflat1 = np.reshape(sw_Transformerval, (-1, NpredperseqTOT))

    # FINALLY SET UP MODEL
    myScienceTransformermodel = CustomScienceTransformermodel()

    myScienceTransformermodel.compile(loss=weightedcustom_lossGCF1, optimizer=Transformeroptimizer)
    recordtrainloss = []
    recordvalloss = []
    tfrecordtrainloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfrecordvalloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfepochstep = tf.Variable(0, trainable=False)

    myScienceTransformermodel.compile(loss=weightedcustom_lossGCF1, optimizer=Transformeroptimizer)
    Dictopt = myScienceTransformermodel.optimizer.get_config()
    print(startbold + startred + 'Optimizer ' + resetfonts, Dictopt)

    # Set up checkpoints to read or write
    mycheckpoint = tf.train.Checkpoint(optimizer=myScienceTransformermodel.optimizer,
                                       model=myScienceTransformermodel, tfepochstep=tf.Variable(0),
                                       tfrecordtrainloss=tfrecordtrainloss, tfrecordvalloss=tfrecordvalloss)

    if Restorefromcheckpoint:
        save_path = inputCHECKPOINTDIR + inputRunName + inputCheckpointpostfix
        mycheckpoint.restore(save_path=save_path).expect_partial()
        tfepochstep = mycheckpoint.tfepochstep
        recordvalloss = mycheckpoint.tfrecordvalloss.numpy().tolist()
        recordtrainloss = mycheckpoint.tfrecordtrainloss.numpy().tolist()
        trainlen = len(recordtrainloss)
        extrainfo = ''
        vallen = len(recordvalloss)
        SavedTrainLoss = recordtrainloss[trainlen - 1]
        SavedValLoss = 0.0
        if vallen > 0:
            extrainfo = ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
            SavedValLoss = recordvalloss[vallen - 1]
        print(startbold + 'Network restored from ' + save_path + '\nLoss ' + str(round(recordtrainloss[trainlen - 1], 7))
              + extrainfo + ' Epochs ' + str(tfepochstep.numpy()) + resetfonts)
        TransformerTFMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=True,
                                                Restored_path=save_path, ValidationFraction=UsedTransformervalidationfrac,
                                                SavedTrainLoss=SavedTrainLoss, SavedValLoss=SavedValLoss)
    else:
        TransformerTFMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=False,
                                                ValidationFraction=UsedTransformervalidationfrac)

    # This just does analysis
    if AnalysisOnly:
        finalanalysis(myScienceTransformermodel, recordtrainloss, recordvalloss, RunComment, True)
        return myScienceTransformermodel

    # Initialize progress bars
    pbar = notebook.trange(Transformerepochs, desc='Training loop', unit='epoch')
    if IncreaseNloc_sample > 1:
        epochsize = int(epochsize / IncreaseNloc_sample)
    elif DecreaseNloc_sample > 1:
        epochsize = int(epochsize * DecreaseNloc_sample)

    bbar = notebook.trange(epochsize, desc='Batch    loop', unit='sample')

    Ctime1 = 0.0
    Ctime2 = 0.0
    Ctime3 = 0.0
    GarbageCollect = True
    garbagecollectcall = 0

    for e in pbar:
        myScienceTransformermodel.resetmetrics()
        train_lossoverbatch = []
        val_lossoverbatch = []

        if LocationBasedValidation:
            Nloc_sample = TrainingNloc
            OuterBatchDimension = Num_Seq
            d_sample = Tseq * TrainingNloc
        else:
            Nloc_sample = Nloc
            OuterBatchDimension = Total_train
            d_sample = Tseq * Nloc
        max_d_sample = d_sample

        if TimeShufflingOnly:
            X_train, y_train, sw_train, Spacetime_train = shuffleDLinput(X_Transformertraining,
                                                                         y_Transformertraining, sw_Transformertraining,
                                                                         Spacetime=Spacetime_Transformertraining)
        else:
            X_train, y_train, sw_train, Spacetime_train = shuffleDLinput(X_Transformertrainingflat1,
                                                                         y_Transformertrainingflat1,
                                                                         sw_Transformertrainingflat1,
                                                                         Spacetime=Spacetime_Transformertrainingflat1)

            if LocationBasedValidation:
                Nloc_sample = TrainingNloc
                OuterBatchDimension = Num_Seq
            else:
                Nloc_sample = Nloc
                OuterBatchDimension = Total_train
            Totaltodo = Nloc_sample * OuterBatchDimension
            if IncreaseNloc_sample > 1:
                Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
            elif DecreaseNloc_sample > 1:
                Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)
            OuterBatchDimension = int(Totaltodo / Nloc_sample)
            if OuterBatchDimension * Nloc_sample != Totaltodo:
                printexit('Inconsistent Nloc_sample ' + str(Nloc_sample))
            d_sample = Tseq * Nloc_sample
            max_d_sample = d_sample

            if SymbolicWindows:
                X_train = np.reshape(X_train, (OuterBatchDimension, Nloc_sample))
            else:
                X_train = np.reshape(X_train, (OuterBatchDimension, d_sample, NpropperseqTOT))
            y_train = np.reshape(y_train, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
            sw_train = np.reshape(sw_train, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
            Spacetime_train = np.reshape(Spacetime_train, (OuterBatchDimension, Nloc_sample))

        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, sw_train, Spacetime_train))
        train_dataset = train_dataset.batch(Transformerbatch_size)

        if batchperepoch:
            qbar = notebook.trange(epochsize, desc='Batch loop epoch ' + str(e))

        # Start Training Batch Loop
        for batch, (X_train, y_train, sw_train, Spacetime_train) in enumerate(train_dataset.take(-1)):
            Numinbatch = X_train.shape[0]
            NuminAttention = X_train.shape[1]
            NumTOTAL = Numinbatch * NuminAttention
            Time = None

            # SymbolicWindows X_train is indexed by Batch index, Location List for Attention. Missing 1(replace by Window), 1 (replace by properties)
            if SymbolicWindows:
                StopWatch.start('label1')
                X_train = X_train.numpy()
                X_train = np.reshape(X_train, NumTOTAL)
                iseqarray = np.right_shift(X_train, 16)
                ilocarray = np.bitwise_and(X_train, 0b1111111111111111)
                StopWatch.stop('label1')
                Ctime1 += StopWatch.get('label1', digits=4)
                StopWatch.start('label3')
                X_train_withSeq = list()
                for iloc in range(0, NumTOTAL):
                    X_train_withSeq.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                #         X_train_withSeq=[ReshapedSequencesTOT[ilocarray[iloc],iseqarray[iloc]:iseqarray[iloc]+Tseq] for iloc in range(0,Numinbatch)]
                X_train_withSeq = np.array(X_train_withSeq)
                X_train_withSeq = np.reshape(X_train_withSeq, (Numinbatch, d_sample, NpropperseqTOT))
                #
                # Calculate Time so we can set FutureMask [i 0:NumTOTAL.t in 0:Tseq, j 0:NumTOTAL u in 0:Tseq]= 1 if Time[j] > Time[i]
                # which Implies this case is vetoed
                Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                StopWatch.stop('label3')
                Ctime3 += StopWatch.get('label3', digits=5)

                StopWatch.start('label2')
                loss = myScienceTransformermodel.train_step((X_train_withSeq, y_train, sw_train), Time=Time)
                StopWatch.stop('label2')
                Ctime2 += StopWatch.get('label2', digits=4)

            else:
                iseqarray = np.right_shift(Spacetime_train, 16)
                Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                loss = myScienceTransformermodel.train_step((X_train, y_train, sw_train), Time=Time)

            if GarbageCollect:
                if SymbolicWindows:
                    X_train_withSeq = None
                X_train = None
                y_train = None
                sw_train = None
                Spacetime_train = None

                if garbagecollectcall > GarbageCollectionLimit:
                    garbagecollectcall = 0
                    gc.collect()
                garbagecollectcall += 1

            localloss = loss["loss"].numpy()
            train_lossoverbatch.append(localloss)

            if batchperepoch:
                qbar.update(Transformerbatch_size)
                qbar.set_postfix(Loss=localloss, Epoch=e)
            bbar.update(Transformerbatch_size)
            bbar.set_postfix(Loss=localloss, Epoch=e)

        # Training Batch Loop has ended
        if GarbageCollect:
            train_dataset = None

        # Start Validation Loop over batches
        if UsedTransformervalidationfrac > 0.001:
            Time = None
            OuterBatchDimension = Total_val
            if LocationBasedValidation:
                Nloc_sample = UsedValidationNloc
                OuterBatchDimension = Num_Seq
            else:
                Nloc_sample = Nloc

            Totaltodo = Nloc_sample * OuterBatchDimension
            if IncreaseNloc_sample > 1:
                Nloc_sample = int(Nloc_sample * IncreaseNloc_sample)
            elif DecreaseNloc_sample > 1:
                Nloc_sample = int(Nloc_sample / DecreaseNloc_sample)
            OuterBatchDimension = int(Totaltodo / Nloc_sample)
            if OuterBatchDimension * Nloc_sample != Totaltodo:
                printexit('Inconsistent Nloc_sample ' + str(Nloc_sample))
            d_sample = Tseq * Nloc_sample
            max_d_sample = d_sample

            if TimeShufflingOnly:
                X_val, y_val, sw_val, Spacetime_val = shuffleDLinput(
                    X_Transformerval, y_Transformerval, sw_Transformerval, Spacetime_Transformerval)
            else:
                X_val, y_val, sw_val, Spacetime_val = shuffleDLinput(
                    X_Transformervalflat1, y_Transformervalflat1, sw_Transformervalflat1, Spacetime_Transformervalflat1)
                if SymbolicWindows:
                    X_val = np.reshape(X_val, (OuterBatchDimension, Nloc_sample))
                else:
                    X_val = np.reshape(X_val, (OuterBatchDimension, d_sample, NpropperseqTOT))
            y_val = np.reshape(y_val, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
            sw_val = np.reshape(sw_val, (OuterBatchDimension, Nloc_sample, NpredperseqTOT))
            Spacetime_val = np.reshape(Spacetime_val, (OuterBatchDimension, Nloc_sample))

            for Validationindex in range(0, OuterBatchDimension):
                X_valbatch = X_val[Validationindex]
                y_valbatch = y_val[Validationindex]
                sw_valbatch = sw_val[Validationindex]
                Spacetime_valbatch = Spacetime_val[Validationindex]
                if SymbolicWindows:
                    X_valbatch = np.reshape(X_valbatch, [1, X_valbatch.shape[0]])
                else:
                    X_valbatch = np.reshape(X_valbatch, [1, X_valbatch.shape[0], X_valbatch.shape[1]])
                y_valbatch = np.reshape(y_valbatch, [1, y_valbatch.shape[0], y_valbatch.shape[1]])
                sw_valbatch = np.reshape(sw_valbatch, [1, sw_valbatch.shape[0], sw_valbatch.shape[1]])
                Numinbatch = X_valbatch.shape[0]
                NuminAttention = X_valbatch.shape[1]
                NumTOTAL = Numinbatch * NuminAttention

                if SymbolicWindows:
                    StopWatch.start('label1')
                    X_valbatch = np.reshape(X_valbatch, NumTOTAL)
                    iseqarray = np.right_shift(X_valbatch, 16)
                    ilocarray = np.bitwise_and(X_valbatch, 0b1111111111111111)
                    StopWatch.stop('label1')
                    Ctime1 += StopWatch.get('label1', digits=4)
                    StopWatch.start('label3')
                    X_valbatch_withSeq = list()
                    for iloc in range(0, NumTOTAL):
                        X_valbatch_withSeq.append(
                            ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                    X_valbatch_withSeq = np.array(X_valbatch_withSeq)
                    X_valbatch_withSeq = np.reshape(X_valbatch_withSeq, (Numinbatch, d_sample, NpropperseqTOT))
                    Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                    StopWatch.stop('label3')
                    Ctime3 += StopWatch.get('label3', digits=5)
                    StopWatch.start('label2')
                    loss = myScienceTransformermodel.test_step((X_valbatch_withSeq, y_valbatch, sw_valbatch), Time=Time)
                    StopWatch.stop('label2')
                    Ctime2 += StopWatch.get('label2', digits=4)

                else:
                    Spacetime_valbatch = np.reshape(Spacetime_valbatch, -1)
                    iseqarray = np.right_shift(Spacetime_valbatch, 16)
                    Time = SetSpacetime(np.reshape(iseqarray, [Numinbatch, -1]))
                    loss = myScienceTransformermodel.test_step((X_valbatch, y_valbatch, sw_valbatch), Time=Time)
                localval = loss["val_loss"].numpy()
                val_lossoverbatch.append(localval)

                bbar.update(Transformerbatch_size)
                bbar.set_postfix(Loss=localloss, Val_loss=localval, Epoch=e)

            if GarbageCollect:
                X_val = None
                y_val = None
                sw_val = None
                X_valbatch = None
                y_valbatch = None
                sw_valbatch = None
                if SymbolicWindows:
                    X_valbatch_withSeq = None
                if garbagecollectcall > GarbageCollectionLimit:
                    garbagecollectcall = 0
                    gc.collect()
                garbagecollectcall += 1

        train_epoch = train_lossoverbatch[-1]
        recordtrainloss.append(train_epoch)
        mycheckpoint.tfrecordtrainloss = tf.Variable(recordtrainloss)

        val_epoch = 0.0
        if UsedTransformervalidationfrac > 0.001:
            val_epoch = val_lossoverbatch[-1]
            recordvalloss.append(val_epoch)
            mycheckpoint.tfrecordvalloss = tf.Variable(recordvalloss)

        # End Epoch Processing
        pbar.set_postfix(Loss=train_epoch, Val=val_epoch)
        bbar.reset()
        tfepochstep = tfepochstep + 1
        mycheckpoint.tfepochstep.assign(tfepochstep)

        # Decide on best fit
        MonitorResult, train_epoch, val_epoch = TransformerTFMonitor.EpochEvaluate(e, train_epoch, val_epoch, tfepochstep,
                                                                                   recordtrainloss, recordvalloss)
        if MonitorResult == 1:
            tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = TransformerTFMonitor.RestoreBestFit()  # Restore Best Fit
        else:
            continue
    # *********************** End of Epoch Loop for custom training

    # Print Fit details
    print(startbold + 'Times ' + str(round(Ctime1, 5)) + ' ' + str(round(Ctime3, 5)) + ' TF ' + str(
        round(Ctime2, 5)) + resetfonts)
    TransformerTFMonitor.PrintEndofFit(Transformerepochs)

    # Set Best Possible Fit
    tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = TransformerTFMonitor.BestPossibleFit()

    # Save Final State
    if Checkpointfinalstate:
        savepath = mycheckpoint.save(file_prefix=CHECKPOINTDIR + RunName)
        print('Checkpoint at ' + savepath + ' from ' + CHECKPOINTDIR)
    trainlen = len(recordtrainloss)
    extrainfo = ''
    if UsedTransformervalidationfrac > 0.001:
        vallen = len(recordvalloss)
        extrainfo = ' Val Epoch ' + str(vallen - 1) + ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
    print('Train Epoch ' + str(trainlen - 1) + ' Train Loss ' + str(round(recordtrainloss[trainlen - 1], 7)) + extrainfo)

    SummarizeFullModel(myScienceTransformermodel)

    finalanalysis(myScienceTransformermodel, recordtrainloss, recordvalloss, RunComment, False)
    return myScienceTransformermodel


def finalanalysis(myScienceTransformermodel, recordtrainloss, recordvalloss, LabelFit, summary):
    global UsedTransformervalidationfrac, Transformervalidationfrac, OuterBatchDimension, Nloc_sample, d_sample, max_d_sample
    Nloc_sample = Nloc
    OuterBatchDimension = Num_Seq
    d_sample = Tseq * Nloc
    max_d_sample = d_sample

    if SymbolicWindows:
        finalizeDL(myScienceTransformermodel, recordtrainloss, recordvalloss, UsedTransformervalidationfrac,
                   ReshapedSequencesTOT, RawInputPredictionsTOT, 1, LabelFit=LabelFit)
    else:
        finalizeDL(myScienceTransformermodel, recordtrainloss, recordvalloss, UsedTransformervalidationfrac,
                   RawInputSequencesTOT, RawInputPredictionsTOT, 1, LabelFit=LabelFit)
    if summary:
        SummarizeFullModel(myScienceTransformermodel)
    if SymbolicWindows:
        DLprediction2D(ReshapedSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)
        DLprediction2B(ReshapedSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)
        if (not Hydrology):
            DLprediction2(ReshapedSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)
    else:
        DLprediction2D(RawInputSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)
        DLprediction2B(RawInputSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)
        if (not Hydrology):
            DLprediction2(RawInputSequencesTOT, RawInputPredictionsTOT, myScienceTransformermodel)


def SummarizeFullModel(DLmodel):
    current_time = timenow()
    print(startbold + startpurple + '\n' + current_time + ' Model Weight Summary' + resetfonts)
    DLmodel.Scienceencoder.summary()
    DLmodel.Sciencemerge.summary()
    DLmodel.fullLSTM.summary()
    DLmodel.summary()
    for ilayer in range(0, num_Encoderlayers):
        print(startbold + startpurple + 'Encoder Layer ' + str(ilayer) + resetfonts)
        DLmodel.Scienceencoder.enc_layers[ilayer].summarize()
    OutputDNNpics(DLmodel)
    return


def OutputDNNpics(DLmodel):
    if not OutputNetworkPictures:
        return
    outputpicture1 = APPLDIR + '/Outputs/Model_' + RunName + '1.png'
    outputpicture2 = APPLDIR + '/Outputs/Model_' + RunName + '2.png'
    outputpicture3 = APPLDIR + '/Outputs/Model_' + RunName + '3.png'
    outputpicture4 = APPLDIR + '/Outputs/Model_' + RunName + '4.png'
    global GlobalSpacetime
    save = GlobalSpacetime
    GlobalSpacetime = False
    Nloc_sample = TrainingNloc
    d_sample = Tseq * TrainingNloc
    tf.keras.utils.plot_model(DLmodel.build_graph([d_sample, NpropperseqTOT]),
                              show_shapes=True, to_file=outputpicture1,
                              show_dtype=True,
                              expand_nested=True)
    tf.keras.utils.plot_model(DLmodel.fullLSTM.build_graph([Tseq, NpropperseqTOT]),
                              show_shapes=True, to_file=outputpicture2,
                              show_dtype=True,
                              expand_nested=True)
    tf.keras.utils.plot_model(DLmodel.Scienceencoder.build_graph([Tseq, NpropperseqTOT]),
                              show_shapes=True, to_file=outputpicture3,
                              show_dtype=True,
                              expand_nested=True)
    tf.keras.utils.plot_model(DLmodel.Sciencemerge.build_graph([Tseq, NpropperseqTOT]),
                              show_shapes=True, to_file=outputpicture4, \
                              show_dtype=True,
                              expand_nested=True)
    GlobalSpacetime = save
    return


"""## Set Transformer Launching Parameters"""

# Finally we can run the Science Transformer
if UseScienceTransformerModel:
    AnalysisOnly = True
    Restorefromcheckpoint = False
    Checkpointfinalstate = True
    if AnalysisOnly:
        Restorefromcheckpoint = True
        Checkpointfinalstate = False
    if Restorefromcheckpoint:
        inputRunName = RunName
        #  inputRunName =  'EARTHQC-Transformer11V'
        #  inputCheckpointpostfix = 'MinLoss-110'
        inputCheckpointpostfix = '-62'
        inputCHECKPOINTDIR = APPLDIR + "/checkpoints/" + inputRunName + "dir/"

    tf.keras.backend.set_floatx('float32')

    SkipDL2B = False
    SkipDL2 = False
    SkipDL2D = False
    SkipDL2E = False
    SkipDL2F = True
    Dumpoutkeyplotsaspics = False

    SampleSize = 5
    Transformerepochs = 100
    PredictionTraining = False

    batchperepoch = False  # if True output a batch bar for each epoch

    # Control Training
    usecustomfit = True
    if AnalysisOnly:
        Restorefromcheckpoint = True
        Checkpointfinalstate = False

    # Repeat key parameters
    FullSetValidation = False
    TimeShufflingOnly = False
    TransformerOnlyFullAttention = False
    SpacewiseSecondAttention = True
    SeparateHeads = True
    MaskingOption = 1
    IncreaseNloc_sample = 1
    DecreaseNloc_sample = 1
    # These are used in fits and DLPrediction2B (calling DLPrediction3) and DLPrediction2D

    if MaskingOption == 0:
        GlobalSpacetime = False
    else:
        GlobalSpacetime = True

    ChopupMatrix = False
    ChopupNumber = 1
    ActivateAttention = False

    # Values from DGX change sepaarateheads
    # Repeat key parameters
    FullSetValidation = False
    TimeShufflingOnly = False
    TransformerOnlyFullAttention = False
    SpacewiseSecondAttention = False
    SeparateHeads = True  # CHANGED
    MaskingOption = 1
    IncreaseNloc_sample = 1
    DecreaseNloc_sample = 1
    # These are used in fits and DLPrediction2B (calling DLPrediction3) and DLPrediction2D

    if MaskingOption == 0:
        GlobalSpacetime = False
    else:
        GlobalSpacetime = True

    ChopupMatrix = False
    ChopupNumber = 1
    ActivateAttention = False

    num_heads = 4
    oldencoderversion = True
    ReuseInputinEncoder = True
    UseMappedinput = True
    Takevasinput = True
    d_model = 128
    d_Attention = 2 * d_model
    if TransformerOnlyFullAttention:
        d_Attention = d_model
    DoubleQKV = False
    d_qk = d_model
    d_intermediateqk = 2 * d_model
    d_intermediatev = 2 * d_model
    d_v = d_model
    if DoubleQKV:
        d_Attention = 2 * d_Attention
        d_qk = 2 * d_model
    depth = d_qk // num_heads
    if not Takevasinput:
        d_v = depth

    num_Encoderlayers = 4
    EncoderActivation = "selu"
    d_EncoderLayer = d_Attention
    d_ffn = 4 * d_model
    d_merge = 2 * d_model
    d_merge = d_model

    LSTMSkipInitial = True
    number_LSTMnodes = 64
    LSTMFinalMLP = 128
    LSTMInitialMLP = 128
    LSTMThirdLayer = False

    dropvalue = 0.2
    LSTMdropout1 = dropvalue
    LSTMrecurrent_dropout1 = dropvalue
    LSTMdropout2 = dropvalue
    LSTMrecurrent_dropout2 = dropvalue
    EncoderDropout = dropvalue
    processindex = 0
    UsedTransformervalidationfrac = 0.0
    Transformerbatch_size = 1

    TransformerTFMonitor = TensorFlowTrainingMonitor()
    if Hydrology:
        TransformerTFMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
    if Earthquake:
        TransformerTFMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
    if ReadJan2021Covid:
        TransformerTFMonitor.SetControlParms(SuccessLimit=5, FailureLimit=2)
    if ReadApril2021Covid:
        TransformerTFMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
    Mymodel = RunScienceTransformer()

# Output parameters used   this Science Transformer
if UseScienceTransformerModel:
    current_time = timenow()
    print(startbold + startred + current_time + ' ' + RunComment + ' ' + RunName + resetfonts)
    print("TimeShufflingOnly: if False shuffle over space and Time each batch; True just shuffle over time ",
          str(TimeShufflingOnly))
    print("Batch size of stochastic gradient descent Transformerbatch_size ", str(Transformerbatch_size))
    if not LocationBasedValidation:
        print(startbold + startred + "Fraction used for a validation dataset ", str(Transformervalidationfrac),
              " No location based Validation" + resetfonts)
    print('FullSetValidation ' + str(FullSetValidation))
    print(
        'Sample size IncreaseNloc_sample ' + str(IncreaseNloc_sample) + ' DecreaseNloc_sample ' + str(DecreaseNloc_sample))
    print("Dimension of value embedding for every input [Model1] d_model ", str(d_model))
    print("Dimension of value embedding for input to Decoder (LSTM) d_merge ", str(d_merge))
    print("Number of Attention Heads which must exactly divide d_model, num_heads ", str(num_heads))
    print("Number of layers in Encoder stage num_Encoderlayers ", str(num_Encoderlayers))
    print("Dropout in Encoder stage, EncoderDropout ", str(EncoderDropout))
    print("Size of Encoder stage, d_EncoderLayer ", str(d_EncoderLayer))
    print("Activation in Encoder Stage EncoderActivation ", str(EncoderActivation))
    print("Size of feedforward network in each encoder layer. It appears to be 4 * d_model, d_ffn ", str(d_ffn))
    print('d_Attention ' + str(d_Attention) + ' typically 2*d_model unless only one attention')
    print('Size of Q K V d_qk ' + str(d_qk))
    print('Double d_qk and d_attention ' + str(DoubleQKV))
    print('d_intermediateqk ' + str(d_intermediateqk) + ' Typically 2 * d_model ')
    print(startbold + startred + "Defines masking used; = 0 none; =1 mask the future MaskingOption ",
          str(MaskingOption) + resetfonts)
    print(startbold + 'Nature of Attention ' + resetfonts)
    print(' Are heads done sequentially SeparateHeads ' + str(SeparateHeads))
    print(' TransformerOnlyFullAttention ' + str(TransformerOnlyFullAttention))
    print(' SpacewiseSecondAttention First attention is Time in sequence Second is Space or Full ' + str(
        SpacewiseSecondAttention))
    print(' ChopupMatrix ' + str(ChopupMatrix) + ' ChopupNumber ' + str(ChopupNumber))
    print(' ActivateAttention ' + str(ActivateAttention))
    print(' ReuseInputinEncoder ' + str(ReuseInputinEncoder))
    print('\n')
    print(startbold + startred + current_time + ' ' + RunComment + ' ' + RunName + resetfonts)
    PrintLSTMandBasicStuff()

"""# TFT Model

##Set up TFT
"""

if not UseTFTModel:
    printexit('TFT Follows so Stopping')

"""###Data and Input Types"""

# Type defintions
import enum


class DataTypes(enum.IntEnum):
    """Defines numerical types of each column."""
    REAL_VALUED = 0
    CATEGORICAL = 1
    DATE = 2
    NULL = -1
    STRING = 3
    BOOL = 4


class InputTypes(enum.IntEnum):
    """Defines input types of each column."""
    TARGET = 0  # Known before and after t for training
    OBSERVED_INPUT = 1  # Known upto time t
    KNOWN_INPUT = 2  # Known at all times
    STATIC_INPUT = 3  # By definition known at all times
    ID = 4  # Single column used as an entity identifier
    TIME = 5  # Single column exclusively used as a time index
    NULL = -1


def checkdfNaN(label, AttributeSpec, y):
    countNaN = 0
    countnotNaN = 0
    if y is None:
        return
    names = y.columns.tolist()
    count = np.zeros(y.shape[1])
    for j in range(0, y.shape[1]):
        colname = names[j]
        if AttributeSpec.loc[colname, 'DataTypes'] != DataTypes.REAL_VALUED:
            continue
        for i in range(0, y.shape[0]):
            if (np.math.isnan(y.iloc[i, j])):
                countNaN += 1
                count[j] += 1
            else:
                countnotNaN += 1

    percent = (100.0 * countNaN) / (countNaN + countnotNaN)
    print(label + ' is NaN ', str(countNaN), ' percent ', str(round(percent, 2)), ' not NaN ', str(countnotNaN))
    for j in range(0, y.shape[1]):
        if count[j] == 0:
            continue
        print(names[j] + ' has NaN ' + str(count[j]))


excludeNULLtype = True
TFTexcludedinputtypes = {InputTypes.ID, InputTypes.TIME}
if excludeNULLtype:
    TFTexcludedinputtypes = {InputTypes.ID, InputTypes.TIME, InputTypes.NULL}

"""###Convert FFFFWNPF to TFT"""

import pandas as pd

if UseTFTModel:
    # Pick Values setting InputType
    # Currently ONLY pick from properties BUT
    # If PropPick = 0 (target) then these should be selected as predictions in FFFFWNPF and futured of length LengthFutures

    # Set Prediction Property mappings and calculations

    # PredictionTFTAction -2 a Future -1 Ignore 0 Futured Basic Prediction, 1 Nonfutured Simple Sum, 2 Nonfutured Energy Averaged Earthquake
    # CalculatedPredmaptoRaw is Raw Prediction on which Calculated Prediction based
    # PredictionCalcLength is >1 if Action=1,2 and says action based on this number of consequitive predictions
    # PredictionTFTnamemapping if a non trivial string it is that returned by TFT in output map; if ' ' it isd a special extra prediction

    PredictionTFTnamemapping = np.full(NpredperseqTOT, ' ', dtype=object)
    PredictionTFTAction = np.full(NpredperseqTOT, -1, dtype=np.int32)
    for ipred in range(0, NpredperseqTOT):
        if ipred >= NumpredbasicperTime:
            PredictionTFTAction[ipred] = -2
        elif FuturedPointer[ipred] >= 0:
            PredictionTFTAction[ipred] = 0
            # Default is -1

    CalculatedPredmaptoRaw = np.full(NpredperseqTOT, -1, dtype=np.int32)
    PredictionCalcLength = np.full(NpredperseqTOT, 1, dtype=np.int32)

    # TFT Pick flags
    # 0 Target and observed input
    # 1 Observed Input NOT predicted
    # 2 Known Input
    # 3 Static Observed Input
    #
    # Data Types 0 Float or Integer converted to Float

    if ReadApril2021Covid:
        if ReadNov2021Covid:
            PropPick = [0, 0, 3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2]
        else:
            PropPick = [0, 0, 3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2]
        PropDataType = [0] * NpropperseqTOT
    if Earthquake:  # Assuming Special non futured 6 months forward prediction defined but NOT directly predicted by TFT
        PropPick = [3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
        PropDataType = [0] * NpropperseqTOT

    # Dataframe is overall label (real starting at 0), Location Name, Time Input Properties, Predicted Properties Nloc times Num_Time values
    # Row major order in Location-Time Space
    Totalsize = (Num_Time + TFTExtraTimes) * Nloc
    RawLabel = np.arange(0, Totalsize, dtype=np.float32)
    LocationLabel = []
    FFFFWNPFUniqueLabel = []
    RawTime = np.empty([Nloc, Num_Time + TFTExtraTimes], dtype=np.float32)
    RawTrain = np.full([Nloc, Num_Time + TFTExtraTimes], True, dtype=bool)
    RawVal = np.full([Nloc, Num_Time + TFTExtraTimes], True, dtype=bool)
    #  print('Times ' + str(Num_Time) + ' ' + str(TFTExtraTimes))
    ierror = 0
    for ilocation in range(0, Nloc):
        #   locname = Locationstate[LookupLocations[ilocation]] + ' ' + Locationname[LookupLocations[ilocation]]
        locname = Locationname[LookupLocations[ilocation]] + ' ' + Locationstate[LookupLocations[ilocation]]
        if locname == "":
            printexit('Illegal null location name ' + str(ilocation))
        for idupe in range(0, len(FFFFWNPFUniqueLabel)):
            if locname == FFFFWNPFUniqueLabel[idupe]:
                print(' Duplicate location name ' + str(ilocation) + ' ' + str(idupe) + ' ' + locname)
                ierror += 1
        FFFFWNPFUniqueLabel.append(locname)
        #    print(str(ilocation) + ' ' +locname)
        for jtime in range(0, Num_Time + TFTExtraTimes):
            RawTime[ilocation, jtime] = np.float32(jtime)
            LocationLabel.append(locname)
            if LocationBasedValidation:
                if MappingtoTraining[ilocation] >= 0:
                    RawTrain[ilocation, jtime] = True
                else:
                    RawTrain[ilocation, jtime] = False
                if MappingtoValidation[ilocation] >= 0:
                    RawVal[ilocation, jtime] = True
                else:
                    RawVal[ilocation, jtime] = False

    if ierror > 0:
        printexit(" Duplicate Names " + str(ierror))

    RawTime = np.reshape(RawTime, -1)
    RawTrain = np.reshape(RawTrain, -1)
    RawVal = np.reshape(RawVal, -1)
    TFTdf1 = pd.DataFrame(RawLabel, columns=['RawLabel'])
    if LocationBasedValidation:
        TFTdf2 = pd.DataFrame(RawTrain, columns=['TrainingSet'])
        TFTdf3 = pd.DataFrame(RawVal, columns=['ValidationSet'])
        TFTdf4 = pd.DataFrame(LocationLabel, columns=['Location'])
        TFTdf5 = pd.DataFrame(RawTime, columns=['Time from Start'])
        TFTdfTotal = pd.concat([TFTdf1, TFTdf2, TFTdf3, TFTdf4, TFTdf5], axis=1)
    else:
        TFTdf2 = pd.DataFrame(LocationLabel, columns=['Location'])
        TFTdf3 = pd.DataFrame(RawTime, columns=['Time from Start'])
        TFTdfTotal = pd.concat([TFTdf1, TFTdf2, TFTdf3], axis=1)
    TFTdfTotalSpec = pd.DataFrame([['RawLabel', DataTypes.REAL_VALUED, InputTypes.NULL]],
                                  columns=['AttributeName', 'DataTypes', 'InputTypes'])
    if LocationBasedValidation:
        TFTdfTotalSpec.loc[len(TFTdfTotalSpec.index)] = ['TrainingSet', DataTypes.BOOL, InputTypes.NULL]
        TFTdfTotalSpec.loc[len(TFTdfTotalSpec.index)] = ['ValidationSet', DataTypes.BOOL, InputTypes.NULL]
    TFTdfTotalSpec.loc[len(TFTdfTotalSpec.index)] = ['Location', DataTypes.STRING, InputTypes.ID]
    TFTdfTotalSpec.loc[len(TFTdfTotalSpec.index)] = ['Time from Start', DataTypes.REAL_VALUED, InputTypes.TIME]

    ColumnsProp = []
    for iprop in range(0, NpropperseqTOT):
        line = str(iprop) + ' ' + InputPropertyNames[PropertyNameIndex[iprop]]
        jprop = PropertyAverageValuesPointer[iprop]
        if QuantityTakeroot[jprop] > 1:
            line += ' Root ' + str(QuantityTakeroot[jprop])
        ColumnsProp.append(line)

    QuantityStatisticsNames = ['Min', 'Max', 'Norm', 'Mean', 'Std', 'Normed Mean', 'Normed Std']
    TFTInputSequences = np.reshape(ReshapedSequencesTOT, (-1, NpropperseqTOT))
    TFTPropertyChoice = np.full(NpropperseqTOT, -1, dtype=np.int32)
    TFTNumberTargets = 0
    for iprop in range(0, NpropperseqTOT):
        if PropPick[iprop] >= 0:
            if PropPick[iprop] == 0:
                TFTNumberTargets += 1
            nextcol = TFTInputSequences[:, iprop]
            dftemp = pd.DataFrame(nextcol, columns=[ColumnsProp[iprop]])
            TFTdfTotal = pd.concat([TFTdfTotal, dftemp], axis=1)
            jprop = TFTdfTotal.columns.get_loc(ColumnsProp[iprop])
            print('Property column ' + str(jprop) + ' ' + ColumnsProp[iprop])
            TFTPropertyChoice[iprop] = jprop
            TFTdfTotalSpec.loc[len(TFTdfTotalSpec.index)] = [ColumnsProp[iprop], PropDataType[iprop], PropPick[iprop]]
    FFFFWNPFNumberTargets = TFTNumberTargets

    ReshapedPredictionsTOT = np.transpose(RawInputPredictionsTOT, (1, 0, 2))

    TFTdfTotalSpec = TFTdfTotalSpec.set_index('AttributeName', drop=False)
    TFTdfTotalshape = TFTdfTotal.shape
    TFTdfTotalcols = TFTdfTotal.columns
    print('TFTdfTotalSpec.shape ' + str(TFTdfTotalSpec.shape))
    print('TFTdfTotal.shape ' + str(TFTdfTotalshape))
    print('TFTdfTotal.columns ' + str(TFTdfTotalcols))
    print('TFTdfTotalSpec.shape ' + str(TFTdfTotalSpec.shape))
    print('TFTdfTotalSpec.columns ' + str(TFTdfTotalSpec.columns))
    pd.set_option('display.max_rows', 100)
    print('Display TFTdfTotalSpec')
    display(TFTdfTotalSpec)

    print('Prediction mapping')

    ifuture = 0
    itarget = 0
    for ipred in range(0, NpredperseqTOT):
        predstatus = PredictionTFTAction[ipred]
        if (predstatus == -1) or (predstatus > 0):
            PredictionTFTnamemapping[ipred] = ' '
            text = 'NOT PREDICTED DIRECTLY'
        elif (predstatus == -2) or (predstatus == 0):
            text = 't+{}-Obs{}'.format(ifuture, itarget)
            PredictionTFTnamemapping[ipred] = text
            itarget += 1
            if itarget >= TFTNumberTargets:
                itarget = 0
                ifuture += 1
        fp = -2
        if ipred < NumpredbasicperTime:
            fp = FuturedPointer[ipred]
        line = startbold + startpurple + str(ipred) + ' ' + Predictionname[
            PredictionNameIndex[ipred]] + ' ' + text + resetfonts + ' Futured ' + str(fp) + ' '
        line += 'Action ' + str(predstatus) + ' Property ' + str(CalculatedPredmaptoRaw[ipred]) + ' Length ' + str(
            PredictionCalcLength[ipred])
        jpred = PredictionAverageValuesPointer[ipred]
        line += ' Processing Root ' + str(QuantityTakeroot[jpred])
        for proppredval in range(0, 7):
            line += ' ' + QuantityStatisticsNames[proppredval] + ' ' + str(round(QuantityStatistics[jpred, proppredval], 3))
        print(wraptotext(line, size=150))

    # Rescaling done by that appropriate for properties and predictions
    TFTdfTotalSpecshape = TFTdfTotalSpec.shape
    TFTcolumn_definition = []
    print(' ')
    print('LIST TFTcolumn_definition')
    for i in range(0, TFTdfTotalSpecshape[0]):
        TFTcolumn_definition.append((TFTdfTotalSpec.iloc[i, 0], TFTdfTotalSpec.iloc[i, 1], TFTdfTotalSpec.iloc[i, 2]))
        print(TFTcolumn_definition[i])
    print(' ')
    print('Names of Columns of TFTdfTotalSpec i.e. TFTdfTotalSpec.columns')
    print(TFTdfTotalSpec.columns)
    print(' ')
    print('TFTdfTotalSpec.index')
    print(TFTdfTotalSpec.index)

    # Set Futures to be calculated
    if Earthquake:
        PlotFutures = np.full(1 + LengthFutures, False, dtype=np.bool)
        PlotFutures[0] = True
        PlotFutures[6] = True
        PlotFutures[12] = True
        PlotFutures[25] = True
        PredictedQuantity = -NumpredbasicperTime
        for ifuture in range(0, 1 + LengthFutures):
            increment = NumpredbasicperTime
            if ifuture > 1:
                increment = NumpredFuturedperTime
            PredictedQuantity += increment
            for j in range(0, increment):
                PlotPredictions[PredictedQuantity + j] = PlotFutures[ifuture]
                CalculateNNSE[PredictedQuantity + j] = PlotFutures[ifuture]
    else:
        PlotFutures = np.full(1 + LengthFutures, True, dtype=np.bool)

"""###TFT Setup"""

DLAnalysisOnly = False
DLRestorefromcheckpoint = False
DLinputRunName = RunName
DLinputRunName = 'EARTHQ-newTFTv28'
DLinputCheckpointpostfix = '-67'

TFTdropout_rate = 0.1
TFTTransformerbatch_size = 64
TFTTransformerepochs = 40
TFTd_model = 160
TFTTransformertestvalbatch_size = max(128, TFTTransformerbatch_size)
TFThidden_layer_size = TFTd_model

number_LSTMnodes = TFTd_model
LSTMactivationvalue = 'tanh'
LSTMrecurrent_activation = 'sigmoid'
LSTMdropout1 = 0.0
LSTMrecurrent_dropout1 = 0.0

TFTLSTMEncoderInitialMLP = 0
TFTLSTMDecoderInitialMLP = 0
TFTLSTMEncoderrecurrent_dropout1 = LSTMrecurrent_dropout1
TFTLSTMDecoderrecurrent_dropout1 = LSTMrecurrent_dropout1
TFTLSTMEncoderdropout1 = LSTMdropout1
TFTLSTMDecoderdropout1 = LSTMdropout1
TFTLSTMEncoderrecurrent_activation = LSTMrecurrent_activation
TFTLSTMDecoderrecurrent_activation = LSTMrecurrent_activation
TFTLSTMEncoderactivationvalue = LSTMactivationvalue
TFTLSTMDecoderactivationvalue = LSTMactivationvalue
TFTLSTMEncoderSecondLayer = True
TFTLSTMDecoderSecondLayer = True
TFTLSTMEncoderThirdLayer = False
TFTLSTMDecoderThirdLayer = False
TFTLSTMEncoderFinalMLP = 0
TFTLSTMDecoderFinalMLP = 0

TFTnum_heads = 4
TFTnum_AttentionLayers = 2

# For default TFT
TFTuseCUDALSTM = True
TFTdefaultLSTM = False
if TFTdefaultLSTM:
    TFTuseCUDALSTM = True
    TFTLSTMEncoderFinalMLP = 0
    TFTLSTMDecoderFinalMLP = 0
    TFTLSTMEncoderrecurrent_dropout1 = 0.0
    TFTLSTMDecoderrecurrent_dropout1 = 0.0
    TFTLSTMEncoderdropout1 = 0.0
    TFTLSTMDecoderdropout1 = 0.0
    TFTLSTMEncoderSecondLayer = False
    TFTLSTMDecoderSecondLayer = False

TFTFutures = 0
if ReadApril2021Covid:
    TFTFutures = 1 + LengthFutures
if Earthquake:
    TFTFutures = 1 + LengthFutures
if TFTFutures == 0:
    printexit('No TFT Futures defined')

TFTSingleQuantity = True
TFTLossFlag = 0
HuberLosscut = 0.01

if TFTSingleQuantity:
    TFTQuantiles = [1.0]
    TFTQuantilenames = ['MSE']
    TFTPrimaryQuantileIndex = 0
else:
    TFTQuantiles = [0.1, 0.5, 0.9]
    TFTQuantilenames = ['p10', 'p50', 'p90']
    TFTPrimaryQuantileIndex = 1
if TFTLossFlag == 11:
    TFTQuantilenames = ['MAE']
if TFTLossFlag == 12:
    TFTQuantilenames = ['Huber']
TFTfixed_params = {
    'total_time_steps': Tseq + TFTFutures,
    'num_encoder_steps': Tseq,
    'num_epochs': TFTTransformerepochs,
    'early_stopping_patience': 60,
    'multiprocessing_workers': 12,
    'optimizer': 'adam',
    'lossflag': TFTLossFlag,
    'HuberLosscut': HuberLosscut,
    'AnalysisOnly': DLAnalysisOnly,
    'inputRunName': DLinputRunName,
    'Restorefromcheckpoint': DLRestorefromcheckpoint,
    'inputCheckpointpostfix': DLinputCheckpointpostfix,
    'maxibatch_size': TFTTransformertestvalbatch_size,
    'TFTuseCUDALSTM': TFTuseCUDALSTM,
    'TFTdefaultLSTM': TFTdefaultLSTM,
}

TFTmodel_params = {
    'dropout_rate': TFTdropout_rate,
    'hidden_layer_size': TFTd_model,
    'learning_rate': 0.00001,
    'minibatch_size': TFTTransformerbatch_size,
    'max_gradient_norm': 0.01,
    'num_heads': TFTnum_heads,
    'stack_size': TFTnum_AttentionLayers,
}

TFTSymbolicWindows = False
TFTFinalGatingOption = 1
TFTMultivariate = True

TFTuse_testing_mode = False

"""###Base Formatter"""

import abc


class GenericDataFormatter(abc.ABC):
    """Abstract base class for all data formatters.

  User can implement the abstract methods below to perform dataset-specific
  manipulations.

  """

    @abc.abstractmethod
    def set_scalers(self, df):
        """Calibrates scalers using the data supplied."""
        raise NotImplementedError()

    @abc.abstractmethod
    def transform_inputs(self, df):
        """Performs feature transformation."""
        raise NotImplementedError()

    @abc.abstractmethod
    def format_predictions(self, df):
        """Reverts any normalisation to give predictions in original scale."""
        raise NotImplementedError()

    @abc.abstractmethod
    def split_data(self, df):
        """Performs the default train, validation and test splits."""
        raise NotImplementedError()

    @property
    @abc.abstractmethod
    def _column_definition(self):
        """Defines order, input type and data type of each column."""
        raise NotImplementedError()

    @abc.abstractmethod
    def get_fixed_params(self):
        """Defines the fixed parameters used by the model for training.

    Requires the following keys:
      'total_time_steps': Defines the total number of time steps used by TFT
      'num_encoder_steps': Determines length of LSTM encoder (i.e. history)
      'num_epochs': Maximum number of epochs for training
      'early_stopping_patience': Early stopping param for keras
      'multiprocessing_workers': # of cpus for data processing


    Returns:
      A dictionary of fixed parameters, e.g.:

      fixed_params = {
          'total_time_steps': 252 + 5,
          'num_encoder_steps': 252,
          'num_epochs': 100,
          'early_stopping_patience': 5,
          'multiprocessing_workers': 5,
      }
    """
        raise NotImplementedError

    # Shared functions across data-formatters
    @property
    def num_classes_per_cat_input(self):
        """Returns number of categories per relevant input.

    This is seqeuently required for keras embedding layers.
    """
        return self._num_classes_per_cat_input

    def get_num_samples_for_calibration(self):
        """Gets the default number of training and validation samples.

    Use to sub-sample the data for network calibration and a value of -1 uses
    all available samples.

    Returns:
      Tuple of (training samples, validation samples)
    """
        return -1, -1

    def get_column_definition(self):
        """"Returns formatted column definition in order expected by the TFT."""

        column_definition = self._column_definition

        # Sanity checks first.
        # Ensure only one ID and time column exist
        def _check_single_column(input_type):
            length = len([tup for tup in column_definition if tup[2] == input_type])

            if length != 1:
                raise ValueError('Illegal number of inputs ({}) of type {}'.format(
                    length, input_type))

        _check_single_column(InputTypes.ID)
        _check_single_column(InputTypes.TIME)

        identifier = [tup for tup in column_definition if tup[2] == InputTypes.ID]
        time = [tup for tup in column_definition if tup[2] == InputTypes.TIME]
        real_inputs = [
            tup for tup in column_definition if tup[1] == DataTypes.REAL_VALUED and
                                                tup[2] not in TFTexcludedinputtypes
        ]
        categorical_inputs = [
            tup for tup in column_definition if tup[1] == DataTypes.CATEGORICAL and
                                                tup[2] not in TFTexcludedinputtypes
        ]

        return identifier + time + real_inputs + categorical_inputs

    #  XXX Looks important in reordering

    def _get_input_columns(self):
        """Returns names of all input columns."""
        return [
            tup[0]
            for tup in self.get_column_definition()
            if tup[2] not in TFTexcludedinputtypes
        ]

    def _get_tft_input_indices(self):
        """Returns the relevant indexes and input sizes required by TFT."""

        # Functions
        def _extract_tuples_from_data_type(data_type, defn):
            return [
                tup for tup in defn if tup[1] == data_type and
                                       tup[2] not in TFTexcludedinputtypes
            ]

        def _get_locations(input_types, defn):
            return [i for i, tup in enumerate(defn) if tup[2] in input_types]

        # Start extraction
        column_definition = [
            tup for tup in self.get_column_definition()
            if tup[2] not in TFTexcludedinputtypes
        ]
        print('column_definition ' + str(column_definition))

        categorical_inputs = _extract_tuples_from_data_type(DataTypes.CATEGORICAL,
                                                            column_definition)
        real_inputs = _extract_tuples_from_data_type(DataTypes.REAL_VALUED,
                                                     column_definition)

        locations = {
            'input_size':
                len(self._get_input_columns()),
            'output_size':
                len(_get_locations({InputTypes.TARGET}, column_definition)),
            'category_counts':
                self.num_classes_per_cat_input,
            'input_obs_loc':
                _get_locations({InputTypes.TARGET}, column_definition),
            'static_input_loc':
                _get_locations({InputTypes.STATIC_INPUT}, column_definition),
            'known_regular_inputs':
                _get_locations({InputTypes.STATIC_INPUT, InputTypes.KNOWN_INPUT},
                               real_inputs),
            'known_categorical_inputs':
                _get_locations({InputTypes.STATIC_INPUT, InputTypes.KNOWN_INPUT},
                               categorical_inputs),
        }
        print('locations Dictionary')
        for key, value in locations.items():
            print(key, ' : ', value)

        return locations

    def get_experiment_params(self):
        """Returns fixed model parameters for experiments."""

        required_keys = [
            'total_time_steps', 'num_encoder_steps', 'num_epochs',
            'early_stopping_patience', 'multiprocessing_workers'
        ]

        fixed_params = self.get_fixed_params()

        for k in required_keys:
            if k not in fixed_params:
                raise ValueError('Field {}'.format(k) +
                                 ' missing from fixed parameter definitions!')

        fixed_params['column_definition'] = self.get_column_definition()

        fixed_params.update(self._get_tft_input_indices())

        return fixed_params


"""###TFT FFFFWNPF Formatter"""


# Custom formatting functions for FFFFWNPF datasets.

# GenericDataFormatter = data_formatters.base.GenericDataFormatter
# DataTypes = data_formatters.base.DataTypes
# InputTypes = data_formatters.base.InputTypes


class FFFFWNPFFormatter(GenericDataFormatter):
    """
  Defines and formats data for the Covid April 21 dataset.
  Attributes:
    column_definition: Defines input and data type of column used in the
      experiment.
    identifiers: Entity identifiers used in experiments.
  """

    _column_definition = TFTcolumn_definition

    def __init__(self):
        """Initialises formatter."""

        self.identifiers = None
        self._real_scalers = None
        self._cat_scalers = None
        self._target_scaler = None
        self._num_classes_per_cat_input = []
        self._time_steps = self.get_fixed_params()['total_time_steps']

    def split_data(self, df, valid_boundary=-1, test_boundary=-1):
        """Splits data frame into training-validation-test data frames.

    This also calibrates scaling object, and transforms data for each split.

    Args:
      df: Source data frame to split.
      valid_boundary: Starting time for validation data
      test_boundary: Starting time for test data

    Returns:
      Tuple of transformed (train, valid, test) data.
    """

        print('Formatting train-valid-test splits.')

        if LocationBasedValidation:
            index = df['TrainingSet']
            train = df[index == True]
            index = df['ValidationSet']
            valid = df[index == True]
            index = train['Time from Start']
            train = train[index < (Num_Time - 0.5)]
            index = valid['Time from Start']
            valid = valid[index < (Num_Time - 0.5)]
            if test_boundary == -1:
                test = df
        #      train.drop('TrainingSet', axis=1, inplace=True)
        #      train.drop('ValidationSet', axis=1, inplace=True)
        #     valid.drop('TrainingSet', axis=1, inplace=True)
        #     valid.drop('ValidationSet', axis=1, inplace=True)
        else:
            index = df['Time from Start']
            train = df[index < (Num_Time - 0.5)]
            valid = df[index < (Num_Time - 0.5)]
            if test_boundary == -1:
                test = df

        if valid_boundary > 0:
            train = df.loc[index < valid_boundary]
            if test_boundary > 0:
                valid = df.loc[(index >= valid_boundary - 7) & (index < test_boundary)]
            else:
                valid = df.loc[(index >= valid_boundary - 7)]
        if test_boundary > 0:
            test = df.loc[index >= test_boundary - 7]

        self.set_scalers(train)

        Trainshape = train.shape
        Traincols = train.columns
        print(' Train Shape ' + str(Trainshape))
        print(Traincols) \
        Validshape = valid.shape
        Validcols = valid.columns
        print(' Validation Shape ' + str(Validshape))
        print(Validcols)
        if test_boundary >= -1:
            return (self.transform_inputs(data) for data in [train, valid, test])
        else:
            return [train, valid]

    def set_scalers(self, df):
        """Calibrates scalers using the data supplied.

    Args:
      df: Data to use to calibrate scalers.
    """
        print('Setting scalers with training data...')

        column_definitions = self.get_column_definition()
        #    print(column_definitions)
        #    print(InputTypes.TARGET)
        id_column = myTFTTools.utilsget_single_col_by_input_type(InputTypes.ID,
                                                                 column_definitions, TFTMultivariate)
        target_column = myTFTTools.utilsget_single_col_by_input_type(InputTypes.TARGET,
                                                                     column_definitions, TFTMultivariate)

        # Format real scalers
        real_inputs = myTFTTools.extract_cols_from_data_type(
            DataTypes.REAL_VALUED, column_definitions,
            TFTexcludedinputtypes)

        # Initialise scaler caches
        self._real_scalers = {}
        self._target_scaler = {}
        identifiers = []
        for identifier, sliced in df.groupby(id_column):

            data = sliced[real_inputs].values
            if TFTMultivariate == True:
                targets = sliced[target_column].values
            else:
                targets = sliced[target_column].values
            #      self._real_scalers[identifier] = sklearn.preprocessing.StandardScaler().fit(data)

            #      self._target_scaler[identifier] = sklearn.preprocessing.StandardScaler().fit(targets)
            identifiers.append(identifier)

        # Format categorical scalers
        categorical_inputs = myTFTTools.extract_cols_from_data_type(
            DataTypes.CATEGORICAL, column_definitions,
            TFTexcludedinputtypes)

        categorical_scalers = {}
        num_classes = []

        # Set categorical scaler outputs
        self._cat_scalers = categorical_scalers
        self._num_classes_per_cat_input = num_classes

        # Extract identifiers in case required
        self.identifiers = identifiers

    def transform_inputs(self, df):
        """Performs feature transformations.

    This includes both feature engineering, preprocessing and normalisation.

    Args:
      df: Data frame to transform.

    Returns:
      Transformed data frame.

    """

        return df

    def format_predictions(self, predictions):
        """Reverts any normalisation to give predictions in original scale.

    Args:
      predictions: Dataframe of model predictions.

    Returns:
      Data frame of unnormalised predictions.
    """

        return predictions

    # Default params
    def get_fixed_params(self):
        """Returns fixed model parameters for experiments."""

        fixed_params = TFTfixed_params

        return fixed_params

    def get_default_model_params(self):
        """Returns default optimised model parameters."""

        model_params = TFTmodel_params

        return model_params

    def get_num_samples_for_calibration(self):
        """Gets the default number of training and validation samples.

    Use to sub-sample the data for network calibration and a value of -1 uses
    all available samples.

    Returns:
      Tuple of (training samples, validation samples)
    """
        numtrain = TFTdfTotalshape[0]
        numvalid = TFTdfTotalshape[0]
        return numtrain, numvalid


"""###Set TFT Parameter Dictionary"""


def setTFTparameters(data_formatter):
    # Sets up default params
    fixed_params = data_formatter.get_experiment_params()
    params = data_formatter.get_default_model_params()

    params["model_folder"] = TFTmodel_folder
    params['optimizer'] = Transformeroptimizer
    fixed_params["quantiles"] = TFTQuantiles
    fixed_params["quantilenames"] = TFTQuantilenames
    fixed_params["quantileindex"] = TFTPrimaryQuantileIndex
    fixed_params["TFTLSTMEncoderFinalMLP"] = TFTLSTMEncoderFinalMLP
    fixed_params["TFTLSTMDecoderFinalMLP"] = TFTLSTMDecoderFinalMLP
    fixed_params["TFTLSTMEncoderrecurrent_dropout1"] = TFTLSTMEncoderrecurrent_dropout1
    fixed_params["TFTLSTMDecoderrecurrent_dropout1"] = TFTLSTMDecoderrecurrent_dropout1
    fixed_params["TFTLSTMEncoderdropout1"] = TFTLSTMEncoderdropout1
    fixed_params["TFTLSTMDecoderdropout1"] = TFTLSTMDecoderdropout1
    fixed_params["TFTLSTMEncoderSecondLayer"] = TFTLSTMEncoderSecondLayer
    fixed_params["TFTLSTMDecoderSecondLayer"] = TFTLSTMDecoderSecondLayer
    fixed_params["TFTLSTMEncoderThirdLayer"] = TFTLSTMEncoderThirdLayer
    fixed_params["TFTLSTMDecoderThirdLayer"] = TFTLSTMDecoderThirdLayer
    fixed_params["TFTLSTMEncoderrecurrent_activation"] = TFTLSTMEncoderrecurrent_activation
    fixed_params["TFTLSTMDecoderrecurrent_activation"] = TFTLSTMDecoderrecurrent_activation
    fixed_params["TFTLSTMEncoderactivationvalue"] = TFTLSTMEncoderactivationvalue
    fixed_params["TFTLSTMDecoderactivationvalue"] = TFTLSTMDecoderactivationvalue
    fixed_params["TFTLSTMEncoderInitialMLP"] = TFTLSTMEncoderInitialMLP
    fixed_params["TFTLSTMDecoderInitialMLP"] = TFTLSTMDecoderInitialMLP
    fixed_params['number_LSTMnodes'] = number_LSTMnodes
    fixed_params["TFTOption1"] = 1
    fixed_params["TFTOption2"] = 0
    fixed_params['TFTMultivariate'] = TFTMultivariate

    fixed_params['TFTFinalGatingOption'] = TFTFinalGatingOption
    fixed_params['TFTSymbolicWindows'] = TFTSymbolicWindows
    fixed_params['name'] = 'TemporalFusionTransformer'
    fixed_params['nameFFF'] = TFTexperimentname
    fixed_params['runname'] = TFTRunName
    fixed_params['runcomment'] = TFTRunComment
    fixed_params['data_formatter'] = data_formatter
    fixed_params['Validation'] = LocationBasedValidation

    # Parameter overrides for testing only! Small sizes used to speed up script.
    if TFTuse_testing_mode:
        fixed_params["num_epochs"] = 1
        params["hidden_layer_size"] = 5
    #    train_samples, valid_samples = 100, 10 is applied later

    # Load all parameters -- fixed and model
    for k in fixed_params:
        params[k] = fixed_params[k]

    return params


"""###TFTTools"""


class TFTTools(object):
    def __init__(self, params, **kwargs):
        # Args: params: Parameters to define TFT

        self.name = params['name']
        self.experimentname = params['nameFFF']
        self.runname = params['runname']
        self.runcomment = params['runcomment']
        self.data_formatter = params['data_formatter']
        self.lossflag = params['lossflag']
        self.HuberLosscut = params['HuberLosscut']
        self.optimizer = params['optimizer']
        self.validation = params['Validation']
        self.AnalysisOnly = params['AnalysisOnly']
        self.Restorefromcheckpoint = params['Restorefromcheckpoint']
        self.inputRunName = params['inputRunName']
        self.inputCheckpointpostfix = params['inputCheckpointpostfix']
        self.excludeNULLtype = excludeNULLtype
        self.TFTexcludedinputtypes = TFTexcludedinputtypes

        # Data parameters
        self.time_steps = int(params['total_time_steps'])
        self.input_size = int(params['input_size'])
        self.output_size = int(params['output_size'])
        self.category_counts = json.loads(str(params['category_counts']))
        self.n_multiprocessing_workers = int(params['multiprocessing_workers'])

        # Relevant indices for TFT
        self._input_obs_loc = json.loads(str(params['input_obs_loc']))
        self._static_input_loc = json.loads(str(params['static_input_loc']))
        self._known_regular_input_idx = json.loads(
            str(params['known_regular_inputs']))
        self._known_categorical_input_idx = json.loads(
            str(params['known_categorical_inputs']))

        self.column_definition = params['column_definition']

        # Network params
        # self.quantiles = [0.1, 0.5, 0.9]
        self.quantiles = params['quantiles']
        self.NumberQuantiles = len(self.quantiles)
        self.Quantilenames = params['quantilenames']
        self.PrimaryQuantileIndex = int(params['quantileindex'])
        self.useMSE = False
        if self.NumberQuantiles == 1 and self.Quantilenames[0] == 'MSE':
            self.useMSE = True
        self.TFTOption1 = params['TFTOption1']
        self.TFTOption2 = params['TFTOption2']
        self.TFTMultivariate = params['TFTMultivariate']

        self.TFTuseCUDALSTM = params['TFTuseCUDALSTM']
        self.TFTdefaultLSTM = params['TFTdefaultLSTM']
        self.number_LSTMnodes = params['number_LSTMnodes']
        self.TFTLSTMEncoderInitialMLP = params["TFTLSTMEncoderInitialMLP"]
        self.TFTLSTMDecoderInitialMLP = params["TFTLSTMDecoderInitialMLP"]
        self.TFTLSTMEncoderFinalMLP = params['TFTLSTMEncoderFinalMLP']
        self.TFTLSTMDecoderFinalMLP = params['TFTLSTMDecoderFinalMLP']
        self.TFTLSTMEncoderrecurrent_dropout1 = params["TFTLSTMEncoderrecurrent_dropout1"]
        self.TFTLSTMDecoderrecurrent_dropout1 = params["TFTLSTMDecoderrecurrent_dropout1"]
        self.TFTLSTMEncoderdropout1 = params["TFTLSTMEncoderdropout1"]
        self.TFTLSTMDecoderdropout1 = params["TFTLSTMDecoderdropout1"]
        self.TFTLSTMEncoderrecurrent_activation = params["TFTLSTMEncoderrecurrent_activation"]
        self.TFTLSTMDecoderrecurrent_activation = params["TFTLSTMDecoderrecurrent_activation"]
        self.TFTLSTMEncoderactivationvalue = params["TFTLSTMEncoderactivationvalue"]
        self.TFTLSTMDecoderactivationvalue = params["TFTLSTMDecoderactivationvalue"]
        self.TFTLSTMEncoderSecondLayer = params["TFTLSTMEncoderSecondLayer"]
        self.TFTLSTMDecoderSecondLayer = params["TFTLSTMDecoderSecondLayer"]
        self.TFTLSTMEncoderThirdLayer = params["TFTLSTMEncoderThirdLayer"]
        self.TFTLSTMDecoderThirdLayer = params["TFTLSTMDecoderThirdLayer"]
        self.TFTFinalGatingOption = params['TFTFinalGatingOption']
        self.TFTSymbolicWindows = params['TFTSymbolicWindows']

        self.FinalLoopSize = 1
        if (self.output_size == 1) and (self.NumberQuantiles == 1):
            self.TFTFinalGatingOption = 0
        if self.TFTFinalGatingOption > 0:
            self.TFTLSTMFinalMLP = 0
            self.FinalLoopSize = self.output_size * self.NumberQuantiles

        self.hidden_layer_size = int(params['hidden_layer_size'])
        self.dropout_rate = float(params['dropout_rate'])
        self.max_gradient_norm = float(params['max_gradient_norm'])
        self.learning_rate = float(params['learning_rate'])
        self.minibatch_size = int(params['minibatch_size'])
        self.maxibatch_size = int(params['maxibatch_size'])
        self.num_epochs = int(params['num_epochs'])
        self.early_stopping_patience = int(params['early_stopping_patience'])

        self.num_encoder_steps = int(params['num_encoder_steps'])
        self.num_stacks = int(params['stack_size'])
        self.num_heads = int(params['num_heads'])

        # Serialisation options
        # XXX
        #    self._temp_folder = os.path.join(params['model_folder'], 'tmp')
        #    self.reset_temp_folder()

        # Extra components to store Tensorflow nodes for attention computations
        # XXX
        #    self._input_placeholder = None
        #    self._attention_components = None
        #    self._prediction_parts = None

        self.TFTSeq = 0
        self.TFTNloc = 0
        self.UniqueLocations = []

    def utilsget_single_col_by_input_type(self, input_type, column_definition, TFTMultivariate):
        """Returns name of single or multiple column.

    Args:
      input_type: Input type of column to extract
      column_definition: Column definition list for experiment
    """

        columnname = [tup[0] for tup in column_definition if tup[2] == input_type]

        # allow multiple targets
        if TFTMultivariate and (input_type == 0):
            return columnname
        else:
            if len(columnname) != 1:
                printexit('Invalid number of columns for Type {}'.format(input_type))
            return columnname[0]

    def _get_single_col_by_type(self, input_type):
        return self.utilsget_single_col_by_input_type(input_type, self.column_definition, self.TFTMultivariate)

    def extract_cols_from_data_type(self, data_type, column_definition,
                                    excluded_input_types):
        """Extracts the names of columns that correspond to a define data_type.

    Args:
      data_type: DataType of columns to extract.
      column_definition: Column definition to use.
      excluded_input_types: Set of input types to exclude

    Returns:
      List of names for columns with data type specified.
    """
        return [
            tup[0]
            for tup in column_definition
            if tup[1] == data_type and tup[2] not in excluded_input_types
        ]

    # Quantile Loss functions.
    def tensorflow_quantile_loss(self, y, y_pred, quantile):
        """Computes quantile loss for tensorflow.

    Standard quantile loss as defined in the "Training Procedure" section of
    the main TFT paper

    Args:
      y: Targets
      y_pred: Predictions
      quantile: Quantile to use for loss calculations (between 0 & 1)

    Returns:
      Tensor for quantile loss.
    """

        # Checks quantile
        if quantile < 0 or quantile > 1:
            printexit(
                'Illegal quantile value={}! Values should be between 0 and 1.'.format(
                    quantile))

        prediction_underflow = y - y_pred
        q_loss = quantile * tf.maximum(prediction_underflow, 0.) + (
                1. - quantile) * tf.maximum(-prediction_underflow, 0.)

        return tf.reduce_sum(q_loss, axis=-1)

    def PrintTitle(self, extrawords):
        current_time = timenow()
        line = self.name + ' ' + self.experimentname + ' ' + self.runname + ' ' + self.runcomment
        beginwords = ''
        if extrawords != '':
            beginwords = extrawords + ' '
        print(wraptotext(startbold + startred + beginwords + current_time + ' ' + line + resetfonts))
        ram_gb = virtual_memory().total / 1e9
        print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))


"""###Setup  Classic TFT"""

# Commented out IPython magic to ensure Python compatibility.
import json

'''
# %cd "/content/gdrive/MyDrive/Colab Datasets/TFToriginal/"
# %ls
# %cd TFTCode/
TFTexperimentname= "FFFFWNPF"
output_folder = "../TFTData" # Please don't change this path
Rootmodel_folder = os.path.join(output_folder, 'saved_models', TFTexperimentname)
TFTmodel_folder = os.path.join(Rootmodel_folder, "fixed" + RunName)
'''
TFTexperimentname = "FFFFWNPF"
TFTmodel_folder = "Notused"
TFTRunName = RunName
TFTRunComment = RunComment
print('Set up useful columns in needed classes')

print('These will be used in selecting items to convert from dataframe to numpy')
if TFTexperimentname == 'FFFFWNPF':
    formatter = FFFFWNPFFormatter()

# Save data frames
# TFTdfTotalSpec.to_csv('TFTdfTotalSpec.csv')
# TFTdfTotal.to_csv('TFTdfTotal.csv')
else:
    import expt_settings.configs

    ExperimentConfig = expt_settings.configs.ExperimentConfig
    config = ExperimentConfig(name, output_folder)
    formatter = config.make_data_formatter()

TFTparams = setTFTparameters(formatter)
myTFTTools = TFTTools(TFTparams)
print(' ')
myTFTTools.PrintTitle('Start TFT')

for k in TFTparams:
    print('# {} = {}'.format(k, TFTparams[k]))

"""###Read TFT Data"""


def printLIST(label, outputlist):
    if len(outputlist) < 5:
        print(label + ' ' + str(outputlist))
        return
    print(label)
    for start in range(0, len(outputlist), 4):
        endindex = min(start + 4, len(outputlist))
        line = ''
        for i in range(start, endindex):
            line += str(outputlist[i]) + ', '
        print(line)
    return


class TFTDataCache(object):
    """Caches data for the TFT.
  This is a class and has no instances so uses cls not self
  It just sets and uses a dictionary to record batched data locations"""

    _data_cache = {}

    @classmethod
    def update(cls, data, key):
        """Updates cached data.

    Args:
      data: Source to update
      key: Key to dictionary location
    """
        cls._data_cache[key] = data

    @classmethod
    def get(cls, key):
        """Returns data stored at key location."""
        return cls._data_cache[key]

    @classmethod
    def contains(cls, key):
        """Retuns boolean indicating whether key is present in cache."""

        return key in cls._data_cache


class TFTdatasetup(object):

    def __init__(self, **kwargs):
        super(TFTdatasetup, self).__init__(**kwargs)

        self.TFTNloc = 0

        # XXX TFTNloc bad
        if myTFTTools.TFTSymbolicWindows:
            # Set up Symbolic maps allowing location order to differ (due to possible sorting in TFT)
            id_col = myTFTTools._get_single_col_by_type(InputTypes.ID)
            time_col = myTFTTools._get_single_col_by_type(InputTypes.TIME)
            target_col = myTFTTools._get_single_col_by_type(InputTypes.TARGET)
            input_cols = [
                tup[0]
                for tup in myTFTTools.column_definition
                if tup[2] not in TFTexcludedinputtypes
            ]

            self.UniqueLocations = TFTdfTotal[id_col].unique()
            self.TFTNloc = len(self.UniqueLocations)
            self.LocationLookup = {}
            for i, locationname in enumerate(self.UniqueLocations):
                self.LocationLookup[locationname] = i  # maps name to TFT master location number

            self.TFTnum_entries = 0  # Number of time values per location
            for identifier, df in TFTdfTotal.groupby(id_col):
                localnum_entries = len(df)
                if self.TFTnum_entries == 0:
                    self.TFTnum_entries = localnum_entries
                else:
                    if self.TFTnum_entries != localnum_entries:
                        printexit('Incorrect length in time for ' + identifier + ' ' + str(localnum_entries))
            self.Lookupinputs = np.zeros((self.TFTNloc, self.TFTnum_entries, myTFTTools.input_size))
            for identifier, df in TFTdfTotal.groupby(id_col):
                location = self.LocationLookup[identifier]
                self.Lookupinputs[location, :, :] = df[input_cols].to_numpy(dtype=np.float32, copy=True)

    def __call__(self, data, Dataset_key, num_samples=-1):
        """Batches Dataset for training, Validation.
    Testing not Batched

    Args:
      data: Data to batch
      Dataset_key: Key used for cache
      num_samples: Maximum number of samples to extract (-1 to use all data)
    """
        max_samples = num_samples
        if max_samples < 0:
            max_samples = data.shape[0]
        sampleddata = self._sampled_data(data, Dataset_key, max_samples=max_samples)
        TFTDataCache.update(sampleddata, Dataset_key)

        print('Cached data "{}" updated'.format(Dataset_key))
        return sampleddata

    def _sampled_data(self, data, Dataset_key, max_samples):
        """Samples segments into a compatible format.

    Args:
      data: Sources data to sample and batch
      max_samples: Maximum number of samples in batch

    Returns:
      Dictionary of batched data with the maximum samples specified.
    """

        if (max_samples < 1) and (max_samples != -1):
            raise ValueError(
                'Illegal number of samples specified! samples={}'.format(max_samples))

        id_col = myTFTTools._get_single_col_by_type(InputTypes.ID)
        time_col = myTFTTools._get_single_col_by_type(InputTypes.TIME)

        # data.sort_values(by=[id_col, time_col], inplace=True)  # gives warning message

        print('Getting legal sampling locations.')
        valid_sampling_locations = []
        split_data_map = {}
        self.TFTSeq = 0

        for identifier, df in data.groupby(id_col):
            self.TFTnum_entries = len(df)
            self.TFTSeq = max(self.TFTSeq, self.TFTnum_entries - myTFTTools.time_steps + 1)
            if self.TFTnum_entries >= myTFTTools.time_steps:
                valid_sampling_locations += [
                    (identifier, myTFTTools.time_steps + i)
                    for i in range(self.TFTnum_entries - myTFTTools.time_steps + 1)
                ]
            split_data_map[identifier] = df
        print(Dataset_key + ' max samples ' + str(max_samples) + ' actual ' + str(len(valid_sampling_locations)))

        actual_samples = min(max_samples, len(valid_sampling_locations))
        if max_samples > 0 and len(valid_sampling_locations) > max_samples:
            print('Extracting {} samples...'.format(max_samples))
            ranges = [
                valid_sampling_locations[i] for i in np.random.choice(
                    len(valid_sampling_locations), max_samples, replace=False)
            ]
        else:
            print('Max samples={} exceeds # available segments={}'.format(
                max_samples, len(valid_sampling_locations)))
            ranges = valid_sampling_locations

        id_col = myTFTTools._get_single_col_by_type(InputTypes.ID)
        time_col = myTFTTools._get_single_col_by_type(InputTypes.TIME)
        target_col = myTFTTools._get_single_col_by_type(InputTypes.TARGET)
        input_cols = [
            tup[0]
            for tup in myTFTTools.column_definition
            if tup[2] not in TFTexcludedinputtypes
        ]
        print('\nid_col ' + str(id_col))
        print('time_col ' + str(time_col))
        print(' ')
        printLIST('target_col(s) LIST ', target_col)
        print(' ')
        printLIST('input_cols LIST', input_cols)

        if myTFTTools.TFTSymbolicWindows:

            inputs = np.zeros((actual_samples), dtype=np.int32)
            outputs = np.zeros((actual_samples, myTFTTools.time_steps, myTFTTools.output_size))
            time = np.empty((actual_samples, myTFTTools.time_steps, 1), dtype=object)
            identifiers = np.empty((actual_samples, myTFTTools.time_steps, 1), dtype=object)

            oldlocationnumber = -1
            storedlocation = np.zeros(self.TFTNloc, dtype=np.int32)
            for i, tup in enumerate(ranges):
                identifier, start_idx = tup
                newlocationnumber = self.LocationLookup[identifier]
                if newlocationnumber != oldlocationnumber:
                    oldlocationnumber = newlocationnumber
                    if storedlocation[newlocationnumber] == 0:
                        storedlocation[newlocationnumber] = 1
                sliced = split_data_map[identifier].iloc[start_idx -
                                                         myTFTTools.time_steps:start_idx]
                #          inputs[i, :, :] = sliced[input_cols]
                inputs[i] = np.left_shift(start_idx, 16) + newlocationnumber
                #         Sequence runs from start_idx - myTFTTools.time_steps to start_idx i.e. start_idx is label of FINAL time step in position start_idx - 1
                if myTFTTools.TFTMultivariate:
                    outputs[i, :, :] = sliced[target_col]
                else:
                    outputs[i, :, :] = sliced[[target_col]]
                time[i, :, 0] = sliced[time_col]
                identifiers[i, :, 0] = sliced[id_col]
            inputs = inputs.reshape(-1, 1, 1)
            sampled_data = {
                'inputs': inputs,
                'outputs': outputs[:, myTFTTools.num_encoder_steps:, :],
                'active_entries': np.ones_like(outputs[:, self.num_encoder_steps:, :]),
                'time': time,
                'identifier': identifiers
            }

        else:
            inputs = np.zeros((actual_samples, myTFTTools.time_steps, myTFTTools.input_size), dtype=np.float32)
            outputs = np.zeros((actual_samples, myTFTTools.time_steps, myTFTTools.output_size), dtype=np.float32)
            time = np.empty((actual_samples, myTFTTools.time_steps, 1), dtype=object)
            identifiers = np.empty((actual_samples, myTFTTools.time_steps, 1), dtype=object)

            for i, tup in enumerate(ranges):
                identifier, start_idx = tup
                sliced = split_data_map[identifier].iloc[start_idx -
                                                         myTFTTools.time_steps:start_idx]
                inputs[i, :, :] = sliced[input_cols]
                if myTFTTools.TFTMultivariate:
                    outputs[i, :, :] = sliced[target_col]
                else:
                    outputs[i, :, :] = sliced[[target_col]]
                time[i, :, 0] = sliced[time_col]
                identifiers[i, :, 0] = sliced[id_col]

            sampled_data = {
                'inputs': inputs,
                'outputs': outputs[:, myTFTTools.num_encoder_steps:, :],
                'active_entries': np.ones_like(outputs[:, myTFTTools.num_encoder_steps:, :], dtype=np.float32),
                'time': time,
                'identifier': identifiers
            }

        return sampled_data


def dothedatasetup():
    myTFTTools.PrintTitle("Loading & splitting data...")

    if myTFTTools.experimentname == 'FFFFWNPF':
        raw_data = TFTdfTotal
    else:
        printexit('Currently only FFFWNPF supported')
    #    raw_data = pd.read_csv(TFTdfTotal, index_col=0)

    # XXX don't use test Could simplify
    train, valid, test = myTFTTools.data_formatter.split_data(raw_data, test_boundary=-1)
    train_samples, valid_samples = myTFTTools.data_formatter.get_num_samples_for_calibration()
    test_samples = -1
    if TFTuse_testing_mode:
        train_samples, valid_samples, test_samples = 100, 10, 100

    myTFTReader = TFTdatasetup()
    train_data = myTFTReader(train, "train", num_samples=train_samples)
    val_data = None
    if valid_samples > 0:
        val_data = myTFTReader(valid, "valid", num_samples=valid_samples)
    test_data = myTFTReader(test, "test", num_samples=test_samples)
    return train_data, val_data, test_data


TFTtrain_datacollection, TFTval_datacollection, TFTtest_datacollection = dothedatasetup()
TFToutput_map = None  # holder for final output

"""##Predict TFT

###Visualize TFT

Called from finalizeDL
"""


class TFTSaveandInterpret():

    def __init__(self, currentTFTmodel, currentoutput_map, ReshapedPredictionsTOT):
        # output_map is a dictionary pointing to dataframes
        # output_map["targets"]) targets are called outputs on input
        # output_map["p10"] is   p10 quantile forecast
        # output_map["p50"] is   p10 quantile forecast
        # output_map["p90"] is   p10 quantile forecast
        #  Labelled by last real time in sequence (t-1) which starts at time Tseq-1 going up to Num_Time-1

        # order of Dataframe columns is 'forecast_time', 'identifier',
        # 't+0-Obs0', 't+0-Obs1', 't+1-Obs0', 't+1-Obs1', 't+2-Obs0', 't+2-Obs1', 't+3-Obs0', 't+3-Obs1',
        # 't+4-Obs0', 't+4-Obs1', 't+5-Obs0', 't+5-Obs1', 't+6-Obs0', 't+6-Obs1', 't+7-Obs0', 't+7-Obs1',
        # 't+8-Obs0', 't+8-Obs1', 't+9-Obs0', 't+9-Obs1', 't+10-Obs0', 't+10-Obs1', 't+11-Obs0', 't+11-Obs1',
        # 't+12-Obs0', 't+12-Obs1', 't+13-Obs0', 't+13-Obs1', 't+14-Obs0', 't+14-Obs1''

        # First time is FFFFWNPF Sequence # + Tseq-1
        # Rows of data frame are ilocation*(Num_Seq+1) + FFFFWNPF Sequence #
        # ilocation runs from 0 ... Nloc-1 in same order in both TFT and FFFFWNPF

        self.ScaledProperty = -1
        self.Scaled = False
        self.savedcolumn = []
        self.currentoutput_map = currentoutput_map
        self.currentTFTmodel = currentTFTmodel
        Sizes = self.currentoutput_map[TFTQuantilenames[TFTPrimaryQuantileIndex]].shape
        self.Numx = Sizes[0]
        self.Numy = Sizes[1]
        self.Num_Seq1 = 1 + Num_Seq
        self.MaxTFTSeq = self.Num_Seq1 - 1
        expectednumx = self.Num_Seq1 * Nloc
        if expectednumx != self.Numx:
            printexit(' Wrong sizes of TFT compared to FFFFWNPF ' + str(expectednumx) + ' ' + str(self.Numx))
        self.ReshapedPredictionsTOT = ReshapedPredictionsTOT
        myTFTTools.PrintTitle('Set up TFTSaveandInterpret')
        return

    def setFFFFmapping(self):
        myTFTTools.PrintTitle('Set up setFFFFmapping')
        self.FFFFWNPFresults = np.zeros((self.Numx, NpredperseqTOT, 3), dtype=np.float32)

        mapFFFFtoTFT = np.empty(Nloc, dtype=np.int32)
        TFTLoc = self.currentoutput_map[TFTQuantilenames[TFTPrimaryQuantileIndex]]['identifier'].unique()
        FFFFWNPFLocLookup = {}
        for i, locname in enumerate(FFFFWNPFUniqueLabel):
            FFFFWNPFLocLookup[locname] = i
        TFTLocLookup = {}
        for i, locname in enumerate(TFTLoc):
            TFTLocLookup[locname] = i
            if FFFFWNPFLocLookup[locname] is None:
                printexit('Missing TFT Location ' + locname)
        for i, locname in enumerate(FFFFWNPFUniqueLabel):
            j = TFTLocLookup[locname]
            if j is None:
                printexit('Missing FFFFWNPF Location ' + locname)
            mapFFFFtoTFT[i] = j

        indexposition = np.empty(NpredperseqTOT, dtype=int)
        output_mapcolumns = self.currentoutput_map[TFTQuantilenames[TFTPrimaryQuantileIndex]].columns
        numcols = len(output_mapcolumns)
        for ipred in range(0, NpredperseqTOT):
            predstatus = PredictionTFTAction[ipred]
            if predstatus > 0:
                indexposition[ipred] = -1
                continue
            label = PredictionTFTnamemapping[ipred]
            if label == ' ':
                indexposition[ipred] = ipred
            else:
                findpos = -1
                for i in range(0, numcols):
                    if label == output_mapcolumns[i]:
                        findpos = i
                if findpos < 0:
                    printexit('Missing Output ' + str(ipred) + ' ' + label)
                indexposition[ipred] = findpos

        for iquantile in range(0, myTFTTools.NumberQuantiles):
            for ilocation in range(0, Nloc):
                for seqnumber in range(0, self.Num_Seq1):

                    for ipred in range(0, NpredperseqTOT):
                        predstatus = PredictionTFTAction[ipred]
                        if predstatus > 0:
                            continue
                        label = PredictionTFTnamemapping[ipred]
                        if label == ' ':  # NOT calculated by TFT
                            if seqnumber >= Num_Seq:
                                value = 0.0
                            else:
                                value = self.ReshapedPredictionsTOT[ilocation, seqnumber, ipred]

                        else:
                            ActualTFTSeq = seqnumber
                            if ActualTFTSeq <= self.MaxTFTSeq:
                                ipos = indexposition[ipred]
                                dfindex = self.Num_Seq1 * mapFFFFtoTFT[ilocation] + ActualTFTSeq
                                value = self.currentoutput_map[TFTQuantilenames[iquantile]].iloc[dfindex, ipos]
                            else:
                                dfindex = self.Num_Seq1 * mapFFFFtoTFT[ilocation] + self.MaxTFTSeq
                                ifuture = int(ipred / FFFFWNPFNumberTargets)
                                jfuture = ActualTFTSeq - self.MaxTFTSeq + ifuture
                                if jfuture <= LengthFutures:
                                    jpred = ipred + (jfuture - ifuture) * FFFFWNPFNumberTargets
                                    value = self.currentoutput_map[TFTQuantilenames[iquantile]].iloc[
                                        dfindex, indexposition[jpred]]
                                else:
                                    value = 0.0

                        FFFFdfindex = self.Num_Seq1 * ilocation + seqnumber
                        self.FFFFWNPFresults[FFFFdfindex, ipred, iquantile] = value

                        # Set Calculated Quantities as previous ipred loop has set base values
                    for ipred in range(0, NpredperseqTOT):
                        predstatus = PredictionTFTAction[ipred]
                        if predstatus <= 0:
                            continue
                        Basedonprediction = CalculatedPredmaptoRaw[ipred]
                        predaveragevaluespointer = PredictionAverageValuesPointer[Basedonprediction]
                        rootflag = QuantityTakeroot[predaveragevaluespointer]
                        rawdata = np.empty(PredictionCalcLength[ipred], dtype=np.float32)
                        ActualTFTSeq = seqnumber

                        if ActualTFTSeq <= self.MaxTFTSeq:
                            for ifuture in range(0, PredictionCalcLength[ipred]):
                                if ifuture == 0:
                                    kpred = Basedonprediction
                                else:
                                    jfuture = NumpredbasicperTime + NumpredFuturedperTime * (ifuture - 1)
                                    kpred = jfuture + FuturedPointer[Basedonprediction]
                                if predstatus == 3:
                                    newvalue = self.ReshapedPredictionsTOT[ilocation, ActualTFTSeq, kpred] / \
                                               QuantityStatistics[predaveragevaluespointer, 2] + QuantityStatistics[
                                                   predaveragevaluespointer, 0]
                                else:
                                    kpos = indexposition[kpred]
                                    dfindex = self.Num_Seq1 * mapFFFFtoTFT[ilocation] + ActualTFTSeq
                                    newvalue = self.currentoutput_map[TFTQuantilenames[iquantile]].iloc[dfindex, kpos] / \
                                               QuantityStatistics[predaveragevaluespointer, 2] + QuantityStatistics[
                                                   predaveragevaluespointer, 0]

                                if rootflag == 2:
                                    newvalue = newvalue ** 2
                                if rootflag == 3:
                                    newvalue = newvalue ** 3
                                rawdata[ifuture] = newvalue

                            # Form collective quantity
                            if (predstatus == 1):
                                value = rawdata.sum()
                            elif predstatus >= 2:
                                value = log_energy(rawdata, sumaxis=0)
                            else:
                                value = 0.0
                            value = SetTakeroot(value, QuantityTakeroot[ipred])
                            actualpredaveragevaluespointer = PredictionAverageValuesPointer[ipred]
                            value = (value - QuantityStatistics[actualpredaveragevaluespointer, 0]) * QuantityStatistics[
                                actualpredaveragevaluespointer, 2]

                        else:  # Sequence out of range
                            value = 0.0

                        FFFFdfindex = self.Num_Seq1 * ilocation + seqnumber
                        self.FFFFWNPFresults[FFFFdfindex, ipred, iquantile] = value
        myTFTTools.PrintTitle('End up setFFFFmapping')
        return

    # Default returns the median (50% quantile)
    def __call__(self, InputVector, Time=None, training=False, Quantile=None):
        lenvector = InputVector.shape[0]
        result = np.empty((lenvector, NpredperseqTOT), dtype=np.float32)
        if Quantile is None:
            Quantile = TFTPrimaryQuantileIndex
        for ivector in range(0, lenvector):
            dfindex = self.Num_Seq1 * InputVector[ivector, 0] + InputVector[ivector, 1]
            result[ivector, :] = self.FFFFWNPFresults[dfindex, :, Quantile]

        return result

    def CheckProperty(self, iprop):
        # Return true if property defined for TFT
        # set ScaledProperty to be column to be changed
        if (iprop < 0) or (iprop >= NpropperseqTOT):
            return False
        jprop = TFTPropertyChoice[iprop]
        if jprop >= 0:
            return True
        return False

    def SetupProperty(self, iprop):
        if self.Scaled:
            self.ResetProperty()
        if (iprop < 0) or (iprop >= NpropperseqTOT):
            return False
        jprop = TFTPropertyChoice[iprop]
        if jprop >= 0:
            self.ScaledProperty = jprop
            self.savedcolumn = TFTdfTotal.iloc[:, jprop].copy()
            return True
        return False

    def ScaleProperty(self, ScalingFactor):
        jprop = self.ScaledProperty
        TFTdfTotal.iloc[:, jprop] = ScalingFactor * self.savedcolumn
        self.Scaled = True
        return

    def ResetProperty(self):
        jprop = self.ScaledProperty
        if jprop >= 0:
            TFTdfTotal.iloc[:, jprop] = self.savedcolumn
        self.Scaled = False
        self.ScaledProperty = -1
        return

    def MakeMapping(self):
        IncreaseNloc_sample = 1
        DecreaseNloc_sample = 1
        TFTtrain_notused, TFTval_notused, TFTtest_changed = dothedatasetup()
        self.currentoutput_map = TFTTestpredict(self.currentTFTmodel, TFTtest_changed)
        self.setFFFFmapping()
        return


def VisualizeTFT(TFTmodel, output_map):
    myTFTTools.PrintTitle('Start VisualizeTFT')
    MyFFFFWNPFLink = TFTSaveandInterpret(TFTmodel, output_map, ReshapedPredictionsTOT)
    MyFFFFWNPFLink.setFFFFmapping()
    modelflag = 2
    myTFTTools.PrintTitle('Invoke DLPrediction')
    FitPredictions = DLprediction(ReshapedSequencesTOT, RawInputPredictionsTOT, MyFFFFWNPFLink, modelflag, LabelFit='TFT')
    myTFTTools.PrintTitle('End VisualizeTFT')
    # Input Predictions RawInputPredictionsTOT for DLPrediction are ordered Sequence #, Location but
    # Input Predictions ReshapedPredictionsTOT for TFTSaveandInterpret are ordered Location, Sequence#
    # Note TFT maximum Sequence # is one larger than FFFFWNPF


"""##TFT Routines

### GLUplusskip: Gated Linear unit plus add and norm with Skip
"""


# GLU with time distribution  optional
# Dropout on input dropout_rate
# Linear layer with hidden_layer_size and activation
# Linear layer with hidden_layer_size and sigmoid
# Follow with an add and norm
class GLUplusskip(tf.keras.layers.Layer):

    def __init__(self, hidden_layer_size,
                 dropout_rate=None,
                 use_time_distributed=True,
                 activation=None,
                 GLUname='Default',
                 **kwargs):
        """Applies a Gated Linear Unit (GLU) to an input.
    Follow with an add and norm

    Args:
      hidden_layer_size: Dimension of GLU
      dropout_rate: Dropout rate to apply if any
      use_time_distributed: Whether to apply across time (index 1)
      activation: Activation function to apply to the linear feature transform if necessary

    Returns:
      Tuple of tensors for: (GLU output, gate)
    """
        super(GLUplusskip, self).__init__(**kwargs)
        self.Gatehidden_layer_size = hidden_layer_size
        self.Gatedropout_rate = dropout_rate
        self.Gateuse_time_distributed = use_time_distributed
        self.Gateactivation = activation

        if self.Gatedropout_rate is not None:
            n1 = 'GLUSkip' + 'dropout' + GLUname
            self.FirstDropout = tf.keras.layers.Dropout(self.Gatedropout_rate, name=n1)

        n3 = 'GLUSkip' + 'DenseAct1' + GLUname
        n5 = 'GLUSkip' + 'DenseAct2' + GLUname
        if self.Gateuse_time_distributed:
            n2 = 'GLUSkip' + 'TD1' + GLUname
            self.Gateactivation_layer = tf.keras.layers.TimeDistributed(
                tf.keras.layers.Dense(self.Gatehidden_layer_size, activation=self.Gateactivation, name=n3), name=n2)
            n4 = 'GLUSkip' + 'TD2' + GLUname
            self.Gategated_layer = tf.keras.layers.TimeDistributed(
                tf.keras.layers.Dense(self.Gatehidden_layer_size, activation='sigmoid', name=n5), name=n4)
        else:
            self.Gateactivation_layer = tf.keras.layers.Dense(self.Gatehidden_layer_size, activation=self.Gateactivation,
                                                              name=n3)
            self.Gategated_layer = tf.keras.layers.Dense(self.Gatehidden_layer_size, activation='sigmoid', name=n5)

        n6 = 'GLUSkip' + 'Mul' + GLUname
        self.GateMultiply = tf.keras.layers.Multiply(name=n6)

        n7 = 'GLUSkip' + 'Add' + GLUname
        n8 = 'GLUSkip' + 'Norm' + GLUname
        self.GateAdd = tf.keras.layers.Add(name=n7)
        self.GateNormalization = tf.keras.layers.LayerNormalization(name=n8)

    # EAGER@tf.function
    def call(self, Gateinput, Skipinput, training=None):
        # Args:
        # Gateinput: Input to gating layer
        # Skipinput: Input to add and norm

        if self.Gatedropout_rate is not None:
            x = self.FirstDropout(Gateinput)
        else:
            x = Gateinput

        activation_layer = self.Gateactivation_layer(x)
        gated_layer = self.Gategated_layer(x)

        # Formal end of GLU
        GLUoutput = self.GateMultiply([activation_layer, gated_layer])

        # Applies skip connection followed by layer normalisation to get GluSkip.
        GLUSkipoutput = self.GateAdd([Skipinput, GLUoutput])
        GLUSkipoutput = self.GateNormalization(GLUSkipoutput)

        return GLUSkipoutput, gated_layer


"""###Linear Layer (Dense)"""


# Layer utility functions.
# Single layer size activation with bias and time distribution  optional

def TFTlinear_layer(size,
                    activation=None,
                    use_time_distributed=False,
                    use_bias=True,
                    LLname='Default'):
    """Returns simple Keras linear layer.

    Args:
      size: Output size
      activation: Activation function to apply if required
      use_time_distributed: Whether to apply layer across time
      use_bias: Whether bias should be included in layer
  """
    n1 = 'LL' + 'Dense' + LLname
    linear = tf.keras.layers.Dense(size, activation=activation, use_bias=use_bias, name=n1)
    if use_time_distributed:
        n2 = 'LL' + 'TD' + LLname
        linear = tf.keras.layers.TimeDistributed(linear, name=n2)
    return linear


"""###Apply MLP"""


class apply_mlp(tf.keras.layers.Layer):

    def __init__(self, hidden_layer_size, output_size, output_activation=None, hidden_activation='tanh',
                 use_time_distributed=False, MLPname='Default', **kwargs):
        """Applies simple feed-forward network to an input.

    Args:
        hidden_layer_size: Hidden state size
      output_size: Output size of MLP
      output_activation: Activation function to apply on output
      hidden_activation: Activation function to apply on input
      use_time_distributed: Whether to apply across time

    Returns:
      Tensor for MLP outputs.
    """
        super(apply_mlp, self).__init__(**kwargs)
        self.MLPhidden_layer_size = hidden_layer_size
        self.MLPoutput_size = output_size
        self.MLPoutput_activation = output_activation
        self.MLPhidden_activation = hidden_activation
        self.MLPuse_time_distributed = use_time_distributed
        n1 = 'MLPDense1' + MLPname
        n2 = 'MLPDense2' + MLPname
        if self.MLPuse_time_distributed:
            n3 = 'MLPTD1' + MLPname
            n4 = 'MLPTD2' + MLPname
            MLPFirstLayer = tf.keras.layers.TimeDistributed(
                tf.keras.layers.Dense(self.MLPhidden_layer_size, activation=self.MLPhidden_activation, name=n1), name=n3)
            MLPSecondLayer = tf.keras.layers.TimeDistributed(
                tf.keras.layers.Dense(self.MLPoutput_size, activation=self.MLPoutput_activation, name=n2), name=n4)
        else:
            MLPFirstLayer = tf.keras.layers.Dense(self.MLPhidden_layer_size, activation=self.MLPhidden_activation, name=n1)
            MLPSecondLayer = tf.keras.layers.Dense(self.MLPoutput_size, activation=self.MLPoutput_activation, name=n2)

    # EAGER@tf.function
    def call(self, inputs):
        #    inputs: MLP inputs

        hidden = MLPFirstLayer(inputs)
        return MLPSecondLayer(hidden)


"""###GRN Gated Residual Network"""


# GRN Gated Residual Network
class GRN(tf.keras.layers.Layer):

    def __init__(self, hidden_layer_size, output_size=None, dropout_rate=None,
                 use_additionalcontext=False, use_time_distributed=True, GRNname='Default', **kwargs):
        """Applies the gated residual network (GRN) as defined in paper.

    Args:
      hidden_layer_size: Internal state size
      output_size: Size of output layer
      dropout_rate: Dropout rate if dropout is applied
      use_time_distributed: Whether to apply network across time dimension
    Returns:
      Tuple of tensors for: (GRN output, GLU gate)
    """

        super(GRN, self).__init__(**kwargs)
        self.GRNhidden_layer_size = hidden_layer_size
        self.GRNoutput_size = output_size
        if self.GRNoutput_size is None:
            self.GRNusedoutput_size = self.GRNhidden_layer_size
        else:
            self.GRNusedoutput_size = self.GRNoutput_size

        self.GRNdropout_rate = dropout_rate
        self.GRNuse_time_distributed = use_time_distributed
        self.use_additionalcontext = use_additionalcontext

        if self.GRNoutput_size is not None:
            n1 = 'GRN' + 'Dense4' + GRNname
            if self.GRNuse_time_distributed:
                n2 = 'GRN' + 'TD4' + GRNname
                self.GRNDense4 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.GRNusedoutput_size, name=n1),
                                                                 name=n2)
            else:
                self.GRNDense4 = tf.keras.layers.Dense(self.GRNusedoutput_size, name=n1)

        n3 = 'GRNDense1' + GRNname
        self.GRNDense1 = TFTlinear_layer(
            self.GRNhidden_layer_size,
            activation=None,
            use_time_distributed=self.GRNuse_time_distributed,
            LLname=n3)

        if self.use_additionalcontext:
            n4 = 'GRNDense2' + GRNname
            self.GRNDense2 = TFTlinear_layer(
                self.GRNhidden_layer_size,
                activation=None,
                use_time_distributed=self.GRNuse_time_distributed,
                use_bias=False,
                LLname=n4)

        n5 = 'GRNAct' + GRNname
        self.GRNActivation = tf.keras.layers.Activation('elu', name=n5)

        n6 = 'GRNDense3' + GRNname
        self.GRNDense3 = TFTlinear_layer(
            self.GRNhidden_layer_size,
            activation=None,
            use_time_distributed=self.GRNuse_time_distributed,
            LLname=n6)

        n7 = 'GRNGLU' + GRNname
        self.GRNGLUplusskip = GLUplusskip(hidden_layer_size=self.GRNusedoutput_size, dropout_rate=self.GRNdropout_rate,
                                          use_time_distributed=self.GRNuse_time_distributed, GLUname=n7)

    # EAGER@tf.function
    def call(self, x, additional_context=None, return_gate=False, training=None):
        """Args:
        x: Network inputs
        additional_context: Additional context vector to use if relevant
        return_gate: Whether to return GLU gate for diagnostic purposes
    """

        # Setup skip connection of given size
        if self.GRNoutput_size is None:
            skip = x
        else:
            skip = self.GRNDense4(x)

        # Apply feedforward network
        hidden = self.GRNDense1(x)
        if additional_context is not None:
            if not self.use_additionalcontext:
                printexit('Inconsistent context in GRN')
            hidden = hidden + self.GRNDense2(additional_context)
        else:
            if self.use_additionalcontext:
                printexit('Inconsistent context in GRN')
        hidden = self.GRNActivation(hidden)
        hidden = self.GRNDense3(hidden)

        gating_layer, gate = self.GRNGLUplusskip(hidden, skip)
        if return_gate:
            return gating_layer, gate
        else:
            return gating_layer


"""###Process Static Variables"""


# Process Static inputs in TFT Style
# TFTScaledStaticInputs[Location,0...NumTrueStaticVariables]

class ProcessStaticInput(tf.keras.layers.Layer):

    def __init__(self, hidden_layer_size, dropout_rate, num_staticproperties, **kwargs):
        super(ProcessStaticInput, self).__init__(**kwargs)
        self.hidden_layer_size = hidden_layer_size
        self.num_staticproperties = num_staticproperties
        self.dropout_rate = dropout_rate
        print('num_staticproperties ' + str(num_staticproperties))

        n4 = 'ProcStaticFlat'
        self.Flatten = tf.keras.layers.Flatten(name=n4)
        n5 = 'ProcStaticG1'
        n7 = 'ProcStaticSoftmax'
        n8 = 'ProcStaticMul'
        self.StaticInputGRN1 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate,
                                   output_size=self.num_staticproperties, use_time_distributed=False, GRNname=n5)

        self.StaticInputGRN2 = []
        for i in range(0, self.num_staticproperties):
            n6 = 'ProcStaticG2-' + str(i)
            self.StaticInputGRN2.append(GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate,
                                            use_time_distributed=False, GRNname=n6))
        self.StaticInputsoftmax = tf.keras.layers.Activation('softmax', name=n7)
        self.StaticMultiply = tf.keras.layers.Multiply(name=n8)

    # EAGER@tf.function
    def call(self, static_inputs, training=None):

        # Embed Static Inputs
        num_static = static_inputs.shape[1]
        if num_static != self.num_staticproperties:
            printexit('Incorrect number of static variables')
        if num_static == 0:
            return None, None

        # static_inputs is [Batch, Static variable, TFTd_model] converted to
        # flatten is [Batch, Static variable*TFTd_model]
        flatten = self.Flatten(static_inputs)

        # Nonlinear transformation with gated residual network.
        mlp_outputs = self.StaticInputGRN1(flatten)
        sparse_weights = self.StaticInputsoftmax(mlp_outputs)
        sparse_weights = tf.expand_dims(sparse_weights, axis=-1)

        trans_emb_list = []
        for i in range(num_static):
            e = self.StaticInputGRN2[i](static_inputs[:, i:i + 1, :])
            trans_emb_list.append(e)
        transformed_embedding = tf.concat(trans_emb_list, axis=1)

        combined = self.StaticMultiply([sparse_weights, transformed_embedding])
        static_encoder = tf.math.reduce_sum(combined, axis=1)

        return static_encoder, sparse_weights


"""###Process Dynamic Variables"""


# Process Initial Dynamic inputs in TFT Style
# ScaledDynamicInputs[Location, time_steps,0...NumDynamicVariables]

class ProcessDynamicInput(tf.keras.layers.Layer):

    def __init__(self, hidden_layer_size, dropout_rate, NumDynamicVariables, PDIname='Default', **kwargs):
        super(ProcessDynamicInput, self).__init__(**kwargs)

        self.hidden_layer_size = hidden_layer_size
        self.NumDynamicVariables = NumDynamicVariables
        self.dropout_rate = dropout_rate
        print('NumDynamicVariables ' + str(NumDynamicVariables))

        n6 = PDIname + 'ProcDynG1'
        n8 = PDIname + 'ProcDynSoftmax'
        n9 = PDIname + 'ProcDynMul'
        self.DynamicVariablesGRN1 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate,
                                        output_size=self.NumDynamicVariables, use_additionalcontext=True,
                                        use_time_distributed=True, GRNname=n6)
        self.DynamicVariablesGRN2 = []
        for i in range(0, self.NumDynamicVariables):
            n7 = PDIname + 'ProcDynG2-' + str(i)
            self.DynamicVariablesGRN2.append(GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate,
                                                 use_additionalcontext=False, use_time_distributed=True, name=n7))
        self.DynamicVariablessoftmax = tf.keras.layers.Activation('softmax', name=n8)
        self.DynamicVariablesMultiply = tf.keras.layers.Multiply(name=n9)

    # EAGER@tf.function
    def call(self, dynamic_variables, static_context_variable_selection=None, training=None):

        # Add time window index to static context
        if static_context_variable_selection is None:
            self.expanded_static_context = None
        else:
            self.expanded_static_context = tf.expand_dims(static_context_variable_selection, axis=1)

        # Test Dynamic Variables
        num_dynamic = dynamic_variables.shape[-1]
        if num_dynamic != self.NumDynamicVariables:
            printexit('Incorrect number of Dynamic Inputs ' + str(num_dynamic) + ' ' + str(self.NumDynamicVariables))
        if num_dynamic == 0:
            return None, None, None

        # dynamic_variables is [Batch, Time window index, Dynamic variable, TFTd_model] converted to
        # flatten is [Batch, Time window index, Dynamic variable,*TFTd_model]
        _, time_steps, embedding_dimension, num_inputs = dynamic_variables.get_shape().as_list()
        flatten = tf.reshape(dynamic_variables, [-1, time_steps, embedding_dimension * num_inputs])

        # Nonlinear transformation with gated residual network.
        mlp_outputs, static_gate = self.DynamicVariablesGRN1(flatten, additional_context=self.expanded_static_context,
                                                             return_gate=True)
        sparse_weights = self.DynamicVariablessoftmax(mlp_outputs)
        sparse_weights = tf.expand_dims(sparse_weights, axis=2)

        trans_emb_list = []
        for i in range(num_dynamic):
            e = self.DynamicVariablesGRN2[i](dynamic_variables[Ellipsis, i], additional_context=None)
            trans_emb_list.append(e)
        transformed_embedding = tf.stack(trans_emb_list, axis=-1)

        combined = self.DynamicVariablesMultiply([sparse_weights, transformed_embedding])
        temporal_ctx = tf.math.reduce_sum(combined, axis=-1)

        return temporal_ctx, sparse_weights, static_gate


"""###TFT LSTM"""


class TFTLSTMLayer(tf.keras.Model):
    # Class for TFT Encoder multiple layer LSTM with possible FCN at start and end
    # All parameters defined externally

    def __init__(self, TFTLSTMSecondLayer, TFTLSTMThirdLayer,
                 TFTLSTMInitialMLP, TFTLSTMFinalMLP,
                 TFTnumber_LSTMnodes, TFTLSTMd_model,
                 TFTLSTMactivationvalue, TFTLSTMrecurrent_activation,
                 TFTLSTMdropout1, TFTLSTMrecurrent_dropout1,
                 TFTreturn_state, LSTMname='Default', **kwargs):
        super(TFTLSTMLayer, self).__init__(**kwargs)

        self.TFTLSTMSecondLayer = TFTLSTMSecondLayer
        self.TFTLSTMThirdLayer = TFTLSTMThirdLayer
        self.TFTLSTMInitialMLP = TFTLSTMInitialMLP
        self.TFTLSTMFinalMLP = TFTLSTMFinalMLP
        self.TFTLSTMd_model = TFTLSTMd_model
        self.TFTnumber_LSTMnodes = TFTnumber_LSTMnodes
        self.TFTLSTMactivationvalue = TFTLSTMactivationvalue
        self.TFTLSTMdropout1 = TFTLSTMdropout1
        self.TFTLSTMrecurrent_dropout1 = TFTLSTMrecurrent_dropout1
        self.TFTLSTMrecurrent_activation = TFTLSTMrecurrent_activation

        self.TFTLSTMreturn_state = TFTreturn_state
        self.first_return_state = self.TFTLSTMreturn_state
        if self.TFTLSTMSecondLayer:
            self.first_return_state = True
        self.second_return_state = self.TFTLSTMreturn_state
        if self.TFTLSTMThirdLayer:
            self.second_return_state = True
        self.third_return_state = self.TFTLSTMreturn_state

        if (self.TFTLSTMInitialMLP > 0):
            n1 = LSTMname + 'LSTMDense1'
            self.dense_1 = tf.keras.layers.Dense(self.TFTLSTMInitialMLP, activation=self.TFTLSTMactivationvalue, name=n1)
        n2 = LSTMname + 'LSTMLayer1'

        if myTFTTools.TFTuseCUDALSTM:
            self.LSTM_1 = tf.compat.v1.keras.layers.CuDNNLSTM(
                self.TFTnumber_LSTMnodes,
                return_sequences=True,
                return_state=self.first_return_state,
                stateful=False, name=n2)
        else:
            self.LSTM_1 = tf.keras.layers.LSTM(self.TFTnumber_LSTMnodes, recurrent_dropout=self.TFTLSTMrecurrent_dropout1,
                                               dropout=self.TFTLSTMdropout1,
                                               return_state=self.first_return_state, activation=self.TFTLSTMactivationvalue,
                                               return_sequences=True,
                                               recurrent_activation=self.TFTLSTMrecurrent_activation, name=n2)

        if self.TFTLSTMSecondLayer:
            n3 = LSTMname + 'LSTMLayer2'
            if myTFTTools.TFTuseCUDALSTM:
                self.LSTM_2 = tf.compat.v1.keras.layers.CuDNNLSTM(
                    self.TFTnumber_LSTMnodes,
                    return_sequences=True,
                    return_state=self.second_return_state,
                    stateful=False, name=n3)
            else:
                self.LSTM_2 = tf.keras.layers.LSTM(self.TFTnumber_LSTMnodes,
                                                   recurrent_dropout=self.TFTLSTMrecurrent_dropout1,
                                                   dropout=self.TFTLSTMdropout1,
                                                   return_state=self.second_return_state,
                                                   activation=self.TFTLSTMactivationvalue, return_sequences=True,
                                                   recurrent_activation=self.TFTLSTMrecurrent_activation, name=n3)
        if self.TFTLSTMThirdLayer:
            n4 = LSTMname + 'LSTMLayer3'
            if myTFTTools.TFTuseCUDALSTM:
                self.LSTM_3 = tf.compat.v1.keras.layers.CuDNNLSTM(
                    self.TFTnumber_LSTMnodes,
                    return_sequences=True,
                    return_state=self.third_return_state,
                    stateful=False, name=n4)
            else:
                self.LSTM_3 = tf.keras.layers.LSTM(self.TFTnumber_LSTMnodes,
                                                   recurrent_dropout=self.TFTLSTMrecurrent_dropout1,
                                                   dropout=self.TFTLSTMdropout1,
                                                   return_state=self.third_return_state,
                                                   activation=self.TFTLSTMactivationvalue,
                                                   return_sequences=True,
                                                   recurrent_activation=self.TFTLSTMrecurrent_activation, name=n4)
        if (self.TFTLSTMFinalMLP > 0):
            n5 = LSTMname + 'LSTMDense2'
            n6 = LSTMname + 'LSTMDense3'
            self.dense_2 = tf.keras.layers.Dense(self.TFTLSTMFinalMLP, activation=self.TFTLSTMactivationvalue, name=n5)
            self.dense_f = tf.keras.layers.Dense(self.TFTLSTMd_model, name=n6)

    # EAGER@tf.function
    def call(self, inputs, initial_state=None, training=None):
        if initial_state is None:
            printexit(' Missing context in LSTM ALL')
        if initial_state[0] is None:
            printexit(' Missing context in LSTM h')
        if initial_state[1] is None:
            printexit(' Missing context in LSTM c')
        returnstate_h = None
        returnstate_c = None
        if (self.TFTLSTMInitialMLP > 0):
            Runningdata = self.dense_1(inputs)
        else:
            Runningdata = inputs

        if self.first_return_state:
            Runningdata, returnstate_h, returnstate_c = self.LSTM_1(inputs, training=training, initial_state=initial_state)
            if returnstate_h is None:
                printexit('Missing context in LSTM returnstate_h')
            if returnstate_c is None:
                printexit('Missing context in LSTM returnstate_c')
        else:
            Runningdata = self.LSTM_1(inputs, training=training, initial_state=initial_state)

        if self.TFTLSTMSecondLayer:
            initial_statehc2 = None
            if self.first_return_state:
                initial_statehc2 = [returnstate_h, returnstate_c]
            if self.second_return_state:
                Runningdata, returnstate_h, returnstate_c = self.LSTM_2(Runningdata, training=training,
                                                                        initial_state=initial_statehc2)
                if returnstate_h is None:
                    printexit('Missing context in LSTM returnstate_h2')
                if returnstate_c is None:
                    printexit('Missing context in LSTM returnstate_c2')
            else:
                Runningdata = self.LSTM_2(Runningdata, training=training, initial_state=initial_statehc2)
        if self.TFTLSTMThirdLayer:
            initial_statehc3 = None
            if self.first_return_state:
                initial_statehc3 = [returnstate_h, returnstate_c]
            if self.third_return_state:
                Runningdata, returnstate_h, returnstate_c = self.LSTM_3(Runningdata, training=training,
                                                                        initial_state=initial_statehc3)
            else:
                Runningdata = self.LSTM_3(Runningdata, training=training, initial_state=initial_statehc3)

        if (self.TFTLSTMFinalMLP > 0):
            Runningdata = self.dense_2(Runningdata)
            Outputdata = self.dense_f(Runningdata)
        else:
            Outputdata = Runningdata

        if self.TFTLSTMreturn_state:
            return Outputdata, returnstate_h, returnstate_c
        else:
            return Outputdata

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])


"""###TFT Multihead Temporal Attention"""


# Attention Components.
# EAGER@tf.function
def TFTget_decoder_mask(self_attn_inputs):
    """Returns causal mask to apply for self-attention layer.

  Args:
    self_attn_inputs: Inputs to self attention layer to determine mask shape
  """
    len_s = tf.shape(self_attn_inputs)[1]
    bs = tf.shape(self_attn_inputs)[:1]
    mask = tf.math.cumsum(tf.eye(len_s, batch_shape=bs), 1)
    return mask


class TFTScaledDotProductAttention(tf.keras.Model):
    """Defines scaled dot product attention layer for TFT

  Attributes:
    dropout: Dropout rate to use
    activation: Normalisation function for scaled dot product attention (e.g.
      softmax by default)
  """

    def __init__(self, attn_dropout=0.0, SPDAname='Default', **kwargs):
        super(TFTScaledDotProductAttention, self).__init__(**kwargs)
        n1 = SPDAname + 'SPDADropout'
        n2 = SPDAname + 'SPDASoftmax'
        n3 = SPDAname + 'SPDAAdd'
        self.dropoutlayer = tf.keras.layers.Dropout(attn_dropout, name=n1)
        self.activationlayer = tf.keras.layers.Activation('softmax', name=n2)
        self.addlayer = tf.keras.layers.Add(name=n3)

    # EAGER@tf.function
    def call(self, q, k, v, mask):
        """Applies scaled dot product attention.

    Args:
      q: Queries
      k: Keys
      v: Values
      mask: Masking if required -- sets softmax to very large value

    Returns:
      Tuple of (layer outputs, attention weights)
    """
        temper = tf.sqrt(tf.cast(tf.shape(k)[-1], dtype='float32'))
        attn = tf.keras.layers.Lambda(lambda x: tf.keras.backend.batch_dot(x[0], x[1], axes=[2, 2]) / temper)(
            [q, k])  # shape=(batch, q, k)
        if mask is not None:
            mmask = tf.keras.layers.Lambda(lambda x: (-1e+9) * (1. - tf.cast(x, 'float32')))(mask)  # setting to infinity
            attn = self.addlayer([attn, mmask])
        attn = self.activationlayer(attn)
        attn = self.dropoutlayer(attn)
        output = tf.keras.layers.Lambda(lambda x: tf.keras.backend.batch_dot(x[0], x[1]))([attn, v])
        return output, attn


class TFTInterpretableMultiHeadAttention(tf.keras.Model):
    """Defines interpretable multi-head attention layer for time only.

  Attributes:
    n_head: Number of heads
    d_k: Key/query dimensionality per head
    d_v: Value dimensionality
    dropout: Dropout rate to apply
    qs_layers: List of queries across heads
    ks_layers: List of keys across heads
    vs_layers: List of values across heads
    attention: Scaled dot product attention layer
    w_o: Output weight matrix to project internal state to the original TFT
      state size
  """

    # EAGER@tf.function
    def __init__(self, n_head, d_model, dropout, MHAname='Default', **kwargs):
        super(TFTInterpretableMultiHeadAttention, self).__init__(**kwargs)
        """Initialises layer.

    Args:
      n_head: Number of heads
      d_model: TFT state dimensionality
      dropout: Dropout discard rate
    """

        self.n_head = n_head
        self.d_k = self.d_v = d_model // n_head
        self.d_model = d_model
        self.dropout = dropout

        self.qs_layers = []
        self.ks_layers = []
        self.vs_layers = []

        # Use same value layer to facilitate interp
        n3 = MHAname + 'MHAV'
        vs_layer = tf.keras.layers.Dense(self.d_v, use_bias=False, name=n3)

        self.Dropoutlayer1 = []
        for i_head in range(n_head):
            n1 = MHAname + 'MHAQ' + str(i)
            n2 = MHAname + 'MHAK' + str(i)
            self.qs_layers.append(tf.keras.layers.Dense(self.d_k, use_bias=False, name=n1))
            self.ks_layers.append(tf.keras.layers.Dense(self.d_k, use_bias=False, name=n2))
            self.vs_layers.append(vs_layer)  # use same vs_layer
            n4 = MHAname + 'Dropout1-' + str(i)
            self.Dropoutlayer1.append(tf.keras.layers.Dropout(self.dropout, name=n4))

        self.attention = TFTScaledDotProductAttention(SPDAname=MHAname)

        n5 = MHAname + 'Dropout2'
        n6 = MHAname + 'w_olayer'
        self.Dropoutlayer2 = tf.keras.layers.Dropout(self.dropout, name=n5)
        self.w_olayer = tf.keras.layers.Dense(d_model, use_bias=False, name=n6)

    # EAGER@tf.function
    def call(self, q, k, v, mask=None):
        """Applies interpretable multihead attention.

    Using T to denote the number of past + future time steps fed into the transformer.

    Args:
      q: Query tensor of shape=(?, T, d_model)
      k: Key of shape=(?, T, d_model)
      v: Values of shape=(?, T, d_model)
      mask: Masking if required with shape=(?, T, T)

    Returns:
      Tuple of (layer outputs, attention weights)
    """

        heads = []
        attns = []
        for i in range(self.n_head):
            qs = self.qs_layers[i](q)
            ks = self.ks_layers[i](k)
            vs = self.vs_layers[i](v)
            head, attn = self.attention(qs, ks, vs, mask)
            head_dropout = self.Dropoutlayer1[i](head)
            heads.append(head_dropout)
            attns.append(attn)

        head = tf.stack(heads) if self.n_head > 1 else heads[0]
        attn = tf.stack(attns)

        outputs = tf.math.reduce_mean(head, axis=0) if self.n_head > 1 else head
        outputs = self.w_olayer(outputs)
        outputs = self.Dropoutlayer2(outputs)  # output dropout

        return outputs, attn


"""###TFTFullNetwork"""


class TFTFullNetwork(tf.keras.Model):

    def __init__(self, **kwargs):
        super(TFTFullNetwork, self).__init__(**kwargs)

        # XXX check TFTSeq TFTNloc UniqueLocations
        self.TFTSeq = 0
        self.TFTNloc = 0
        self.UniqueLocations = []
        self.hidden_layer_size = myTFTTools.hidden_layer_size
        self.dropout_rate = myTFTTools.dropout_rate
        self.num_heads = myTFTTools.num_heads

        # New parameters in this TFT version
        self.num_static = len(myTFTTools._static_input_loc)
        self.num_categorical_variables = len(myTFTTools.category_counts)
        self.NumDynamicHistoryVariables = myTFTTools.input_size - self.num_static  # Note Future (targets) are also in history
        self.num_regular_variables = myTFTTools.input_size - self.num_categorical_variables

        self.NumDynamicFutureVariables = 0
        line = 'Future DF Locations '
        for i in myTFTTools._known_regular_input_idx:
            if i not in myTFTTools._static_input_loc:
                self.NumDynamicFutureVariables += 1
                line += str(i) + ' '
        for i in myTFTTools._known_categorical_input_idx:
            if i + self.num_regular_variables not in myTFTTools._static_input_loc:
                self.NumDynamicFutureVariables += 1
                line += 'CAT ' + str(i) + ' '
        print(line)

        # Embed Categorical Variables
        line = 'CATEGORICAL EMBEDDINGS '
        self.CatVariablesembeddings = []
        for i in range(0, self.num_categorical_variables):
            numcat = self.category_counts[i]
            line += str(i) + ' CT ' + str(numcat) + ' '
            n1 = 'CatEmbed-' + str(i)
            n2 = n1 + 'Input ' + str(numcat)
            n3 = n1 + 'Map'
            n1 = n1 + 'Seq'
            embedding = tf.keras.Sequential([
                tf.keras.layers.InputLayer([myTFTTools.time_steps], name=n2),
                tf.keras.layers.Embedding(
                    numcat,
                    self.hidden_layer_size,
                    input_length=myTFTTools.time_steps,
                    dtype=tf.float32, name=n3)
            ], name=n1)
            self.CatVariablesembeddings.append(embedding)
        print(line)

        # Embed Static Variables
        numstatic = 0
        line = 'Static '
        self.StaticInitialembeddings = []
        for i in range(self.num_regular_variables):
            if i in myTFTTools._static_input_loc:
                n1 = 'StaticRegEmbed-' + str(numstatic)
                embedding = tf.keras.layers.Dense(self.hidden_layer_size, name=n1)
                line += str(i) + ' '
                self.StaticInitialembeddings.append(embedding)
                numstatic += 1
        print(line)

        # Embed Targets _input_obs_loc - also included as part of Observed inputs
        self.convert_obs_inputs = []
        num_obs_inputs = 0
        line = 'Observed Inputs '
        for i in myTFTTools._input_obs_loc:
            n1 = 'OBSINPEmbed-Dense-' + str(num_obs_inputs)
            n2 = 'OBSINPEmbed-Time-' + str(num_obs_inputs)
            embedding = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.hidden_layer_size, name=n1), name=n2)
            num_obs_inputs += 1
            self.convert_obs_inputs.append(embedding)
            line += str(i) + ' '
        print(line)

        # Embed unknown_inputs which are elsewhere called observed inputs
        self.convert_unknown_inputs = []
        num_unknown_inputs = 0
        line = ' Unknown Inputs '
        for i in range(self.num_regular_variables):
            if i not in myTFTTools._known_regular_input_idx and i not in myTFTTools._input_obs_loc:
                line += str(i) + ' '
                n1 = 'UNKINPEmbed-Dense-' + str(num_unknown_inputs)
                n2 = 'UNKINPEmbed-Time-' + str(num_unknown_inputs)
                embedding = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.hidden_layer_size, name=n1), name=n2)
                num_unknown_inputs += 1
                self.convert_unknown_inputs.append(embedding)
        print(line)

        # Embed Known Inputs
        self.convert_known_regular_inputs = []
        line = 'Known Inputs '
        num_known_regular_inputs = 0
        for i in myTFTTools._known_regular_input_idx:
            if i not in myTFTTools._static_input_loc:
                n1 = 'KnownINPEmbed-Dense-' + str(num_known_regular_inputs)
                n2 = 'KnownINPEmbed-Time-' + str(num_known_regular_inputs)
                embedding = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.hidden_layer_size, name=n1), name=n2)
                num_known_regular_inputs += 1
                self.convert_known_regular_inputs.append(embedding)
                line += str(i) + ' '
        print(line)

        # Select Input Static Variables
        self.ControlProcessStaticInput = ProcessStaticInput(self.hidden_layer_size, self.dropout_rate, self.num_static)

        self.StaticGRN1 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False,
                              GRNname='Control1')
        self.StaticGRN2 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False,
                              GRNname='Control2')
        self.StaticGRN3 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False,
                              GRNname='Control3')
        self.StaticGRN4 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=False,
                              GRNname='Control4')

        # Select Input Dynamic Variables
        self.ControlProcessDynamicInput1 = ProcessDynamicInput(self.hidden_layer_size, self.dropout_rate,
                                                               self.NumDynamicHistoryVariables, PDIname='Control1')

        if myTFTTools.TFTdefaultLSTM:
            self.TFTLSTMEncoder = tf.compat.v1.keras.layers.CuDNNLSTM(
                self.hidden_layer_size,
                return_sequences=True,
                return_state=True,
                stateful=False,
            )
            self.TFTLSTMDecoder = tf.compat.v1.keras.layers.CuDNNLSTM(
                self.hidden_layer_size,
                return_sequences=True,
                return_state=False,
                stateful=False,
            )
        else:
            self.TFTLSTMEncoder = TFTLSTMLayer(myTFTTools.TFTLSTMEncoderSecondLayer, myTFTTools.TFTLSTMEncoderThirdLayer,
                                               myTFTTools.TFTLSTMEncoderInitialMLP, myTFTTools.TFTLSTMEncoderFinalMLP,
                                               myTFTTools.number_LSTMnodes, self.hidden_layer_size,
                                               myTFTTools.TFTLSTMEncoderactivationvalue,
                                               myTFTTools.TFTLSTMEncoderrecurrent_activation,
                                               myTFTTools.TFTLSTMEncoderdropout1,
                                               myTFTTools.TFTLSTMEncoderrecurrent_dropout1, TFTreturn_state=True,
                                               LSTMname='ControlEncoder')
            self.TFTLSTMDecoder = TFTLSTMLayer(myTFTTools.TFTLSTMDecoderSecondLayer, myTFTTools.TFTLSTMDecoderThirdLayer,
                                               myTFTTools.TFTLSTMDecoderInitialMLP, myTFTTools.TFTLSTMDecoderFinalMLP,
                                               myTFTTools.number_LSTMnodes, self.hidden_layer_size,
                                               myTFTTools.TFTLSTMDecoderactivationvalue,
                                               myTFTTools.TFTLSTMDecoderrecurrent_activation,
                                               myTFTTools.TFTLSTMDecoderdropout1,
                                               myTFTTools.TFTLSTMDecoderrecurrent_dropout1, TFTreturn_state=False,
                                               LSTMname='ControlDecoder')

        self.TFTFullLSTMGLUplusskip = GLUplusskip(self.hidden_layer_size, self.dropout_rate, activation=None,
                                                  use_time_distributed=True, GLUname='ControlLSTM')
        self.TemporalGRN5 = GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_additionalcontext=True,
                                use_time_distributed=True, GRNname='Control5')

        self.ControlProcessDynamicInput2 = ProcessDynamicInput(self.hidden_layer_size, self.dropout_rate,
                                                               self.NumDynamicFutureVariables, PDIname='Control2')

        # Decoder self attention
        self.TFTself_attn_layer = TFTInterpretableMultiHeadAttention(
            self.num_heads, self.hidden_layer_size, self.dropout_rate)

        # Set up for final prediction
        self.FinalGLUplusskip2 = []
        self.FinalGLUplusskip3 = []
        self.FinalGRN6 = []
        for FinalGatingLoop in range(0, myTFTTools.FinalLoopSize):
            self.FinalGLUplusskip2.append(GLUplusskip(self.hidden_layer_size, self.dropout_rate, activation=None,
                                                      use_time_distributed=True,
                                                      GLUname='ControlFinal2-' + str(FinalGatingLoop)))
            self.FinalGLUplusskip3.append(GLUplusskip(self.hidden_layer_size, self.dropout_rate, activation=None,
                                                      use_time_distributed=True,
                                                      GLUname='ControlFinal3-' + str(FinalGatingLoop)))
            self.FinalGRN6.append(GRN(self.hidden_layer_size, dropout_rate=self.dropout_rate, use_time_distributed=True,
                                      GRNname='Control6-' + str(FinalGatingLoop)))

        # Final Processing
        if myTFTTools.TFTLSTMFinalMLP > 0:
            self.FinalApplyMLP = apply_mlp(myTFTTools.TFTLSTMFinalMLP,
                                           output_size=myTFTTools.output_size * myTFTTools.NumberQuantiles,
                                           output_activation=None, hidden_activation='selu',
                                           use_time_distributed=True, MLPname='Predict')


        else:
            if myTFTTools.FinalLoopSize == 1:
                n1 = 'FinalTD'
                n2 = 'FinalDense'
                self.FinalLayer = tf.keras.layers.TimeDistributed(
                    tf.keras.layers.Dense(myTFTTools.output_size * myTFTTools.NumberQuantiles, name=n2), name=n1)
            else:
                self.FinalStack = []
                localloopsize = myTFTTools.output_size * myTFTTools.NumberQuantiles
                for localloop in range(0, localloopsize):
                    self.FinalStack.append(tf.keras.layers.Dense(1))

    # Called with each batch as input
    # EAGER@tf.function
    def call(self, all_inputs, ignoredtime, ignoredidentifiers, training=None):
        # ignoredtime, ignoredidentifiers not used

        time_steps = myTFTTools.time_steps
        combined_input_size = myTFTTools.input_size
        encoder_steps = myTFTTools.num_encoder_steps

        # Sanity checks on inputs
        for InputIndex in myTFTTools._known_regular_input_idx:
            if InputIndex in myTFTTools._input_obs_loc:
                printexit('Observation cannot be known a priori!' + str(InputIndex))
        for InputIndex in myTFTTools._input_obs_loc:
            if InputIndex in myTFTTools._static_input_loc:
                printexit('Observation cannot be static!' + str(InputIndex))

        Sizefrominputs = all_inputs.get_shape().as_list()[-1]
        if Sizefrominputs != myTFTTools.input_size:
            raise printexit('Illegal number of inputs! Inputs observed={}, expected={}'.format(
                Sizefrominputs, myTFTTools.input_size))

        regular_inputs, categorical_inputs = all_inputs[:, :, :self.num_regular_variables], all_inputs[:, :,
                                                                                            self.num_regular_variables:]

        # Embed categories of all categorical variables -- static and Dynamic
        # categorical variables MUST be at end and reordering done in preprocessing (definition of train valid test)
        # XXX add reordering
        categoricalembedded_inputs = []
        for i in range(0, self.num_categorical_variables):
            categoricalembedded_inputs.append(CatVariablesembeddings[i](categorical_inputs[Ellipsis, i]))

        # Complete Static Variables -- whether categorical or regular -- they are essentially thought of as known inputs
        if myTFTTools._static_input_loc:
            static_inputs = []
            numstatic = 0
            for i in range(self.num_regular_variables):
                if i in myTFTTools._static_input_loc:
                    static_inputs.append(self.StaticInitialembeddings[numstatic](regular_inputs[:, 0, i:i + 1]))
                    numstatic += 1
            static_inputs = static_inputs + [self.categoricalembedded_inputs[i][:, 0, :]
                                             for i in range(self.num_categorical_variables)
                                             if i + self.num_regular_variables in myTFTTools._static_input_loc]
            static_inputs = tf.stack(static_inputs, axis=1)
        else:
            static_inputs = None

        # Targets misleadingly labelled obs_inputs. They are used as targets to predict and as observed inputs
        obs_inputs = []
        num_obs_inputs = 0
        for i in myTFTTools._input_obs_loc:
            e = self.convert_obs_inputs[num_obs_inputs](regular_inputs[Ellipsis, i:i + 1])
            num_obs_inputs += 1
            obs_inputs.append(e)
        obs_inputs = tf.stack(obs_inputs, axis=-1)

        # Categorical Unknown inputs. Unknown + Target is complete Observed InputCategory
        categorical_unknown_inputs = []
        for i in range(self.num_categorical_variables):
            if i not in myTFTTools._known_categorical_input_idx and i + self.num_regular_variables not in myTFTTools._input_obs_loc:
                e = self.categoricalembedded_inputs[i]
                categorical_unknown_inputs.append(e)

        # Regular Unknown inputs
        unknown_inputs = []
        num_unknown_inputs = 0
        for i in range(self.num_regular_variables):
            if i not in myTFTTools._known_regular_input_idx and i not in myTFTTools._input_obs_loc:
                e = self.convert_unknown_inputs[num_unknown_inputs](regular_inputs[Ellipsis, i:i + 1])
                num_unknown_inputs += 1
                unknown_inputs.append(e)

        # Add in categorical_unknown_inputs into unknown_inputs
        if unknown_inputs + categorical_unknown_inputs:
            unknown_inputs = tf.stack(unknown_inputs + categorical_unknown_inputs, axis=-1)
        else:
            unknown_inputs = None

        # A priori known inputs
        known_regular_inputs = []
        num_known_regular_inputs = 0
        for i in myTFTTools._known_regular_input_idx:
            if i not in myTFTTools._static_input_loc:
                e = self.convert_known_regular_inputs[num_known_regular_inputs](regular_inputs[Ellipsis, i:i + 1])
                num_known_regular_inputs += 1
                known_regular_inputs.append(e)

        known_categorical_inputs = []
        for i in myTFTTools._known_categorical_input_idx:
            if i + self.num_regular_variables not in myTFTTools._static_input_loc:
                e = categoricalembedded_inputs[i]
                known_categorical_inputs.append(e)

        known_combined_layer = tf.stack(known_regular_inputs + known_categorical_inputs, axis=-1)

        #  Now we know unknown_inputs, known_combined_layer, obs_inputs, static_inputs

        # Identify known and observed historical_inputs.
        if unknown_inputs is not None:
            historical_inputs = tf.concat([
                unknown_inputs[:, :encoder_steps, :],
                known_combined_layer[:, :encoder_steps, :],
                obs_inputs[:, :encoder_steps, :]
            ], axis=-1)
        else:
            historical_inputs = tf.concat([
                known_combined_layer[:, :encoder_steps, :],
                obs_inputs[:, :encoder_steps, :]
            ], axis=-1)

        # Identify known future inputs.
        future_inputs = known_combined_layer[:, encoder_steps:, :]

        # Process Static Variables
        static_encoder, static_weights = self.ControlProcessStaticInput(static_inputs)
        static_context_variable_selection = self.StaticGRN1(static_encoder)
        static_context_enrichment = self.StaticGRN2(static_encoder)
        static_context_state_h = self.StaticGRN3(static_encoder)
        static_context_state_c = self.StaticGRN4(static_encoder)
        # End set up of static variables

        historical_features, historical_flags, _ = self.ControlProcessDynamicInput1(historical_inputs,
                                                                                    static_context_variable_selection=static_context_variable_selection)

        history_lstm, state_h, state_c = self.TFTLSTMEncoder(historical_features,
                                                             initial_state=[static_context_state_h, static_context_state_c])

        input_embeddings = historical_features
        lstm_layer = history_lstm

        future_features, future_flags, _ = self.ControlProcessDynamicInput2(future_inputs,
                                                                            static_context_variable_selection=static_context_variable_selection)

        future_lstm = self.TFTLSTMDecoder(future_features, initial_state=[state_h, state_c])
        input_embeddings = tf.concat([historical_features, future_features], axis=1)
        lstm_layer = tf.concat([history_lstm, future_lstm], axis=1)

        temporal_feature_layer, _ = self.TFTFullLSTMGLUplusskip(lstm_layer, input_embeddings)
        expanded_static_context = tf.expand_dims(static_context_enrichment, axis=1)  # Add fake time axis
        enriched = self.TemporalGRN5(temporal_feature_layer, additional_context=expanded_static_context, return_gate=False)

        # Calculate attention
        # mask does not use "time" as implicit in order of entries in window
        mask = TFTget_decoder_mask(enriched)
        x, self_att = self.TFTself_attn_layer(enriched, enriched, enriched, mask=mask)

        if myTFTTools.FinalLoopSize > 1:
            StackLayers = []

        for FinalGatingLoop in range(0, myTFTTools.FinalLoopSize):
            x, _ = self.FinalGLUplusskip2[FinalGatingLoop](x, enriched)

            # Nonlinear processing on outputs
            decoder = self.FinalGRN6[FinalGatingLoop](x)

            # Final skip connection
            transformer_layer, _ = self.FinalGLUplusskip3[FinalGatingLoop](decoder, temporal_feature_layer)

            if myTFTTools.FinalLoopSize > 1:
                StackLayers.append(transformer_layer)
        # End Loop over FinalGatingLoop

        if myTFTTools.FinalLoopSize > 1:
            transformer_layer = tf.stack(StackLayers, axis=-1)

        # Attention components for explainability IGNORED
        attention_components = {
            # Temporal attention weights
            'decoder_self_attn': self_att,
            # Static variable selection weights
            'static_flags': static_weights[Ellipsis, 0],
            # Variable selection weights of past inputs
            'historical_flags': historical_flags[Ellipsis, 0, :],
            # Variable selection weights of future inputs
            'future_flags': future_flags[Ellipsis, 0, :]
        }
        self._attention_components = attention_components

        # Original split procerssing here and did
        # return transformer_layer, all_inputs, attention_components

        if myTFTTools.TFTLSTMFinalMLP > 0:
            outputs = self.FinalApplyMLP(transformer_layer[Ellipsis, encoder_steps:, :])

        else:
            if myTFTTools.FinalLoopSize == 1:
                outputs = self.FinalLayer(transformer_layer[Ellipsis, encoder_steps:, :])
            else:
                outputstack = []
                localloopsize = myTFTTools.output_size * myTFTTools.NumberQuantiles
                for localloop in range(0, localloopsize):
                    localoutput = self.FinalStack[localloop](transformer_layer[Ellipsis, encoder_steps:, :, localloop])
                    outputstack.append(localoutput)
                outputs = tf.stack(outputstack, axis=-2)
                outputs = tf.squeeze(outputs, axis=-1)

        return outputs


"""##TFT Run & Output

###TFT Output
"""


def TFTTestpredict(custommodel, datacollection):
    """Computes predictions for a given input dataset.

  Args:
    df: Input dataframe
    return_targets: Whether to also return outputs aligned with predictions to
      faciliate evaluation

  Returns:
    Input dataframe or tuple of (input dataframe, algined output dataframe).
  """
    inputs = datacollection['inputs']
    time = datacollection['time']
    identifier = datacollection['identifier']
    outputs = datacollection['outputs']
    print(inputs.shape)
    print(time.shape)
    print(identifier.shape)
    print(outputs.shape)

    combined = None
    myTFTTools.PrintTitle('Start TFTTestpredict')
    OuterBatchDimension = inputs.shape[0]
    batchsize = myTFTTools.maxibatch_size
    numberoftestbatches = math.ceil(OuterBatchDimension / batchsize)
    count1 = 0
    for countbatches in range(0, numberoftestbatches):
        count2 = min(OuterBatchDimension, count1 + batchsize)
        if count2 <= count1:
            continue
        samples = np.arange(count1, count2)
        count1 += batchsize
        X_test = inputs[samples, Ellipsis]

        time_test = []
        id_test = []
        Numinbatch = X_test.shape[0]
        if myTFTTools.TFTSymbolicWindows:
            X_test = X_test.numpy()
            X_test = np.reshape(X_test, Numinbatch)
            iseqarray = np.right_shift(X_test, 16)
            ilocarray = np.bitwise_and(X_test, 0b1111111111111111)
            X_testFull = list()
            for iloc in range(0, Numinbatch):
                X_testFull.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
            X_test = np.array(X_testFull)

        batchprediction = custommodel(X_test, time_test, id_test, training=False).numpy()
        if combined is None:
            combined = batchprediction
        else:
            combined = np.concatenate((combined, batchprediction), axis=0)

    # Extract predictions for each quantile into different entries
    process_map = {
        qname:
            combined[Ellipsis, i * myTFTTools.output_size:(i + 1) * myTFTTools.output_size]
        for i, qname in enumerate(myTFTTools.Quantilenames)
    }
    process_map['targets'] = outputs
    myTFTTools.PrintTitle('End TFTTestpredict')

    def format_outputs(prediction):
        """Returns formatted dataframes for prediction."""

        reshapedprediction = prediction.reshape(prediction.shape[0], -1)
        flat_prediction = pd.DataFrame(
            reshapedprediction[:, :],
            columns=[
                't+{}-Obs{}'.format(i, j)
                for i in range(myTFTTools.time_steps - myTFTTools.num_encoder_steps)
                for j in range(0, myTFTTools.output_size)
            ])
        cols = list(flat_prediction.columns)
        flat_prediction['forecast_time'] = time[:,
                                           myTFTTools.num_encoder_steps - 1, 0]
        flat_prediction['identifier'] = identifier[:, 0, 0]

        # Arrange in order
        return flat_prediction[['forecast_time', 'identifier'] + cols]

    return {k: format_outputs(process_map[k]) for k in process_map}

    # Simple Plot of Loss from history


def finalizeTFTDL(ActualModel, recordtrainloss, recordvalloss, validationfrac, test_datacollection, modelflag, LabelFit=''):
    # Ouput Loss v Epoch
    histlen = len(recordtrainloss)
    trainloss = recordtrainloss[histlen - 1]
    plt.rcParams["figure.figsize"] = [8, 6]
    plt.plot(recordtrainloss)
    if (validationfrac > 0.001) and len(recordvalloss) > 0:
        valloss = recordvalloss[histlen - 1]
        plt.plot(recordvalloss)
    else:
        valloss = 0.0

    current_time = timenow()
    print(startbold + startred + current_time + ' ' + RunName + ' finalizeDL ' + RunComment + resetfonts)
    plt.title(LabelFit + ' ' + RunName + ' model loss ' + str(round(trainloss, 7)) + ' Val ' + str(round(valloss, 7)))
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.yscale("log")
    plt.grid(True)
    plt.legend(['train', 'val'], loc='upper left')
    plt.show()

    # Setup TFT
    if modelflag == 2:
        global SkipDL2F, IncreaseNloc_sample, DecreaseNloc_sample
        SkipDL2F = True
        IncreaseNloc_sample = 1
        DecreaseNloc_sample = 1
        TFToutput_map = TFTTestpredict(ActualModel, test_datacollection)
        VisualizeTFT(ActualModel, TFToutput_map)
    else:
        printexit("unsupported model " + str(modelflag))


"""###TFTcustommodel

Control Full TFT Network
"""


class TFTcustommodel(tf.keras.Model):
    def __init__(self, **kwargs):
        super(TFTcustommodel, self).__init__(**kwargs)
        self.myTFTFullNetwork = TFTFullNetwork()

    def compile(self, optimizer, loss):
        super(TFTcustommodel, self).compile()
        if optimizer == 'adam':
            self.optimizer = tf.keras.optimizers.Adam(learning_rate=myTFTTools.learning_rate)
        else:
            self.optimizer = tf.keras.optimizers.get(optimizer)
        Dictopt = self.optimizer.get_config()
        print(startbold + startred + 'Optimizer ' + resetfonts, Dictopt)

        if loss == 'MSE' or loss == 'mse':
            self.loss_object = tf.keras.losses.MeanSquaredError()
        elif loss == 'MAE' or loss == 'mae':
            self.loss_object = tf.keras.losses.MeanAbsoluteError()
        else:
            self.loss_object = loss
        self.loss_tracker = tf.keras.metrics.Mean(name="loss")
        self.loss_tracker.reset_states()
        self.val_tracker = tf.keras.metrics.Mean(name="val")
        self.val_tracker.reset_states()
        return

    def resetmetrics(self):
        self.loss_tracker.reset_states()
        self.val_tracker.reset_states()
        return

    def build_graph(self, shapes):
        input = tf.keras.layers.Input(shape=shapes, name="Input")
        return tf.keras.models.Model(inputs=[input], outputs=[self.call(input)])

    @tf.function
    def train_step(self, data):
        if len(data) == 5:
            X_train, y_train, sw_train, time_train, id_train = data
        else:
            X_train, y_train = data
            sw_train = []
            time_train = []
            id_train = []

        with tf.GradientTape() as tape:
            predictions = self(X_train, time_train, id_train, training=True)
            #      loss = self.loss_object(y_train, predictions, sw_train)
            loss = self.loss_object(y_train, predictions)

        gradients = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))
        self.loss_tracker.update_state(loss)
        return {"loss": self.loss_tracker.result()}

    @tf.function
    def test_step(self, data):
        if len(data) == 5:
            X_val, y_val, sw_val, time_val, id_val = data
        else:
            X_val, y_val = data
            sw_val = []
            time_train = []
            id_train = []

        predictions = self(X_val, time_val, id_val, training=False)
        #    loss = self.loss_object(y_val, predictions, sw_val)
        loss = self.loss_object(y_val, predictions)

        self.val_tracker.update_state(loss)
        return {"val_loss": self.val_tracker.result()}

    # @tf.function
    def call(self, inputs, time, identifier, training=None):
        predictions = self.myTFTFullNetwork(inputs, time, identifier, training=training)
        return predictions


"""### TFT Overall Batch Training

* TIME not set explicitly
* Weights allowed or not
* Assumes TFTFullNetwork is full Network
"""


def RunTFTCustomVersion():
    myTFTTools.PrintTitle("Start Tensorflow")

    global AnyOldValidation
    UseClassweights = False
    usecustomfit = True
    AnyOldValidation = myTFTTools.validation

    garbagecollectcall = 0

    # XXX InitializeDLforTimeSeries setSeparateDLinput NOT USED
    tf.keras.backend.set_floatx('float32')
    # tf.compat.v1.disable_eager_execution()
    myTFTcustommodel = TFTcustommodel(name='myTFTcustommodel')
    lossobject = 'MSE'
    if myTFTTools.lossflag == 8:
        lossobject = custom_lossGCF1
    if myTFTTools.lossflag == 11:
        lossobject = 'MAE'
    if myTFTTools.lossflag == 12:
        lossobject = tf.keras.losses.Huber(delta=myTFTTools.HuberLosscut)
    myTFTcustommodel.compile(loss=lossobject, optimizer=myTFTTools.optimizer)

    recordtrainloss = []
    recordvalloss = []
    tfrecordtrainloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfrecordvalloss = tf.Variable([], shape=tf.TensorShape(None), trainable=False)
    tfepochstep = tf.Variable(0, trainable=False)

    # Set up checkpoints to read or write
    mycheckpoint = tf.train.Checkpoint(optimizer=myTFTcustommodel.optimizer,
                                       model=myTFTcustommodel, tfepochstep=tf.Variable(0),
                                       tfrecordtrainloss=tfrecordtrainloss, tfrecordvalloss=tfrecordvalloss)

    # This restores back up
    if Restorefromcheckpoint:
        save_path = inputCHECKPOINTDIR + inputRunName + inputCheckpointpostfix
        mycheckpoint.restore(save_path=save_path).expect_partial()
        tfepochstep = mycheckpoint.tfepochstep
        recordvalloss = mycheckpoint.tfrecordvalloss.numpy().tolist()
        recordtrainloss = mycheckpoint.tfrecordtrainloss.numpy().tolist()
        trainlen = len(recordtrainloss)
        extrainfo = ''
        vallen = len(recordvalloss)
        SavedTrainLoss = recordtrainloss[trainlen - 1]
        SavedValLoss = 0.0
        if vallen > 0:
            extrainfo = ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
            SavedValLoss = recordvalloss[vallen - 1]
        print(startbold + 'Network restored from ' + save_path + '\nLoss ' + str(round(recordtrainloss[trainlen - 1], 7))
              + extrainfo + ' Epochs ' + str(tfepochstep.numpy()) + resetfonts)
        TFTTrainingMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=True,
                                              Restored_path=save_path, ValidationFraction=AnyOldValidation,
                                              SavedTrainLoss=SavedTrainLoss,
                                              SavedValLoss=SavedValLoss)
    else:
        TFTTrainingMonitor.SetCheckpointParms(mycheckpoint, CHECKPOINTDIR, RunName=RunName, Restoredcheckpoint=False,
                                              ValidationFraction=AnyOldValidation)

    # This just does analysis
    if AnalysisOnly:
        if OutputNetworkPictures:
            outputpicture1 = APPLDIR + '/Outputs/Model_' + RunName + '1.png'
            outputpicture2 = APPLDIR + '/Outputs/Model_' + RunName + '2.png'
            tf.keras.utils.plot_model(myTFTcustommodel.build_graph([Tseq, NpropperseqTOT]),
                                      show_shapes=True, to_file=outputpicture1,
                                      show_dtype=True,
                                      expand_nested=True)
            tf.keras.utils.plot_model(myTFTcustommodel.myTFTFullNetwork.build_graph([Tseq, NpropperseqTOT]),
                                      show_shapes=True, to_file=outputpicture2,
                                      show_dtype=True,
                                      expand_nested=True)
        if myTFTTools.TFTSymbolicWindows:
            finalizeTFTDL(myTFTcustommodel, recordtrainloss, recordvalloss, AnyOldValidation, TFTtest_datacollection, 2,
                          LabelFit='Custom TFT Fit')
        else:
            finalizeTFTDL(myTFTcustommodel, recordtrainloss, recordvalloss, AnyOldValidation, TFTtest_datacollection, 2,
                          LabelFit='Custom TFT Fit')
            return

    # Initialize progress bars
    epochsize = len(TFTtrain_datacollection["inputs"])
    if AnyOldValidation > 0.001:
        epochsize += len(TFTval_datacollection["inputs"])

    pbar = notebook.trange(myTFTTools.num_epochs, desc='Training loop', unit='epoch')
    bbar = notebook.trange(epochsize, desc='Batch    loop', unit='sample')

    train_epoch = 0.0  # Training Loss this epoch
    val_epoch = 0.0  # Validation Loss this epoch

    Ctime1 = 0.0
    Ctime2 = 0.0
    Ctime3 = 0.0
    GarbageCollect = True

    #  train_dataset = tf.data.Dataset.from_tensor_slices((TFTtrain_datacollection['inputs'],TFTtrain_datacollection['outputs'],TFTtrain_datacollection['active_entries']))
    #  val_dataset = tf.data.Dataset.from_tensor_slices((TFTval_datacollection['inputs'],TFTval_datacollection['outputs'],TFTval_datacollection['active_entries']))
    OuterTrainBatchDimension = TFTtrain_datacollection['inputs'].shape[0]
    OuterValBatchDimension = TFTval_datacollection['inputs'].shape[0]
    print('Samples to batch Train ' + str(OuterTrainBatchDimension) + ' Val ' + str(OuterValBatchDimension))
    #  train_dataset = train_dataset.shuffle(buffer_size = OuterBatchDimension, reshuffle_each_iteration=True).batch(myTFTTools.minibatch_size)
    #  val_dataset = val_dataset.batch(myTFTTools.maxibatch_size)
    np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))

    trainbatchsize = myTFTTools.minibatch_size
    valbatchsize = myTFTTools.maxibatch_size
    numberoftrainbatches = math.ceil(OuterTrainBatchDimension / trainbatchsize)
    numberofvalbatches = math.ceil(OuterValBatchDimension / valbatchsize)

    for e in pbar:
        myTFTcustommodel.resetmetrics()
        train_lossoverbatch = []
        val_lossoverbatch = []

        if batchperepoch:
            qbar = notebook.trange(epochsize, desc='Batch loop epoch ' + str(e))

        #   for batch, (X_train, y_train, sw_train) in enumerate(train_dataset.take(-1))
        trainingorder = np.arange(0, OuterTrainBatchDimension)
        np.random.shuffle(trainingorder)
        count1 = 0

        for countbatches in range(0, numberoftrainbatches):
            count2 = min(OuterTrainBatchDimension, count1 + trainbatchsize)
            if count2 <= count1:
                continue
            samples = trainingorder[count1:count2]
            count1 += trainbatchsize
            X_train = TFTtrain_datacollection['inputs'][samples, Ellipsis]
            y_train = TFTtrain_datacollection['outputs'][samples, Ellipsis]
            sw_train = []
            time_train = []
            id_train = []
            Numinbatch = X_train.shape[0]
            # myTFTTools.TFTSymbolicWindows X_train is indexed by Batch index, 1(replace by Window), 1 (replace by properties)
            if myTFTTools.TFTSymbolicWindows:
                StopWatch.start('label1')
                X_train = X_train.numpy()
                X_train = np.reshape(X_train, Numinbatch)
                iseqarray = np.right_shift(X_train, 16)
                ilocarray = np.bitwise_and(X_train, 0b1111111111111111)
                StopWatch.stop('label1')
                Ctime1 += StopWatch.get('label1', digits=4)
                StopWatch.start('label3')
                X_train_withSeq = list()
                for iloc in range(0, Numinbatch):
                    X_train_withSeq.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                #         X_train_withSeq=[ReshapedSequencesTOT[ilocarray[iloc],iseqarray[iloc]:iseqarray[iloc]+Tseq] for iloc in range(0,Numinbatch)]
                StopWatch.stop('label3')
                Ctime3 += StopWatch.get('label3', digits=5)
                StopWatch.start('label2')
                loss = myTFTcustommodel.train_step((np.array(X_train_withSeq), y_train, sw_train, time_train, id_train))
                StopWatch.stop('label2')
                Ctime2 += StopWatch.get('label2', digits=4)

            else:
                loss = myTFTcustommodel.train_step((X_train, y_train, sw_train, time_train, id_train))

            GarbageCollect = False
            if GarbageCollect:
                if myTFTTools.TFTSymbolicWindows:
                    X_train_withSeq = None
                X_train = None
                y_train = None
                sw_train = None
                time_train = None
                id_train = None
                if garbagecollectcall > GarbageCollectionLimit:
                    garbagecollectcall = 0
                    gc.collect()
                garbagecollectcall += 1

            localloss = loss["loss"].numpy()
            train_lossoverbatch.append(localloss)

            if batchperepoch:
                qbar.update(LSTMbatch_size)
                qbar.set_postfix(Loss=localloss, Epoch=e)
            bbar.update(Numinbatch)
            bbar.set_postfix(Loss=localloss, Epoch=e)
        # End Training step for one batch

        # Start Validation
        if AnyOldValidation:
            count1 = 0
            for countbatches in range(0, numberofvalbatches):
                count2 = min(OuterValBatchDimension, count1 + valbatchsize)
                if count2 <= count1:
                    continue
                samples = np.arange(count1, count2)
                count1 += valbatchsize
                X_val = TFTval_datacollection['inputs'][samples, Ellipsis]
                y_val = TFTval_datacollection['outputs'][samples, Ellipsis]
                sw_val = []
                #      for batch, (X_val, y_val, sw_val) in enumerate(val_dataset.take(-1)):
                time_val = []
                id_val = []
                Numinbatch = X_val.shape[0]
                # myTFTTools.TFTSymbolicWindows X_val is indexed by Batch index, 1(replace by Window), 1 (replace by properties)
                if myTFTTools.TFTSymbolicWindows:
                    StopWatch.start('label1')
                    X_val = X_val.numpy()
                    X_val = np.reshape(X_val, Numinbatch)
                    iseqarray = np.right_shift(X_val, 16)
                    ilocarray = np.bitwise_and(X_val, 0b1111111111111111)
                    StopWatch.stop('label1')
                    Ctime1 += StopWatch.get('label1', digits=4)
                    StopWatch.start('label3')
                    X_valFull = list()
                    for iloc in range(0, Numinbatch):
                        X_valFull.append(ReshapedSequencesTOT[ilocarray[iloc], iseqarray[iloc]:iseqarray[iloc] + Tseq])
                    StopWatch.stop('label3')
                    Ctime3 += StopWatch.get('label3', digits=5)
                    StopWatch.start('label2')
                    loss = myTFTcustommodel.test_step((np.array(X_valFull), y_val, sw_val, time_val, id_val))
                    StopWatch.stop('label2')
                    Ctime2 += StopWatch.get('label2', digits=4)

                else:
                    loss = myTFTcustommodel.test_step((X_val, y_val, sw_val, time_val, id_val))

                localval = loss["val_loss"].numpy()
                val_lossoverbatch.append(localval)

                bbar.update(Numinbatch)
                bbar.set_postfix(Val_loss=localval, Epoch=e)
        # End Batch

        train_epoch = train_lossoverbatch[-1]
        recordtrainloss.append(train_epoch)
        mycheckpoint.tfrecordtrainloss = tf.Variable(recordtrainloss)
        '''
    line = 'Train ' + str(round(np.mean(train_lossoverbatch),5)) + ' '
    count = 0
    for x in train_lossoverbatch:
      if count%100 == 0:
        line = line + str(count) +':' + str(round(x,5)) + ' '
      count += 1
    print(wraptotext(line,size=180))
    '''
        val_epoch = 0.0
        if AnyOldValidation > 0.001:
            val_epoch = val_lossoverbatch[-1]
            recordvalloss.append(val_epoch)
            mycheckpoint.tfrecordvalloss = tf.Variable(recordvalloss)
            '''
      line = 'Val ' + str(round(np.mean(val_lossoverbatch),5)) + ' '
      count = 0
      for x in val_lossoverbatch:
        if count%100 == 0:
          line = line + str(count) +':' + str(round(x,5)) + ' '
        count += 1
      print(wraptotext(line,size=180))
      '''

        pbar.set_postfix(Loss=train_epoch, Val=val_epoch)
        bbar.reset()
        tfepochstep = tfepochstep + 1
        mycheckpoint.tfepochstep.assign(tfepochstep)

        # Decide on best fit
        MonitorResult, train_epoch, val_epoch = TFTTrainingMonitor.EpochEvaluate(e, train_epoch, val_epoch,
                                                                                 tfepochstep, recordtrainloss,
                                                                                 recordvalloss)
        if MonitorResult == 1:
            tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = TFTTrainingMonitor.RestoreBestFit()  # Restore Best Fit
        else:
            continue
    # *********************** End of Epoch Loop

    # Print Fit details
    print(startbold + 'Times ' + str(round(Ctime1, 5)) + ' ' + str(round(Ctime3, 5)) + ' TF ' + str(
        round(Ctime2, 5)) + resetfonts)
    TFTTrainingMonitor.PrintEndofFit(TFTTransformerepochs)

    # Set Best Possible Fit
    tfepochstep, recordtrainloss, recordvalloss, train_epoch, val_epoch = TFTTrainingMonitor.BestPossibleFit()

    if Checkpointfinalstate:
        savepath = mycheckpoint.save(file_prefix=CHECKPOINTDIR + RunName)
        print('Checkpoint at ' + savepath + ' from ' + CHECKPOINTDIR)
    trainlen = len(recordtrainloss)
    extrainfo = ''
    if AnyOldValidation > 0.001:
        vallen = len(recordvalloss)
        extrainfo = ' Val Epoch ' + str(vallen - 1) + ' Val Loss ' + str(round(recordvalloss[vallen - 1], 7))
    print('Train Epoch ' + str(trainlen - 1) + ' Train Loss ' + str(round(recordtrainloss[trainlen - 1], 7)) + extrainfo)

    #
    myTFTcustommodel.summary()
    print('\nmyTFTcustommodel.myTFTFullNetwork **************************************')
    myTFTcustommodel.myTFTFullNetwork.summary()
    print('\nmyTFTcustommodel.myTFTFullNetwork.TFTLSTMEncoder **************************************')
    if not myTFTTools.TFTdefaultLSTM:
        myTFTcustommodel.myTFTFullNetwork.TFTLSTMEncoder.summary()
        print('\nmyTFTcustommodel.myTFTFullNetwork.TFTLSTMDecoder **************************************')
        myTFTcustommodel.myTFTFullNetwork.TFTLSTMEncoder.summary()
    print('\nmyTFTcustommodel.myTFTFullNetwork.TFTself_attn_layer **************************************')
    myTFTcustommodel.myTFTFullNetwork.TFTself_attn_layer.summary()
    myTFTcustommodel.myTFTFullNetwork.TFTself_attn_layer.attention.summary()

    if OutputNetworkPictures:
        outputpicture1 = APPLDIR + '/Outputs/Model_' + RunName + '1.png'
        outputpicture2 = APPLDIR + '/Outputs/Model_' + RunName + '2.png'
        tf.keras.utils.plot_model(myTFTcustommodel.build_graph([Tseq, NpropperseqTOT]),
                                  show_shapes=True, to_file=outputpicture1,
                                  show_dtype=True,
                                  expand_nested=True)
        tf.keras.utils.plot_model(myTFTcustommodel.myTFTFullNetwork.build_graph([Tseq, NpropperseqTOT]),
                                  show_shapes=True, to_file=outputpicture2,
                                  show_dtype=True,
                                  expand_nested=True)
    if myTFTTools.TFTSymbolicWindows:
        finalizeTFTDL(myTFTcustommodel, recordtrainloss, recordvalloss, AnyOldValidation, TFTtest_datacollection, 2,
                      LabelFit='Custom TFT Fit')
    else:
        finalizeTFTDL(myTFTcustommodel, recordtrainloss, recordvalloss, AnyOldValidation, TFTtest_datacollection, 2,
                      LabelFit='Custom TFT Fit')
    return


"""###Run TFT"""

# Run TFT Only
AnalysisOnly = myTFTTools.AnalysisOnly
Dumpoutkeyplotsaspics = True
Restorefromcheckpoint = myTFTTools.Restorefromcheckpoint
Checkpointfinalstate = True
if AnalysisOnly:
    Restorefromcheckpoint = True
    Checkpointfinalstate = False
if Restorefromcheckpoint:
    inputCHECKPOINTDIR = CHECKPOINTDIR
    inputRunName = myTFTTools.inputRunName
    inputCheckpointpostfix = myTFTTools.inputCheckpointpostfix
    inputCHECKPOINTDIR = APPLDIR + "/checkpoints/" + inputRunName + "dir/"

batchperepoch = False  # if True output a batch bar for each epoch
GlobalSpacetime = False
IncreaseNloc_sample = 1
DecreaseNloc_sample = 1
SkipDL2F = True
FullSetValidation = False

TFTTrainingMonitor = TensorFlowTrainingMonitor()
if Hydrology:
    TFTTrainingMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
if Earthquake:
    TFTTrainingMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)
if ReadJan2021Covid or ReadApril2021Covid:
    TFTTrainingMonitor.SetControlParms(SuccessLimit=1, FailureLimit=2)


def PrintTFTBasicStuff():
    myTFTTools.PrintTitle('Start TFT Deep Learning')
    if myTFTTools.TFTSymbolicWindows:
        print(startbold + startred + 'Symbolic Windows used to save space' + resetfonts)
    else:
        print(startbold + startred + 'Symbolic Windows NOT used' + resetfonts)
    print('Training Locations ' + str(TrainingNloc) + ' Validation Locations ' + str(ValidationNloc) +
          ' Sequences ' + str(Num_Seq))
    if LocationBasedValidation:
        print(startbold + startred + " Location Based Validation with fraction " + str(
            LocationValidationFraction) + resetfonts)
        if RestartLocationBasedValidation:
            print(startbold + startred + " Using Validation set saved in " + RestartValidationSetRunName + resetfonts)
    print('\nAre futures predicted ' + str(UseFutures) + ' Custom Loss Pointer ' + str(
        CustomLoss) + ' Class weights used ' + str(UseClassweights))

    print('\nProperties per sequence ' + str(NpropperseqTOT))
    print('\n' + startbold + startpurple + 'Properties ' + resetfonts)
    labelline = 'Name   '
    for propval in range(0, 7):
        labelline += QuantityStatisticsNames[propval] + '    '
    print('\n' + startbold + labelline + resetfonts)
    for iprop in range(0, NpropperseqTOT):
        line = startbold + startpurple + str(iprop) + ' ' + InputPropertyNames[PropertyNameIndex[iprop]] + resetfonts
        jprop = PropertyAverageValuesPointer[iprop]
        line += ' Root ' + str(QuantityTakeroot[jprop])
        for proppredval in range(0, 7):
            line += ' ' + str(round(QuantityStatistics[jprop, proppredval], 3))
        print(line)

    print('\nPredictions per sequence ' + str(NpredperseqTOT))
    print('\n' + startbold + startpurple + 'Predictions ' + resetfonts)
    print('\n' + startbold + labelline + resetfonts)
    for ipred in range(0, NpredperseqTOT):
        line = startbold + startpurple + str(ipred) + ' ' + Predictionname[PredictionNameIndex[ipred]] + ' wgt ' + str(
            round(Predictionwgt[ipred], 3)) + resetfonts + ' '
        jpred = PredictionAverageValuesPointer[ipred]
        line += ' Root ' + str(QuantityTakeroot[jpred])
        for proppredval in range(0, 7):
            line += ' ' + str(round(QuantityStatistics[jpred, proppredval], 3))
        print(line)
    print('\n')

    myTFTTools.PrintTitle('Start TFT Deep Learning')
    for k in TFTparams:
        print('# {} = {}'.format(k, TFTparams[k]))


runtype = ''
if Restorefromcheckpoint:
    runtype = 'Restarted '
myTFTTools.PrintTitle(runtype)
PrintTFTBasicStuff()

RunTFTCustomVersion()
myTFTTools.PrintTitle('TFT run completed')
sys.exit(0)

"""#End modified TFT"""
